{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from gbp.gbp import *\n",
    "from gbp.factor import *\n",
    "from gbp.grid import *\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class MultilayerAbstractionSystem:\n",
    "    def __init__(self, base_graph, num_layers=3):\n",
    "        self.layers = []  # Each is an instance of AbstractionLayer\n",
    "        self.num_layers = num_layers\n",
    "        self.build_base_layer(base_graph)\n",
    "    \n",
    "    def build_base_layer(self, base_graph):\n",
    "        layer0 = AbstractionLayer(level=0, graph=base_graph)\n",
    "        self.layers.append(layer0)\n",
    "\n",
    "    def build_abstraction_layers(self):\n",
    "        for l in range(1, self.num_layers):\n",
    "            coarse_layer = self.layers[-1].abstract_to_next_layer()\n",
    "            self.layers.append(coarse_layer)\n",
    "\n",
    "    def run_gbp_on_all_layers(self, num_iters=20):\n",
    "        for layer in self.layers:\n",
    "            layer.run_gbp(num_iters=num_iters)\n",
    "\n",
    "    def recover_to_base(self):\n",
    "        \"\"\"\n",
    "        Backward propagation of solutions from coarsest layer to base.\n",
    "        Could apply coarse correction or interpolation.\n",
    "        \"\"\"\n",
    "        for l in reversed(range(1, len(self.layers))):\n",
    "            self.layers[l].propagate_to_finer(self.layers[l-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eaff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractionLayer:\n",
    "    def __init__(self, level, PrevLayer):\n",
    "        self.level = level\n",
    "        self.super_graph = self.build_super_graph(PrevLayer)  # GBP-style graph (var_nodes, factors)\n",
    "        self.abstract_graph = self.build_abstract_graph(self.supergraph)  # Abstract graph\n",
    "    \n",
    "    \n",
    "    def build_super_graph(self, PrevLayer):\n",
    "        \"\"\"\n",
    "        Construct supergraph from previous layer's graph.\n",
    "        This involves aggregating variable nodes and factors.\n",
    "        \"\"\"\n",
    "\n",
    "        varis_sup, prior_facs_sup, horizontal_facs_sup, vertical_facs_sup  = build_coarse_slam_graph(\n",
    "            prior_facs_fine=prior_facs,\n",
    "            between_facs_fine=between_facs,\n",
    "            H=H, W=W,\n",
    "            stride = 2,\n",
    "        )\n",
    "\n",
    "        return PrevLayer.graph\n",
    "    \n",
    "\n",
    "    def build_abstract_graph(self, supergraph, r=2):\n",
    "        varis_sup = supergraph.varis\n",
    "        prior_facs_sup = supergraph.prior_facs\n",
    "        horizontal_facs_sup = supergraph.horizontal_facs\n",
    "        vertical_facs_sup = supergraph.vertical_facs\n",
    "\n",
    "        abs_beliefs = []\n",
    "        Bs = []\n",
    "        ks = []\n",
    "\n",
    "        # === 1. Build Abstraction Variables ===\n",
    "        varis_sup_mu = varis_sup.belief.mu()\n",
    "        varis_sup_sigma = varis_sup.belief.sigma()\n",
    "\n",
    "        for i in range(len(varis_sup.var_id)):\n",
    "            varis_sup_mu_i = varis_sup_mu[i]\n",
    "            varis_sup_sigma_i = varis_sup_sigma[i]\n",
    "\n",
    "            eigvals, eigvecs = np.linalg.eigh(varis_sup_sigma_i)\n",
    "\n",
    "            # Step 2: Sort eigenvalues and eigenvectors in descending order of eigenvalues\n",
    "            idx = np.argsort(eigvals)[::-1]      # Get indices of sorted eigenvalues (largest first)\n",
    "            eigvals = eigvals[idx]               # Reorder eigenvalues\n",
    "            eigvecs = eigvecs[:, idx]            # Reorder corresponding eigenvectors\n",
    "\n",
    "            # Step 3: Select the top-k eigenvectors to form the projection matrix (principal subspace)\n",
    "            r = r\n",
    "            B_reduced = eigvecs[:, :r]                 # B_reduced: shape (8, r), projects 8D to rD\n",
    "\n",
    "            Bs.append(B_reduced)                        # Store the projection matrix for this variable\n",
    "\n",
    "            # Step 4: Project eta and Lam onto the reduced 2D subspace\n",
    "            # This gives the natural parameters of the reduced 2D Gaussian\n",
    "            varis_abs_mu_i = B_reduced.T @ varis_sup_mu_i          # Projected natural mean: shape (2,)\n",
    "            varis_abs_sigma_i = B_reduced.T @ varis_sup_sigma_i @ B_reduced  # Projected covariance: shape (2, 2)\n",
    "            ks.append(varis_sup_mu_i - B_reduced @ varis_abs_mu_i)  # Store the offset for this variable\n",
    "\n",
    "            varis_abs_lam_i = jnp.linalg.inv(varis_abs_sigma_i)  # Inverse covariance (precision matrix): shape (2, 2)\n",
    "            varis_abs_eta_i = varis_abs_lam_i @ varis_abs_mu_i  # Natural parameters: shape (2,)\n",
    "            abs_beliefs.append(Gaussian(varis_abs_eta_i, varis_abs_lam_i))\n",
    "\n",
    "\n",
    "        N, Ni_v, _ = varis_sup.msgs.eta.shape\n",
    "        abs_msgs = Gaussian(jnp.zeros((N, Ni_v, r)), jnp.zeros((N, Ni_v, r, r)))  # messages (eta, Lambda) to each factor port\n",
    "\n",
    "        varis_abs = Variable(\n",
    "            var_id=varis_sup.var_id,\n",
    "            belief=tree_stack(abs_beliefs, axis=0),\n",
    "            msgs=abs_msgs,\n",
    "            adj_factor_idx=jnp.stack(varis_sup.adj_factor_idx),\n",
    "        )\n",
    "\n",
    "        # === 2. Build Abs Priors ===\n",
    "        prior_facs_abs = Factor(\n",
    "            factor_id=prior_facs_sup.factor_id,\n",
    "            z=prior_facs_sup.z,\n",
    "            z_Lam=prior_facs_sup.z_Lam,\n",
    "            threshold=prior_facs_sup.threshold,\n",
    "            potential=None,\n",
    "            adj_var_id=prior_facs_sup.adj_var_id,\n",
    "            adj_var_idx=prior_facs_sup.adj_var_idx,\n",
    "        )\n",
    "\n",
    "        # === Build Horizontal & Vertical Between Factors Separately ===\n",
    "        horizontal_facs_abs = Factor(\n",
    "            factor_id=horizontal_facs_sup.factor_id,\n",
    "            z= horizontal_facs_sup.z,\n",
    "            z_Lam= horizontal_facs_sup.z_Lam,\n",
    "            threshold= horizontal_facs_sup.threshold,\n",
    "            potential=None,\n",
    "            adj_var_id= horizontal_facs_sup.adj_var_id,\n",
    "            adj_var_idx= horizontal_facs_sup.adj_var_idx,\n",
    "        )   \n",
    "\n",
    "        vertical_facs_abs = Factor(\n",
    "            factor_id=vertical_facs_sup.factor_id,\n",
    "            z= vertical_facs_sup.z,\n",
    "            z_Lam= vertical_facs_sup.z_Lam,\n",
    "            threshold= vertical_facs_sup.threshold,\n",
    "            potential=None,                                         \n",
    "            adj_var_id= vertical_facs_sup.adj_var_id,\n",
    "            adj_var_idx= vertical_facs_sup.adj_var_idx,\n",
    "        )\n",
    "\n",
    "        # === 3. Build Abstract Graph ===\n",
    "        abstract_graph = Graph(\n",
    "            varis=varis_abs,\n",
    "            prior_facs=prior_facs_abs,\n",
    "            horizontal_facs=horizontal_facs_abs,\n",
    "            vertical_facs=vertical_facs_abs,\n",
    "            r=r,  # Dimension of the reduced subspace\n",
    "            Bs=Bs,  # List of projection matrices for each variable\n",
    "            ks=ks,  # Offsets for each variable)\n",
    "        )\n",
    "   \n",
    "        return abstract_graph\n",
    "\n",
    "\n",
    "    def run_gbp(self, num_iters=20):\n",
    "        # Call your GBP solver on self.graph\n",
    "        pass\n",
    "\n",
    "    def build_super_graph(self, PrevLayer):\n",
    "        # Construct supergraph from previous layer's graph\n",
    "        # This could involve aggregating variable nodes and factors\n",
    "        pass    \n",
    "\n",
    "    def build_abstract_graph(self, supergraph):\n",
    "        # Create abstract graph from supergraph\n",
    "        # This could involve SVD or PCA to reduce dimensions\n",
    "        pass\n",
    "\n",
    "\n",
    "    def propagate_to_finer(self, finer_layer):\n",
    "        # Optional: propagate mu or corrections back to finer layer\n",
    "        pass\n",
    "\n",
    "    def stack_variable_nodes(self):\n",
    "        # Collect 4 fine variable mus into one 8D vector\n",
    "        pass\n",
    "\n",
    "    def compute_svd_embeddings(self, supernodes):\n",
    "        # Use SVD or PCA to map each 8D vector into 2D\n",
    "        pass\n",
    "\n",
    "    def build_graph_from_embeddings(self, embeddings):\n",
    "        # Connect adjacent nodes in grid pattern, construct new graph\n",
    "        pass\n",
    "\n",
    "    def create_supernode_mapping(self):\n",
    "        # Track which fine nodes belong to which coarse node\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorGraph:\n",
    "    def __init__(self, variable_nodes, factors):\n",
    "        self.variable_nodes = variable_nodes  # List of variable nodes\n",
    "        self.factors = factors  # List of factor nodes\n",
    "\n",
    "    def build_graph(self):\n",
    "        # Construct the internal graph structure from variable nodes and factors\n",
    "        pass\n",
    "\n",
    "    def add_factor(self, factor):\n",
    "        # Add a new factor to the graph\n",
    "        pass\n",
    "\n",
    "    def update_variable(self, var_node, new_value):\n",
    "        # Update a variable node's value\n",
    "        pass\n",
    "\n",
    "    def run_gbp(self, num_iters=20):\n",
    "        # Run Generalized Belief Propagation on the graph\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
