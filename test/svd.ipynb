{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0d0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前 notebook 所在目录的父目录\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from gbp.gbp import *\n",
    "from gbp.factor import *\n",
    "from gbp.grid import *\n",
    "\n",
    "H = 16\n",
    "W = 16\n",
    "prior_noise_std=prior_std=1\n",
    "odom_noise_std=odom_std=0.01\n",
    "seed=0\n",
    "num_iters=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1afd499",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions, prior_meas, between_meas = generate_grid_slam_data(H=H, W=W, \n",
    "                                    prior_noise_std=prior_noise_std, odom_noise_std=odom_noise_std, seed=seed)\n",
    "varis, prior_facs, between_facs = build_pose_slam_graph(N=256, prior_meas=prior_meas, between_meas=between_meas, \n",
    "                                                        prior_std=prior_std, odom_std=odom_std,\n",
    "                                                        Ni_v=10, D=2)\n",
    "\n",
    "\n",
    "# build the coarse-level pose SLAM grid\n",
    "varis_sup, prior_facs_sup, horizontal_facs_sup, vertical_facs_sup  = build_coarse_slam_graph(\n",
    "    prior_facs_fine=prior_facs,\n",
    "    between_facs_fine=between_facs,\n",
    "    H=H, W=W,\n",
    "    stride = 2,\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Variable update\n",
    "varis_sup, vtof_msgs, linpoints = update_variable(varis_sup)\n",
    "\n",
    "# Factor update\n",
    "prior_facs, varis_sup = update_factor(prior_facs_sup, varis_sup, vtof_msgs, linpoints, h3_fn, l2)\n",
    "\n",
    "# Variable update\n",
    "varis_sup, vtof_msgs, linpoints = update_variable(varis_sup)\n",
    "\n",
    "\n",
    "# Factor update\n",
    "horizontal_facs_sup, varis_sup = update_factor(horizontal_facs_sup, varis_sup, vtof_msgs, \n",
    "                                                linpoints, h4_fn, l2)\n",
    "\n",
    "vertical_facs_sup, varis_sup = update_factor(vertical_facs_sup, varis_sup, vtof_msgs, \n",
    "                                                linpoints, h5_fn, l2)\n",
    "\n",
    "\n",
    "# Variable update\n",
    "varis_sup, vtof_msgs, linpoints = update_variable(varis_sup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c87e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jax.jit\n",
    "def h3_fn_tilde(x, B):\n",
    "    \"\"\"\n",
    "    Predicts measurement h(x) for abs prior.\n",
    "\n",
    "    Input:\n",
    "        x: (2,) → 2D abstraction of 4 stacked fine-level variables\n",
    "        B: (8,2) → projection matrix from 2D to 8D\n",
    "    Output:\n",
    "        z_hat: (16,) = [x0, x1, x2, x3, x1-x0, x2-x0, x3-x1, x3-x2]\n",
    "    \"\"\"\n",
    "    x = x.reshape(-1)\n",
    "    x = B @ x  # Project 2D abstraction to 8D\n",
    "    \n",
    "    x0 = x[0:2]\n",
    "    x1 = x[2:4]\n",
    "    x2 = x[4:6]\n",
    "    x3 = x[6:8]\n",
    "\n",
    "    # 4 priors (just xi)\n",
    "    z_hat_0 = x0\n",
    "    z_hat_1 = x1\n",
    "    z_hat_2 = x2\n",
    "    z_hat_3 = x3\n",
    "\n",
    "    # 4 internal between\n",
    "    z_hat_4 = x1 - x0\n",
    "    z_hat_5 = x2 - x0\n",
    "    z_hat_6 = x3 - x1\n",
    "    z_hat_7 = x3 - x2\n",
    "\n",
    "    return jnp.concatenate([\n",
    "        z_hat_0, z_hat_1, z_hat_2, z_hat_3,\n",
    "        z_hat_4, z_hat_5, z_hat_6, z_hat_7\n",
    "    ])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def h4_fn_tilde(xs, Bs):\n",
    "    \"\"\"\n",
    "    Predicts coarse between measurement h(xs) where:\n",
    "      - xs[0] is coarse variable i (8D)\n",
    "      - xs[1] is coarse variable j (8D)\n",
    "    Fixed: uses v01→v02 and v11→v12 edges\n",
    "    \n",
    "    Returns:\n",
    "        z_hat: shape (4,) = two 2D relative positions\n",
    "    \"\"\"\n",
    "    xi = xs[0]\n",
    "    xj = xs[1]\n",
    "    Bi = Bs[0]\n",
    "    Bj = Bs[1]\n",
    "\n",
    "    # Project coarse variables to 8D\n",
    "    xi = Bi @ xi  # shape (8,)\n",
    "    xj = Bj @ xj  # shape (8,)\n",
    "\n",
    "    # First residual: xj[0:2] - xi[2:4]  (v02 - v01)\n",
    "    r1 = xj[0:2] - xi[2:4]\n",
    "\n",
    "    # Second residual: xj[4:6] - xi[6:8] (v12 - v11)\n",
    "    r2 = xj[4:6] - xi[6:8]\n",
    "\n",
    "    return jnp.concatenate([r1, r2])  # shape (4,)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def h5_fn_tilde(xs, Bs):\n",
    "    \"\"\"\n",
    "    Predicts coarse between measurement h(xs) where:\n",
    "      - xs[0] is coarse variable i (8D)\n",
    "      - xs[1] is coarse variable j (8D)\n",
    "    Fixed: uses v10→v20 and v11→v21 edges\n",
    "\n",
    "    Returns:\n",
    "        z_hat: shape (4,) = two 2D relative positions\n",
    "    \"\"\"\n",
    "    xi = xs[0]\n",
    "    xj = xs[1]\n",
    "    Bi = Bs[0]\n",
    "    Bj = Bs[1]\n",
    "\n",
    "    # Project coarse variables to 8D\n",
    "    xi = Bi @ xi  # shape (8,)\n",
    "    xj = Bj @ xj  # shape (8,)  \n",
    "\n",
    "    # First residual: xj[0:2] - xi[4:6]  (v20 - v10)\n",
    "    r1 = xj[0:2] - xi[4:6]\n",
    "\n",
    "    # Second residual: xj[2:4] - xi[6:8] (v21 - v11)\n",
    "    r2 = xj[2:4] - xi[6:8]\n",
    "\n",
    "    return jnp.concatenate([r1, r2])  # shape (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a73516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_abs_slam_graph(\n",
    "    varis_sup: Variable,\n",
    "    prior_facs_sup: Factor,\n",
    "    horizontal_facs_sup: Factor,\n",
    "    vertical_facs_sup: Factor,\n",
    ") -> Tuple[Variable, Factor, Factor]:\n",
    "\n",
    "    abs_beliefs = []\n",
    "    abs_msgs_eta = []\n",
    "    abs_msgs_Lam = []\n",
    "    abs_adj_factor_idx = []\n",
    "\n",
    "    # === 1. Build Abstraction Variables ===\n",
    "    varis_sup_mu = varis_sup.belief.mu()\n",
    "    varis_sup_sigma = varis_sup.belief.sigma()\n",
    "\n",
    "    for i in range(len(varis_sup.var_id)):\n",
    "        varis_sup_mu_i = varis_sup_mu[i]\n",
    "        varis_sup_sigma_i = varis_sup_sigma[i]\n",
    "\n",
    "        eigvals, eigvecs = np.linalg.eigh(np.linalg.inv(varis_sup_sigma_i))\n",
    "\n",
    "        # Step 2: Sort eigenvalues and eigenvectors in descending order of eigenvalues\n",
    "        idx = np.argsort(eigvals)[::-1]      # Get indices of sorted eigenvalues (largest first)\n",
    "        eigvals = eigvals[idx]               # Reorder eigenvalues\n",
    "        eigvecs = eigvecs[:, idx]            # Reorder corresponding eigenvectors\n",
    "\n",
    "        # Step 3: Select the top-k eigenvectors to form the projection matrix (principal subspace)\n",
    "        k = 2\n",
    "        B_k = eigvecs[:, :2]                 # B_k: shape (8, 2), projects 8D to 2D\n",
    "\n",
    "        # Step 4: Project eta and Lam onto the reduced 2D subspace\n",
    "        # This gives the natural parameters of the reduced 2D Gaussian\n",
    "        varis_abs_mu_i = B_k.T @ varis_sup_mu_i          # Projected natural mean: shape (2,)\n",
    "        varis_abs_sigma_i = B_k.T @ varis_sup_sigma_i @ B_k  # Projected covariance: shape (2, 2)\n",
    "\n",
    "        varis_abs_lam_i = jnp.linalg.inv(varis_abs_sigma_i)  # Inverse covariance (precision matrix): shape (2, 2)\n",
    "        varis_abs_eta_i = varis_abs_lam_i @ varis_abs_mu_i  # Natural parameters: shape (2,)\n",
    "        abs_beliefs.append(Gaussian(varis_abs_eta_i, varis_abs_lam_i))\n",
    "\n",
    "        abs_msgs_eta.append(jnp.zeros((8)))  # 8D for coarse variable\n",
    "        abs_msgs_Lam.append(jnp.zeros((8, 8)))\n",
    "\n",
    "\n",
    "    varis_abs = Variable(\n",
    "        var_id=varis_sup.var_id,\n",
    "        belief=tree_stack(abs_beliefs, axis=0),\n",
    "        msgs=Gaussian(jnp.stack(abs_msgs_eta), jnp.stack(abs_msgs_Lam)),\n",
    "        adj_factor_idx=jnp.stack(varis_sup.adj_factor_idx),\n",
    "    )\n",
    "\n",
    "    # === 2. Build Abs Priors ===\n",
    "    prior_facs_abs = Factor(\n",
    "        factor_id=prior_facs_sup.factor_id,\n",
    "        z=prior_facs_sup.z,\n",
    "        z_Lam=prior_facs_sup.z_Lam,\n",
    "        threshold=prior_facs_sup.threshold,\n",
    "        potential=None,\n",
    "        adj_var_id=prior_facs_sup.adj_var_id,\n",
    "        adj_var_idx=prior_facs_sup.adj_var_idx,\n",
    "    )\n",
    "\n",
    "    # === Build Horizontal & Vertical Between Factors Separately ===\n",
    "    horizontal_facs_abs = Factor(\n",
    "        factor_id=horizontal_facs_sup.factor_id,\n",
    "        z= horizontal_facs_sup.z,\n",
    "        z_Lam= horizontal_facs_sup.z_Lam,\n",
    "        threshold= horizontal_facs_sup.threshold,\n",
    "        potential=None,\n",
    "        adj_var_id= horizontal_facs_sup.adj_var_id,\n",
    "        adj_var_idx= horizontal_facs_sup.adj_var_idx,\n",
    "    )   \n",
    "\n",
    "    vertical_facs_abs = Factor(\n",
    "        factor_id=vertical_facs_sup.factor_id,\n",
    "        z= vertical_facs_sup.z,\n",
    "        z_Lam= vertical_facs_sup.z_Lam,\n",
    "        threshold= vertical_facs_sup.threshold,\n",
    "        potential=None,                                         \n",
    "        adj_var_id= vertical_facs_sup.adj_var_id,\n",
    "        adj_var_idx= vertical_facs_sup.adj_var_idx,\n",
    "    )\n",
    "\n",
    "    return varis_abs, prior_facs_abs, horizontal_facs_abs, vertical_facs_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c252aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "varis_abs, prior_facs_abs, horizontal_facs_abs, vertical_facs_abs = build_abs_slam_graph(\n",
    "    varis_sup=varis_sup,\n",
    "    prior_facs_sup=prior_facs_sup,\n",
    "    horizontal_facs_sup=horizontal_facs_sup,\n",
    "    vertical_facs_sup=vertical_facs_sup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f185e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_solve_coarse(varis, prior_facs, horizontal_between_facs, vertical_between_facs, num_iters=50, visualize=False, prior_h=h3_fn, between_h=[h4_fn,h5_fn]):\n",
    "    energy_log = []\n",
    "    positions_log = []\n",
    "\n",
    "    \n",
    "    # Initialize variable with only priors factors \n",
    "    varis, vtof_msgs, linpoints = update_variable(varis)\n",
    "    prior_facs, varis = update_factor(prior_facs, varis, vtof_msgs, linpoints, prior_h, l2)\n",
    "    if visualize:\n",
    "        # Linearization points and energy computation\n",
    "        prior_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "            prior_facs, linpoints[prior_facs.adj_var_id[:, 0]], prior_h\n",
    "        ))\n",
    "\n",
    "        horizontal_between_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "            horizontal_between_facs, linpoints[horizontal_between_facs.adj_var_id], between_h[0]\n",
    "        ))\n",
    "\n",
    "        vertical_between_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "            vertical_between_facs, linpoints[vertical_between_facs.adj_var_id], between_h[1]\n",
    "        ))\n",
    "\n",
    "\n",
    "        energy = prior_energy + horizontal_between_energy + vertical_between_energy\n",
    "        energy_log.append(energy)\n",
    "\n",
    "        positions_log.append(linpoints)\n",
    "\n",
    "\n",
    "    for i in range(num_iters-1):\n",
    "        # Step 1: Variable update\n",
    "        varis, vtof_msgs, linpoints = update_variable(varis)\n",
    "\n",
    "        # Step 2: Factor update\n",
    "        prior_facs, varis = update_factor(prior_facs, varis, vtof_msgs, linpoints, prior_h, l2)\n",
    "\n",
    "        horizontal_between_facs, varis = update_factor(horizontal_between_facs, varis, vtof_msgs, \n",
    "                                                       linpoints, between_h[0], l2)\n",
    "\n",
    "        vertical_between_facs, varis = update_factor(vertical_between_facs, varis, vtof_msgs, \n",
    "                                                       linpoints, between_h[1], l2)\n",
    "        \n",
    "        if visualize:\n",
    "            # Step 3: Linearization points and energy computation\n",
    "            prior_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "                prior_facs, linpoints[prior_facs.adj_var_id[:, 0]], prior_h\n",
    "            ))\n",
    "    \n",
    "            horizontal_between_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "                horizontal_between_facs, linpoints[horizontal_between_facs.adj_var_id], between_h[0]\n",
    "            ))\n",
    "    \n",
    "            vertical_between_energy = jnp.sum(jax.vmap(factor_energy, in_axes=(0, 0, None))(\n",
    "                vertical_between_facs, linpoints[vertical_between_facs.adj_var_id], between_h[1]\n",
    "            ))\n",
    "\n",
    "            energy = prior_energy + horizontal_between_energy + vertical_between_energy\n",
    "\n",
    "            energy_log.append(energy)\n",
    "            positions_log.append(linpoints)\n",
    "\n",
    "        \n",
    "    return varis, prior_facs, horizontal_between_facs, vertical_between_facs, \\\n",
    "            np.array(energy_log), np.array(positions_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
