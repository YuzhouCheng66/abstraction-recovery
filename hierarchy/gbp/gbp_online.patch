diff --git a/gbp.py b/gbp.py
index 8b9c3d2..online 100644
--- a/gbp.py
+++ b/gbp.py
@@ -118,6 +118,194 @@ class FactorGraph:
         for factor in self.factors[:self.n_factor_nodes]:
             factor.robustify_loss()

+    # ================================================================
+    # Online / Incremental construction helpers
+    # ================================================================
+    def push_var(self, v, residual=1.0):
+        """
+        Push (or re-push) a variable into the residual heap.
+        We allow stale heap entries and skip them when popped.
+        """
+        r = float(residual)
+        self.var_residual[v] = r
+        heapq.heappush(self.var_heap, (-r, v.variableID, v))
+
+    def ensure_variable(self, variable_id, dofs=2, GT=None, tiny_prior=1e-6, init_mu=None, activate=True):
+        """
+        Get or create a variable with given id.
+        Used for online pose-graph growth.
+        """
+        if variable_id < len(self.var_nodes) and self.var_nodes[variable_id] is not None:
+            v = self.var_nodes[variable_id]
+            if GT is not None:
+                v.GT = np.array(GT, copy=True)
+            return v
+
+        while len(self.var_nodes) <= variable_id:
+            self.var_nodes.append(None)
+
+        v = VariableNode(variable_id, dofs=dofs)
+        v.type = "variable"
+
+        if GT is not None:
+            v.GT = np.array(GT, copy=True)
+
+        # tiny prior to avoid singularity
+        v.prior.lam = float(tiny_prior) * np.eye(dofs)
+        if init_mu is None:
+            v.prior.eta = np.zeros(dofs)
+        else:
+            init_mu = np.asarray(init_mu).reshape(-1)
+            v.prior.eta = v.prior.lam @ init_mu
+
+        v.update_belief()
+
+        self.var_nodes[variable_id] = v
+        self.n_var_nodes = max(self.n_var_nodes, variable_id + 1)
+
+        if activate:
+            self.push_var(v, residual=1.0)
+
+        return v
+
+    def add_binary_factor(self, vi, vj, measurement, measurement_lambda,
+                          meas_fn, jac_fn, linpoint=None,
+                          ftype="base", activate=True):
+        """
+        Add a binary factor (odometry / loop closure) online.
+        """
+        fid = self.n_factor_nodes
+        f = Factor(fid, [vi, vj],
+                   measurement=measurement,
+                   measurement_lambda=measurement_lambda,
+                   meas_fn=meas_fn,
+                   jac_fn=jac_fn)
+        f.type = ftype
+
+        vi.adj_factors.append(f)
+        vj.adj_factors.append(f)
+
+        if linpoint is None:
+            linpoint = np.concatenate([vi.mu, vj.mu])
+        f.compute_factor(linpoint=linpoint, update_self=True)
+
+        self.factors.append(f)
+        self.n_factor_nodes += 1
+        self.n_edges += 2
+        self.n_msgs += 2
+
+        vi.update_belief()
+        vj.update_belief()
+
+        if activate:
+            self.push_var(vi, 1.0)
+            self.push_var(vj, 1.0)
+
+        return f
+
+    def add_unary_prior_factor(self, v, measurement, measurement_lambda,
+                               meas_fn, jac_fn, linpoint=None,
+                               ftype="prior", activate=True):
+        """
+        Add a unary prior / anchor factor online.
+        """
+        fid = self.n_factor_nodes
+        f = Factor(fid, [v],
+                   measurement=measurement,
+                   measurement_lambda=measurement_lambda,
+                   meas_fn=meas_fn,
+                   jac_fn=jac_fn)
+        f.type = ftype
+
+        v.adj_factors.append(f)
+
+        if linpoint is None:
+            linpoint = v.mu
+        f.compute_factor(linpoint=linpoint, update_self=True)
+
+        self.factors.append(f)
+        self.n_factor_nodes += 1
+        self.n_edges += 1
+        self.n_msgs += 1
+
+        v.update_belief()
+
+        if activate:
+            self.push_var(v, 1.0)
+
+        return f
+
@@
-    def residual_iteration_var_heap(self):
+    def residual_iteration_var_heap(self, max_updates=50):
         if len(self.var_heap) == 0:
             for v in self.var_nodes:
                 self.var_residual[v] = v.residual
                 heapq.heappush(self.var_heap, (-v.residual, v.variableID, v))
 
         n_updates = 0
-        while (n_updates < len(self.var_nodes)) and len(self.var_heap) > 0:
+        while (n_updates < max_updates) and len(self.var_heap) > 0:
             neg_r, vid, v = heapq.heappop(self.var_heap)
 
             cur_r = self.var_residual.get(v, 0.0)
