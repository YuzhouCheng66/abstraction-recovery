{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db67ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output, State, no_update\n",
    "import dash_cytoscape as cyto\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "# ==== GBP import ====\n",
    "from gbp.gbp import *\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"Factor Graph SVD Abs&Recovery\"\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# SLAM-like base graph\n",
    "# -----------------------\n",
    "def make_slam_like_graph(N=100, step_size=25, loop_prob=0.05, loop_radius=50, prior_prop=0.0, seed=None):\n",
    "    if seed is None :\n",
    "        rng = np.random.default_rng()  # ✅ Ensure we have an RNG\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    nodes, edges = [], []\n",
    "    positions = []\n",
    "    x, y = 0.0, 0.0\n",
    "    positions.append((x, y))\n",
    "\n",
    "    # ✅ Deterministic-by-RNG: trajectory generation\n",
    "    for _ in range(1, int(N)):\n",
    "        dx, dy = rng.standard_normal(2)  # replace np.random.randn\n",
    "        norm = np.sqrt(dx**2 + dy**2) + 1e-6\n",
    "        dx, dy = dx / norm * float(step_size), dy / norm * float(step_size)\n",
    "        x, y = x + dx, y + dy\n",
    "        positions.append((x, y))\n",
    "\n",
    "    # Sequential edges along the path\n",
    "    for i, (px, py) in enumerate(positions):\n",
    "        nodes.append({\n",
    "            \"data\": {\"id\": f\"{i}\", \"layer\": 0, \"dim\": 2, \"num_base\": 1},\n",
    "            \"position\": {\"x\": float(px), \"y\": float(py)}\n",
    "        })\n",
    "\n",
    "    for i in range(int(N) - 1):\n",
    "        edges.append({\"data\": {\"source\": f\"{i}\", \"target\": f\"{i+1}\"}})\n",
    "\n",
    "    # ✅ Deterministic-by-RNG: loop-closure edges\n",
    "    for i in range(int(N)):\n",
    "        for j in range(i + 5, int(N)):\n",
    "            if rng.random() < float(loop_prob):  # replace np.random.rand\n",
    "                xi, yi = positions[i]\n",
    "                xj, yj = positions[j]\n",
    "                if np.hypot(xi - xj, yi - yj) < float(loop_radius):\n",
    "                    edges.append({\"data\": {\"source\": f\"{i}\", \"target\": f\"{j}\"}})\n",
    "\n",
    "    # ✅ Sample priors using the same RNG\n",
    "    if prior_prop <= 0.0:\n",
    "        strong_ids = {0}\n",
    "    elif prior_prop >= 1.0:\n",
    "        strong_ids = set(range(N))\n",
    "    else:\n",
    "        k = max(1, int(np.floor(prior_prop * N)))\n",
    "        strong_ids = set(rng.choice(N, size=k, replace=False).tolist())\n",
    "\n",
    "    # Add edges for nodes with strong priors\n",
    "    for i in strong_ids:\n",
    "        edges.append({\"data\": {\"source\": f\"{i}\", \"target\": \"prior\"}})\n",
    "\n",
    "    edges.append({\"data\": {\"source\": f\"{0}\", \"target\": \"anchor\"}}) \n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Grid aggregation\n",
    "# -----------------------\n",
    "def fuse_to_super_grid(prev_nodes, prev_edges, gx, gy, layer_idx):\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "    xmin, ymin = positions.min(axis=0); xmax, ymax = positions.max(axis=0)\n",
    "    cell_w = (xmax - xmin) / gx if gx > 0 else 1.0\n",
    "    cell_h = (ymax - ymin) / gy if gy > 0 else 1.0\n",
    "    if cell_w == 0: cell_w = 1.0\n",
    "    if cell_h == 0: cell_h = 1.0\n",
    "    cell_map = {}\n",
    "    for idx, n in enumerate(prev_nodes):\n",
    "        x, y = n[\"position\"][\"x\"], n[\"position\"][\"y\"]\n",
    "        cx = min(int((x - xmin) / cell_w), gx - 1)\n",
    "        cy = min(int((y - ymin) / cell_h), gy - 1)\n",
    "        cid = cx + cy * gx\n",
    "        cell_map.setdefault(cid, []).append(idx)\n",
    "    super_nodes, node_map = [], {}\n",
    "    for cid, indices in cell_map.items():\n",
    "        pts = positions[indices]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in indices]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in indices]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums))\n",
    "        nid = str(len(super_nodes))\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val   # Inherit the sum\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        for i in indices:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            elif su == sv:\n",
    "                eid = tuple(sorted((su, \"prior\")))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = tuple(sorted((su, \"prior\")))\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "# -----------------------\n",
    "# K-Means aggregation\n",
    "# -----------------------\n",
    "def fuse_to_super_kmeans(prev_nodes, prev_edges, k, layer_idx, max_iters=20, tol=1e-6, seed=0):\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "    n = positions.shape[0]\n",
    "    if k <= 0: \n",
    "        k = 1\n",
    "    k = min(k, n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # -------- Improved initialization --------\n",
    "    # Randomly sample k points without replacement to ensure each cluster starts with a distinct point\n",
    "    init_idx = rng.choice(n, size=k, replace=False)\n",
    "    centers = positions[init_idx]\n",
    "\n",
    "    # Lloyd iterations\n",
    "    for _ in range(max_iters):\n",
    "        d2 = ((positions[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)\n",
    "        assign = np.argmin(d2, axis=1)\n",
    "\n",
    "        # -------- Empty-cluster fix --------\n",
    "        counts = np.bincount(assign, minlength=k)\n",
    "        empty_clusters = np.where(counts == 0)[0]\n",
    "        for ci in empty_clusters:\n",
    "            # Find the largest cluster\n",
    "            big_cluster = np.argmax(counts)\n",
    "            big_idxs = np.where(assign == big_cluster)[0]\n",
    "            # Steal one point over\n",
    "            steal_idx = big_idxs[0]\n",
    "            assign[steal_idx] = ci\n",
    "            counts[big_cluster] -= 1\n",
    "            counts[ci] += 1\n",
    "\n",
    "        moved = 0.0\n",
    "        for ci in range(k):\n",
    "            idxs = np.where(assign == ci)[0]\n",
    "            new_c = positions[idxs].mean(axis=0)\n",
    "            moved = max(moved, float(np.linalg.norm(new_c - centers[ci])))\n",
    "            centers[ci] = new_c\n",
    "        if moved < tol:\n",
    "            break\n",
    "\n",
    "    # Final assign (redo once to be safe)\n",
    "    d2 = ((positions[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)\n",
    "    assign = np.argmin(d2, axis=1)\n",
    "\n",
    "    counts = np.bincount(assign, minlength=k)\n",
    "    empty_clusters = np.where(counts == 0)[0]\n",
    "    for ci in empty_clusters:\n",
    "        big_cluster = np.argmax(counts)\n",
    "        big_idxs = np.where(assign == big_cluster)[0]\n",
    "        steal_idx = big_idxs[0]\n",
    "        assign[steal_idx] = ci\n",
    "        counts[big_cluster] -= 1\n",
    "        counts[ci] += 1\n",
    "\n",
    "    # ---------- Build the super graph ----------\n",
    "    super_nodes, node_map = [], {}\n",
    "    for ci in range(k):\n",
    "        idxs = np.where(assign == ci)[0]\n",
    "        pts = positions[idxs]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in idxs]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in idxs]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums)) \n",
    "        nid = f\"{ci}\"\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val   # Inherit the sum\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        for i in idxs:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            else:\n",
    "                eid = (su, \"prior\")\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = (su, \"prior\")\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "\n",
    "def copy_to_abs(super_nodes, super_edges, layer_idx):\n",
    "    abs_nodes = []\n",
    "    for n in super_nodes:\n",
    "        nid = n[\"data\"][\"id\"].replace(\"s\", \"a\", 1)\n",
    "        abs_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": n[\"data\"][\"dim\"],\n",
    "                \"num_base\": n[\"data\"].get(\"num_base\", 1)  # Inherit\n",
    "            },\n",
    "            \"position\": {\"x\": n[\"position\"][\"x\"], \"y\": n[\"position\"][\"y\"]}\n",
    "        })\n",
    "    abs_edges = []\n",
    "    for e in super_edges:\n",
    "        abs_edges.append({\"data\": {\n",
    "            \"source\": e[\"data\"][\"source\"].replace(\"s\", \"a\", 1),\n",
    "            \"target\": e[\"data\"][\"target\"].replace(\"s\", \"a\", 1)\n",
    "        }})\n",
    "    return abs_nodes, abs_edges\n",
    "\n",
    "# -----------------------\n",
    "# Sequential merge (tail group absorbs remainder)\n",
    "# -----------------------\n",
    "def fuse_to_super_order(prev_nodes, prev_edges, k, layer_idx, tail_heavy=True):\n",
    "    \"\"\"\n",
    "    Sequentially split prev_nodes in current order into k groups; the last group absorbs the remainder (tail_heavy=True).\n",
    "    Reuse existing rules for aggregating dim/num_base, deduplicating edges, and propagating prior.\n",
    "    \"\"\"\n",
    "    n = len(prev_nodes)\n",
    "    if k <= 0: k = 1\n",
    "    k = min(k, n)\n",
    "\n",
    "    # Group sizes\n",
    "    base = n // k\n",
    "    rem  = n %  k\n",
    "    if rem > 0:\n",
    "        sizes = [k]*(base) + [rem]     # Tail absorbs remainder: ..., last += rem\n",
    "    else:\n",
    "        sizes = [k]*(base)\n",
    "\n",
    "    # Build groups: record indices per group\n",
    "    groups = []\n",
    "    start = 0\n",
    "    for s in sizes:\n",
    "        groups.append(list(range(start, start+s)))\n",
    "        start += s\n",
    "\n",
    "    # ---- Build super_nodes & node_map ----\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "\n",
    "    super_nodes, node_map = [], {}\n",
    "    for gi, idxs in enumerate(groups):\n",
    "        pts = positions[idxs]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in idxs]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in idxs]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums))\n",
    "\n",
    "        nid = f\"{gi}\"  # Same as kmeans: use group index as id (string)\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        # Build base-id -> super-id mapping (note: ids are strings throughout)\n",
    "        for i in idxs:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "\n",
    "    # ---- Super edges: keep and deduplicate inter-group edges; intra-group edges collapse to prior; prior edges roll up to their owning super ----\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            else:\n",
    "                # Intra-group pairwise edge → group prior (consistent with grid/kmeans handling)\n",
    "                eid = tuple(sorted((su, \"prior\")))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = tuple(sorted((su, \"prior\")))\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Tools\n",
    "# -----------------------\n",
    "def parse_layer_name(name):\n",
    "    if name == \"base\": return (\"base\", 0)\n",
    "    m = re.match(r\"(super|abs)(\\d+)$\", name)\n",
    "    return (m.group(1), int(m.group(2))) if m else (\"base\", 0)\n",
    "\n",
    "def highest_pair_idx(names):\n",
    "    hi = 0\n",
    "    for nm in names:\n",
    "        kind, k = parse_layer_name(nm)\n",
    "        if kind in (\"super\",\"abs\"): hi = max(hi, k)\n",
    "    return hi\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Initialization & Boundary\n",
    "# -----------------------\n",
    "def init_layers(N=100, step_size=25, loop_prob=0.05, loop_radius=50, prior_prop=0.0, seed=None):\n",
    "    base_nodes, base_edges = make_slam_like_graph(N, step_size, loop_prob, loop_radius, prior_prop, seed)\n",
    "    return [{\"name\": \"base\", \"nodes\": base_nodes, \"edges\": base_edges}]\n",
    "\n",
    "VIEW_W, VIEW_H = 960, 600\n",
    "ASPECT = VIEW_W / VIEW_H\n",
    "AXIS_PAD=20.0\n",
    "# ==== Blobal Status ====\n",
    "layers = init_layers()\n",
    "\n",
    "\n",
    "def adjust_bounds_to_aspect(xmin, xmax, ymin, ymax, aspect):\n",
    "    cx=(xmin+xmax)/2; cy=(ymin+ymax)/2\n",
    "    dx=xmax-xmin; dy=ymax-ymin\n",
    "    if dx<=0: dx=1\n",
    "    if dy<=0: dy=1\n",
    "    if dx/dy > aspect:\n",
    "        dy_new=dx/aspect\n",
    "        return xmin,xmax,cy-dy_new/2,cy+dy_new/2\n",
    "    else:\n",
    "        dx_new=dy*aspect\n",
    "        return cx-dx_new/2,cx+dx_new/2,ymin,ymax\n",
    "\n",
    "def reset_global_bounds(base_nodes):\n",
    "    global GLOBAL_XMIN, GLOBAL_XMAX, GLOBAL_YMIN, GLOBAL_YMAX\n",
    "    global GLOBAL_XMIN_ADJ, GLOBAL_XMAX_ADJ, GLOBAL_YMIN_ADJ, GLOBAL_YMAX_ADJ\n",
    "    xs=[n[\"position\"][\"x\"] for n in base_nodes] or [0.0]\n",
    "    ys=[n[\"position\"][\"y\"] for n in base_nodes] or [0.0]\n",
    "    GLOBAL_XMIN,GLOBAL_XMAX=min(xs),max(xs)\n",
    "    GLOBAL_YMIN,GLOBAL_YMAX=min(ys),max(ys)\n",
    "    GLOBAL_XMIN_ADJ,GLOBAL_XMAX_ADJ,GLOBAL_YMIN_ADJ,GLOBAL_YMAX_ADJ=adjust_bounds_to_aspect(\n",
    "        GLOBAL_XMIN,GLOBAL_XMAX,GLOBAL_YMIN,GLOBAL_YMAX,ASPECT)\n",
    "\n",
    "# ==== Blobal Status ====\n",
    "layers = init_layers()\n",
    "pair_idx = 0\n",
    "reset_global_bounds(layers[0][\"nodes\"])\n",
    "gbp_graph = None\n",
    "\n",
    "# -----------------------\n",
    "# GBP Graph Construction\n",
    "# -----------------------\n",
    "def build_noisy_pose_graph(\n",
    "    nodes,\n",
    "    edges,\n",
    "    prior_sigma: float = 10,\n",
    "    odom_sigma: float = 10,\n",
    "    tiny_prior: float = 1e-12,\n",
    "    seed=None,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Construct a 2D pose-only factor graph (linear, Gaussian) and inject noise.\n",
    "    Parameters:\n",
    "      prior_sigma : standard deviation of the strong prior (smaller = stronger)\n",
    "      odom_sigma  : standard deviation of odometry measurement noise\n",
    "      prior_prop  : 0.0 = anchor only; (0,1) = randomly select by proportion; >=1.0 = all\n",
    "      tiny_prior  : a tiny prior added to all nodes to prevent singularity\n",
    "      seed        : random seed (for reproducibility)\n",
    "    \"\"\"\n",
    "\n",
    "    fg = FactorGraph(nonlinear_factors=False, eta_damping=0)\n",
    "\n",
    "    var_nodes = []\n",
    "    I2 = np.eye(2, dtype=float)\n",
    "    N = len(nodes)\n",
    "\n",
    "    # ---- Pre-generate noise ----\n",
    "    prior_noises = {}\n",
    "    odom_noises = {}\n",
    "\n",
    "    if seed is None:\n",
    "        rng = np.random.default_rng()\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Generate noise for all edges\n",
    "    for e in edges:\n",
    "        src = e[\"data\"][\"source\"]; dst = e[\"data\"][\"target\"]\n",
    "        # Binary edge\n",
    "        if (dst != \"prior\") and (dst != \"anchor\"):\n",
    "            odom_noises[(int(src[:]), int(dst[:]))] = rng.normal(0.0, odom_sigma, size=2)\n",
    "        # Unary edge (strong prior)\n",
    "        elif dst == \"prior\":\n",
    "            prior_noises[int(src[:])] = rng.normal(0.0, prior_sigma, size=2)\n",
    "\n",
    "\n",
    "    # ---- variable nodes ----\n",
    "    for i, n in enumerate(nodes):\n",
    "        v = VariableNode(i, dofs=2)\n",
    "        v.GT = np.array([n[\"position\"][\"x\"], n[\"position\"][\"y\"]], dtype=float)\n",
    "\n",
    "        # Tiny prior\n",
    "        v.prior.lam = tiny_prior * I2\n",
    "        v.prior.eta = np.zeros(2, dtype=float)\n",
    "\n",
    "        var_nodes.append(v)\n",
    "\n",
    "    fg.var_nodes = var_nodes\n",
    "    fg.n_var_nodes = len(var_nodes)\n",
    "\n",
    "\n",
    "    # ---- prior factors ----\n",
    "    def meas_fn_unary(x, *args):\n",
    "        return [x]\n",
    "    def jac_fn_unary(x, *args):\n",
    "        return [np.eye(2)]\n",
    "    # ---- odometry factors ----\n",
    "    def meas_fn(xy, *args):\n",
    "        return [xy[2:] - xy[:2]]\n",
    "    def jac_fn(xy, *args):\n",
    "        return [np.array([[-1, 0, 1, 0],\n",
    "                         [ 0,-1, 0, 1]], dtype=float)]\n",
    "    \n",
    "    factors = []\n",
    "    fid = 0\n",
    "\n",
    "    for e in edges:\n",
    "        src = e[\"data\"][\"source\"]; dst = e[\"data\"][\"target\"]\n",
    "        if (dst != \"prior\") and (dst != \"anchor\"):\n",
    "            i, j = int(src[:]), int(dst[:])\n",
    "            vi, vj = var_nodes[i], var_nodes[j]\n",
    "\n",
    "            meas = (vj.GT - vi.GT) + odom_noises[(i, j)]\n",
    "\n",
    "            meas_lambda = np.eye(len(meas))/ (odom_sigma**2)\n",
    "            f = Factor(fid, [vi, vj], [meas], [meas_lambda], meas_fn, jac_fn)\n",
    "            f.type = \"base\"\n",
    "            linpoint = np.r_[vi.GT, vj.GT]\n",
    "            f.compute_factor(linpoint=linpoint, update_self=True)\n",
    "\n",
    "            factors.append(f)\n",
    "            vi.adj_factors.append(f)\n",
    "            vj.adj_factors.append(f)\n",
    "            fid += 1\n",
    "\n",
    "        elif dst == \"prior\":\n",
    "            i = int(src[:])\n",
    "            vi = var_nodes[i]\n",
    "            z = vi.GT + prior_noises[i]\n",
    "\n",
    "            z_lambda = np.eye(len(meas))/ (prior_sigma**2)\n",
    "            f = Factor(fid, [vi], [z], [z_lambda], meas_fn_unary, jac_fn_unary)\n",
    "            f.type = \"prior\"\n",
    "            f.compute_factor(linpoint=z, update_self=True)\n",
    "\n",
    "            factors.append(f)\n",
    "            vi.adj_factors.append(f)\n",
    "            fid += 1\n",
    "\n",
    "    # anchor for initial position\n",
    "    v0 = var_nodes[0]\n",
    "    z = v0.GT\n",
    "\n",
    "    z_lambda = np.eye(len(meas))/ ((1e-4)**2)\n",
    "    f = Factor(fid, [v0], [z], [z_lambda], meas_fn_unary, jac_fn_unary)\n",
    "    f.type = \"prior\"\n",
    "    f.compute_factor(linpoint=z, update_self=True)\n",
    "\n",
    "    factors.append(f)\n",
    "    v0.adj_factors.append(f)\n",
    "    fid += 1\n",
    "\n",
    "    fg.factors = factors\n",
    "    fg.n_factor_nodes = len(factors)\n",
    "    return fg\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "def build_super_graph(layers, eta_damping=0.4):\n",
    "    \"\"\"\n",
    "    首次构建 super graph，固定结构 & closure。\n",
    "    之后不要再重建，用 bottom_up_modify_super_graph 只更新数值。\n",
    "    \"\"\"\n",
    "    # ---------- Extract base & super ----------\n",
    "    base_graph  = layers[-2][\"graph\"]\n",
    "    super_nodes = layers[-1][\"nodes\"]\n",
    "    super_edges = layers[-1][\"edges\"]\n",
    "    node_map    = layers[-1][\"node_map\"]   # 'bN' -> 'sX_...'\n",
    "\n",
    "    # base: id(int) -> VariableNode\n",
    "    id2var = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    # ---------- super_id -> [base_id(int)] ----------\n",
    "    super_groups = {}\n",
    "    for b_str, s_id in node_map.items():\n",
    "        b_int = int(b_str)\n",
    "        super_groups.setdefault(s_id, []).append(b_int)\n",
    "\n",
    "    # ---------- 对每个 super group 建 (start, dofs) 表 ----------\n",
    "    # local_idx[sid][bid] = (start, dofs), total_dofs[sid] = sum(dofs)\n",
    "    local_idx   = {}\n",
    "    total_dofs  = {}\n",
    "    for sid, group in super_groups.items():\n",
    "        off = 0\n",
    "        local_idx[sid] = {}\n",
    "        for bid in group:\n",
    "            d = id2var[bid].dofs\n",
    "            local_idx[sid][bid] = (off, d)\n",
    "            off += d\n",
    "        total_dofs[sid] = off\n",
    "\n",
    "    # ============ 预计算：哪些 base factors 属于哪个 super group / pair ============\n",
    "\n",
    "    def precompute_super_factor_maps(base_graph, node_map, super_groups):\n",
    "        # in_group：super_id -> [fid, ...]\n",
    "        group2factors_allin = { sid: [] for sid in super_groups }\n",
    "\n",
    "        # cross： (sidA, sidB) (ordered) -> [fid, ...]\n",
    "        pairgroups2factors  = defaultdict(list)\n",
    "\n",
    "        for fid, f in enumerate(base_graph.factors):\n",
    "            vids = [v.variableID for v in f.adj_var_nodes]\n",
    "\n",
    "            # unary factor\n",
    "            if len(vids) == 1:\n",
    "                bid = vids[0]\n",
    "                sid = node_map[str(bid)]\n",
    "                group2factors_allin[sid].append(fid)\n",
    "                continue\n",
    "\n",
    "            # binary factor\n",
    "            if len(vids) == 2:\n",
    "                i, j = vids\n",
    "                si, sj = node_map[str(i)], node_map[str(j)]\n",
    "                if si == sj:\n",
    "                    group2factors_allin[si].append(fid)\n",
    "                else:\n",
    "                    key = (si, sj) if si < sj else (sj, si)\n",
    "                    pairgroups2factors[key].append(fid)\n",
    "                continue\n",
    "\n",
    "            # 更高阶 factor 需要时再扩展\n",
    "        return group2factors_allin, pairgroups2factors\n",
    "\n",
    "    group2factors_allin, pairgroups2factors = precompute_super_factor_maps(\n",
    "        base_graph, node_map, super_groups\n",
    "    )\n",
    "\n",
    "    # 把这些结构性信息存到 layer 里，方便后续 in-place 更新使用\n",
    "    layer = layers[-1]\n",
    "    layer[\"super_groups\"]          = super_groups\n",
    "    layer[\"local_idx\"]             = local_idx\n",
    "    layer[\"total_dofs\"]            = total_dofs\n",
    "    layer[\"group2factors_allin\"]   = group2factors_allin\n",
    "    layer[\"pairgroups2factors\"]    = pairgroups2factors\n",
    "\n",
    "    # ---------- 创建 super VariableNodes（只做一次） ----------\n",
    "    fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "\n",
    "    super_var_nodes = {}   # sid(str) -> VariableNode\n",
    "    for i, sn in enumerate(super_nodes):\n",
    "        sid  = sn[\"data\"][\"id\"]\n",
    "        dofs = total_dofs.get(sid, 0)\n",
    "\n",
    "        v = VariableNode(i, dofs=dofs)\n",
    "        gt_vec = np.zeros(dofs)\n",
    "        mu_blocks    = []\n",
    "        Sigma_blocks = []\n",
    "\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            # Stack base GT\n",
    "            gt_base = getattr(id2var[bid], \"GT\", None)\n",
    "            if gt_base is None or len(gt_base) != d:\n",
    "                gt_base = np.zeros(d)\n",
    "            gt_vec[st:st+d] = gt_base\n",
    "\n",
    "            # Stack base belief\n",
    "            vb = id2var[bid]\n",
    "            mu_blocks.append(vb.mu)\n",
    "            Sigma_blocks.append(vb.Sigma)\n",
    "\n",
    "        super_var_nodes[sid] = v\n",
    "        v.GT = gt_vec\n",
    "\n",
    "        mu_super    = np.concatenate(mu_blocks) if mu_blocks else np.zeros(dofs)\n",
    "        Sigma_super = block_diag(*Sigma_blocks) if Sigma_blocks else np.eye(dofs)\n",
    "        lam = np.linalg.inv(Sigma_super)\n",
    "        eta = lam @ mu_super\n",
    "        v.mu     = mu_super\n",
    "        v.Sigma  = Sigma_super\n",
    "        v.belief = NdimGaussian(dofs, eta, lam)\n",
    "        v.prior.lam = 1e-12 * lam\n",
    "        v.prior.eta = 1e-12 * eta\n",
    "\n",
    "        fg.var_nodes.append(v)\n",
    "\n",
    "    fg.n_var_nodes = len(fg.var_nodes)\n",
    "\n",
    "    # ---------- Utility: 组装一个 super group 的 linpoint（用 base belief means） ----------\n",
    "    def make_linpoint_for_group(sid):\n",
    "        x = np.zeros(total_dofs[sid])\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            mu = getattr(id2var[bid], \"mu\", None)\n",
    "            if mu is None or len(mu) != d:\n",
    "                mu = np.zeros(d)\n",
    "            x[st:st+d] = mu\n",
    "        return x\n",
    "\n",
    "    # 把这些辅助对象也挂到 layer 上，后面可以复用\n",
    "    layer[\"super_var_nodes\"]         = super_var_nodes\n",
    "    layer[\"make_linpoint_for_group\"] = make_linpoint_for_group\n",
    "\n",
    "    # ---------- 3) super prior（in-group unary + in-group binary） ----------\n",
    "    def make_super_prior_factor(sid):\n",
    "        idx_map = local_idx[sid]\n",
    "        ncols   = total_dofs[sid]\n",
    "\n",
    "        factor_ids = group2factors_allin[sid]\n",
    "        in_group   = [base_graph.factors[fid] for fid in factor_ids]\n",
    "\n",
    "        def meas_fn_super_prior(x_super, *args):\n",
    "            meas_fn = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "\n",
    "                x_loc_list = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "                meas_fn.extend(f.meas_fn(x_loc))\n",
    "            return meas_fn if meas_fn else np.zeros(0)\n",
    "\n",
    "        def jac_fn_super_prior(x_super, *args):\n",
    "            Jrows = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "\n",
    "                x_loc_list = []\n",
    "                dims = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    dims.append(d)\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "\n",
    "                Jloc  = f.jac_fn(x_loc)\n",
    "                lens  = [J.shape[0] for J in Jloc]\n",
    "                Jlocs = np.vstack(Jloc)\n",
    "\n",
    "                rows = np.zeros((Jlocs.shape[0], ncols))\n",
    "                c0 = 0\n",
    "                for vid, d in zip(vids, dims):\n",
    "                    st, _ = idx_map[vid]\n",
    "                    rows[:, st:st+d] = Jlocs[:, c0:c0+d]\n",
    "                    c0 += d\n",
    "                cuts = np.cumsum(lens)[:-1]\n",
    "                rows = np.split(rows, cuts, axis=0)\n",
    "                Jrows.extend(rows)\n",
    "            return Jrows if Jrows else np.zeros((0, ncols))\n",
    "\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "        for f in in_group:\n",
    "            ext_z(f.measurement)\n",
    "            ext_l(f.measurement_lambda)\n",
    "\n",
    "        return meas_fn_super_prior, jac_fn_super_prior, z_super, z_super_lambda\n",
    "\n",
    "    # ---------- 4) super between（cross-group binary） ----------\n",
    "    def make_super_between_factor(sidA, sidB):\n",
    "        groupA, groupB = super_groups[sidA], super_groups[sidB]\n",
    "        idxA, idxB     = local_idx[sidA], local_idx[sidB]\n",
    "        nA, nB         = total_dofs[sidA], total_dofs[sidB]\n",
    "\n",
    "        key = (sidA, sidB) if sidA < sidB else (sidB, sidA)\n",
    "        factor_ids = pairgroups2factors.get(key, [])\n",
    "        cross = [base_graph.factors[fid] for fid in factor_ids]\n",
    "\n",
    "        def meas_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            meas_fn = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                meas_fn.extend(f.meas_fn(x_loc))\n",
    "            return meas_fn\n",
    "\n",
    "        def jac_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            Jrows = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                    left_start, right_start = si, nA + sj\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                    left_start, right_start = nA + si, sj\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                Jloc = f.jac_fn(x_loc)\n",
    "\n",
    "                lens  = [J.shape[0] for J in Jloc]\n",
    "                cuts  = np.cumsum(lens)[:-1]\n",
    "                Jlocs = np.vstack(Jloc)\n",
    "                rows  = np.zeros((Jlocs.shape[0], nA + nB))\n",
    "                rows[:, left_start:left_start+di]  = Jlocs[:, :di]\n",
    "                rows[:, right_start:right_start+dj] = Jlocs[:, di:di+dj]\n",
    "                rows = np.split(rows, cuts, axis=0)\n",
    "                Jrows.extend(rows)\n",
    "            return Jrows\n",
    "\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "        for f in cross:\n",
    "            ext_z(f.measurement)\n",
    "            ext_l(f.measurement_lambda)\n",
    "\n",
    "        return meas_fn_super_between, jac_fn_super_between, z_super, z_super_lambda\n",
    "\n",
    "    # ---------- 5) 按 super_edges 建所有 factors（只做一次） ----------\n",
    "    for e in super_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if v == \"prior\":\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_prior_factor(u)\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_prior\"\n",
    "            lin0 = make_linpoint_for_group(u)\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "        else:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_between_factor(u, v)\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u], super_var_nodes[v]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_between\"\n",
    "            lin0 = np.concatenate([make_linpoint_for_group(u), make_linpoint_for_group(v)])\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "            super_var_nodes[v].adj_factors.append(f)\n",
    "\n",
    "    fg.n_factor_nodes = len(fg.factors)\n",
    "\n",
    "    # 记得在外面：layers[-1][\"graph\"] = fg\n",
    "    return fg\n",
    "\n",
    "\n",
    "\n",
    "def build_abs_graph(\n",
    "    layers,\n",
    "    r_reduced = 2,\n",
    "    eta_damping=0.4):\n",
    "\n",
    "    abs_var_nodes = {}\n",
    "    Bs = {}\n",
    "    ks = {}\n",
    "    k2s = {}\n",
    "\n",
    "    # === 1. Build Abstraction Variables ===\n",
    "    abs_fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "    sup_fg = layers[-2][\"graph\"]\n",
    "\n",
    "    for sn in sup_fg.var_nodes:\n",
    "        if sn.dofs <= r_reduced:\n",
    "            r = sn.dofs\n",
    "        else:\n",
    "            r = r_reduced\n",
    "\n",
    "        sid = sn.variableID\n",
    "        varis_sup_mu    = sn.mu\n",
    "        varis_sup_sigma = sn.Sigma\n",
    "\n",
    "        # eig 分解\n",
    "        eigvals, eigvecs = np.linalg.eigh(varis_sup_sigma)\n",
    "        idx     = np.argsort(eigvals)[::-1]\n",
    "        eigvecs = eigvecs[:, idx]\n",
    "\n",
    "        # B_reduced: (d_sup, r)\n",
    "        B_reduced = eigvecs[:, :r]\n",
    "        Bs[sid]   = B_reduced\n",
    "\n",
    "        # 投影\n",
    "        varis_abs_mu    = B_reduced.T @ varis_sup_mu\n",
    "        varis_abs_sigma = B_reduced.T @ varis_sup_sigma @ B_reduced\n",
    "        ks[sid]         = varis_sup_mu - B_reduced @ varis_abs_mu\n",
    "\n",
    "        varis_abs_lam = np.linalg.inv(varis_abs_sigma)\n",
    "        varis_abs_eta = varis_abs_lam @ varis_abs_mu\n",
    "\n",
    "        v = VariableNode(sid, dofs=r)\n",
    "        v.GT     = sn.GT\n",
    "        v.mu     = varis_abs_mu\n",
    "        v.Sigma  = varis_abs_sigma\n",
    "        v.belief = NdimGaussian(r, varis_abs_eta, varis_abs_lam)\n",
    "\n",
    "        abs_var_nodes[sid] = v\n",
    "        abs_fg.var_nodes.append(v)\n",
    "\n",
    "    abs_fg.n_var_nodes = len(abs_fg.var_nodes)\n",
    "\n",
    "    # === 2. Abstract Prior ===\n",
    "    def make_abs_prior_factor(sup_factor):\n",
    "        sid = sup_factor.adj_var_nodes[0].variableID  # super 变量 ID\n",
    "\n",
    "        def meas_fn_abs_prior(x_abs, *args):\n",
    "            B = Bs[sid]\n",
    "            k = ks[sid]\n",
    "            return sup_factor.meas_fn(B @ x_abs + k)\n",
    "        \n",
    "        def jac_fn_abs_prior(x_abs, *args):\n",
    "            B = Bs[sid]\n",
    "            k = ks[sid]\n",
    "            Jloc = sup_factor.jac_fn(B @ x_abs + k)\n",
    "            lens = [J.shape[0] for J in Jloc]\n",
    "            cuts = np.cumsum(lens)[:-1]\n",
    "            return np.split(np.vstack(Jloc) @ B, cuts, axis=0)\n",
    "\n",
    "        return meas_fn_abs_prior, jac_fn_abs_prior, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "\n",
    "    # === 3. Abstract Between ===\n",
    "    def make_abs_between_factor(sup_factor):\n",
    "        vids = [v.variableID for v in sup_factor.adj_var_nodes]\n",
    "        i, j = vids\n",
    "        ni   = abs_var_nodes[i].dofs\n",
    "\n",
    "        def meas_fn_abs_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            Bi, Bj = Bs[i], Bs[j]\n",
    "            ki, kj = ks[i], ks[j]\n",
    "            return sup_factor.meas_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "\n",
    "        def jac_fn_abs_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            Bi, Bj = Bs[i], Bs[j]\n",
    "            ki, kj = ks[i], ks[j]\n",
    "\n",
    "            J_sup = sup_factor.jac_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "            lens  = [J.shape[0] for J in J_sup]\n",
    "            cuts  = np.cumsum(lens)[:-1]\n",
    "            J_sup = np.vstack(J_sup)\n",
    "\n",
    "            J_abs = np.zeros((J_sup.shape[0], ni + xj.shape[0]))\n",
    "            J_abs[:, :ni] = J_sup[:, :Bi.shape[0]] @ Bi\n",
    "            J_abs[:, ni:] = J_sup[:, Bi.shape[0]:] @ Bj\n",
    "            return np.split(J_abs, cuts, axis=0)\n",
    "\n",
    "        return meas_fn_abs_between, jac_fn_abs_between, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "\n",
    "    # === 4. 构建所有 abs factors（只做一次） ===\n",
    "    for f in sup_fg.factors:\n",
    "        if len(f.adj_var_nodes) == 1:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_prior_factor(f)\n",
    "            v_id = f.adj_var_nodes[0].variableID\n",
    "            v    = abs_var_nodes[v_id]\n",
    "\n",
    "            abs_f = Factor(f.factorID, [v], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_prior\"\n",
    "            abs_f.adj_beliefs = [v.belief]\n",
    "\n",
    "            lin0 = v.mu\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            v.adj_factors.append(abs_f)\n",
    "\n",
    "        elif len(f.adj_var_nodes) == 2:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_between_factor(f)\n",
    "            i, j   = [v.variableID for v in f.adj_var_nodes]\n",
    "            vi, vj = abs_var_nodes[i], abs_var_nodes[j]\n",
    "\n",
    "            abs_f = Factor(f.factorID, [vi, vj], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_between\"\n",
    "            abs_f.adj_beliefs = [vi.belief, vj.belief]\n",
    "\n",
    "            lin0 = np.concatenate([vi.mu, vj.mu])\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            vi.adj_factors.append(abs_f)\n",
    "            vj.adj_factors.append(abs_f)\n",
    "\n",
    "    abs_fg.n_factor_nodes = len(abs_fg.factors)\n",
    "\n",
    "    return abs_fg, Bs, ks, k2s\n",
    "\n",
    "\n",
    "def bottom_up_modify_abs_graph(\n",
    "    layers,\n",
    "    r_reduced = 2,\n",
    "    eta_damping=0.4):\n",
    "    \"\"\"\n",
    "    In-place 更新 abs 层：\n",
    "      - 更新 Bs, ks\n",
    "      - 更新 abs_fg.var_nodes 的 mu, Sigma, belief\n",
    "      - 如需要，对 abs_fg.factors 重新 compute_factor\n",
    "    不再 new FactorGraph / new Factor。\n",
    "    \"\"\"\n",
    "\n",
    "    abs_layer = layers[-1]\n",
    "    abs_fg    = abs_layer[\"graph\"]\n",
    "    abs_fg.eta_damping = eta_damping\n",
    "    sup_fg    = layers[-2][\"graph\"]\n",
    "\n",
    "    # 复用原有的 Bs/ks（如果你也想更新 B，可以在这里重新算）\n",
    "    Bs = abs_layer[\"Bs\"]\n",
    "    ks = abs_layer[\"ks\"]\n",
    "\n",
    "    # === 1. 更新每个 abs 变量的投影 ===\n",
    "    for sn in sup_fg.var_nodes:\n",
    "        if sn.dofs <= r_reduced:\n",
    "            r = sn.dofs\n",
    "        else:\n",
    "            r = r_reduced\n",
    "\n",
    "        sid = sn.variableID\n",
    "        varis_sup_mu    = sn.mu\n",
    "        varis_sup_sigma = sn.Sigma\n",
    "\n",
    "        # 这里有两种选择：\n",
    "        #  A) 子空间固定：使用旧的 B（推荐，便宜）\n",
    "        B_reduced = Bs[sid]\n",
    "\n",
    "        #  B) 子空间随 covariance 变化：每次重新 eig（贵很多）\n",
    "        # eigvals, eigvecs = np.linalg.eigh(varis_sup_sigma)\n",
    "        # idx     = np.argsort(eigvals)[::-1]\n",
    "        # eigvecs = eigvecs[:, idx]\n",
    "        # B_reduced = eigvecs[:, :r]\n",
    "        # Bs[sid]   = B_reduced\n",
    "\n",
    "        varis_abs_mu    = B_reduced.T @ varis_sup_mu\n",
    "        varis_abs_sigma = B_reduced.T @ varis_sup_sigma @ B_reduced\n",
    "        ks[sid]         = varis_sup_mu - B_reduced @ varis_abs_mu\n",
    "\n",
    "        varis_abs_lam = np.linalg.inv(varis_abs_sigma)\n",
    "        varis_abs_eta = varis_abs_lam @ varis_abs_mu\n",
    "\n",
    "        v = abs_fg.var_nodes[sid]   # 结构不变，直接拿旧节点\n",
    "        v.mu     = varis_abs_mu\n",
    "        v.Sigma  = varis_abs_sigma\n",
    "        v.belief = NdimGaussian(r, varis_abs_eta, varis_abs_lam)\n",
    "\n",
    "    abs_fg.n_var_nodes = len(abs_fg.var_nodes)\n",
    "\n",
    "    # === 2. 如需重新线性化 abs factors（可选但通常是需要的） ===\n",
    "    for f in abs_fg.factors:\n",
    "        lin0 = np.concatenate([v.mu for v in f.adj_var_nodes])\n",
    "        f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "    # Bs, ks 已在 dict 中更新，closure 会自动看到新值\n",
    "    abs_layer[\"Bs\"] = Bs\n",
    "    abs_layer[\"ks\"] = ks\n",
    "    # abs_layer[\"k2s\"] = k2s\n",
    "\n",
    "    return \n",
    "\n",
    "def bottom_up_modify_super_graph(layers, eta_damping=0.4):\n",
    "    \"\"\"\n",
    "    In-place 更新 super graph：\n",
    "      - 从 base_graph 更新 super var 的 mu / Sigma / belief\n",
    "      - 不再重建 FactorGraph / Factor / VariableNode。\n",
    "      - 不再对 big Σ 做 np.linalg.inv，而是复用 base belief 的 (η, Λ) 做 block_diag。\n",
    "    \"\"\"\n",
    "    t_total_start = time.perf_counter()\n",
    "\n",
    "    base_graph = layers[-2][\"graph\"]\n",
    "    layer      = layers[-1]\n",
    "\n",
    "    super_nodes      = layer[\"nodes\"]\n",
    "    node_map         = layer[\"node_map\"]\n",
    "    super_fg         = layer[\"graph\"]\n",
    "    super_groups     = layer[\"super_groups\"]\n",
    "    local_idx        = layer[\"local_idx\"]\n",
    "    total_dofs       = layer[\"total_dofs\"]\n",
    "    super_var_nodes  = layer[\"super_var_nodes\"]   # sid(str) -> VariableNode\n",
    "\n",
    "    # ---------- 0) 构建 id2var ----------\n",
    "    id2var = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    # ---------- 1) 更新每个 super variable 的 mu / Sigma / belief ----------\n",
    "    for sn in super_nodes:\n",
    "        sid  = sn[\"data\"][\"id\"]\n",
    "        v    = super_var_nodes[sid]\n",
    "        dofs = total_dofs[sid]\n",
    "\n",
    "        gt_vec = np.zeros(dofs)\n",
    "\n",
    "        mu_blocks    = []\n",
    "        Sigma_blocks = []\n",
    "        lam_blocks   = []\n",
    "        eta_blocks   = []\n",
    "\n",
    "        # ---- 1.1 收集 base 节点信息 ----\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            vb = id2var[bid]\n",
    "\n",
    "            # GT\n",
    "            gt_base = getattr(vb, \"GT\", None)\n",
    "            if gt_base is None or len(gt_base) != d:\n",
    "                gt_base = np.zeros(d)\n",
    "            gt_vec[st:st+d] = gt_base\n",
    "\n",
    "            # belief / covariance\n",
    "            mu_blocks.append(vb.mu)           # shape (d,)\n",
    "            Sigma_blocks.append(vb.Sigma)     # shape (d,d)\n",
    "\n",
    "            # 直接复用 base 的 η, Λ，避免在 super 层重新求逆\n",
    "            lam_blocks.append(vb.belief.lam)  # shape (d,d)\n",
    "            eta_blocks.append(vb.belief.eta)  # shape (d,)\n",
    "        v.GT = gt_vec\n",
    "\n",
    "        # ---- 1.2 block_diag + concat ----\n",
    "        mu_super    = np.concatenate(mu_blocks)      if mu_blocks    else np.zeros(dofs)\n",
    "        Sigma_super = block_diag(*Sigma_blocks)      if Sigma_blocks else np.eye(dofs)\n",
    "        lam_super   = block_diag(*lam_blocks)        if lam_blocks   else np.eye(dofs)\n",
    "        eta_super   = np.concatenate(eta_blocks)     if eta_blocks   else np.zeros(dofs)\n",
    "\n",
    "        # ---- 1.3 更新 belief / prior（不再有 inv + Λμ）----\n",
    "        v.mu     = mu_super\n",
    "        v.Sigma  = Sigma_super\n",
    "        v.belief = NdimGaussian(dofs, eta_super, lam_super)\n",
    "        v.prior.lam = 1e-12 * lam_super\n",
    "        v.prior.eta = 1e-12 * eta_super\n",
    "\n",
    "    super_fg.n_var_nodes = len(super_fg.var_nodes)\n",
    "\n",
    "    # ---------- 2) 重新线性化 super factors（目前还是关闭） ----------\n",
    "    for f in super_fg.factors:\n",
    "        lin0 = np.concatenate([v.mu for v in f.adj_var_nodes])\n",
    "        f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "    return super_fg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def top_down_modify_base_and_abs_graph(layers):\n",
    "    \"\"\"\n",
    "    From the super graph downward, split μ to the base graph,\n",
    "    and simultaneously update the base variables' beliefs and the adjacent factors'\n",
    "    adj_beliefs / messages.\n",
    "\n",
    "    Assume layers[-1] is the super layer and layers[-2] is the base layer.\n",
    "    \"\"\"\n",
    "    super_graph = layers[-1][\"graph\"]\n",
    "    base_graph = layers[-2][\"graph\"]\n",
    "    node_map   = layers[-1][\"node_map\"]  # { base_id(str) -> super_id(str) }\n",
    "\n",
    "\n",
    "    # super_id -> [base_id(int)]\n",
    "    super_groups = {}\n",
    "    for b_str, s_id in node_map.items():\n",
    "        b_int = int(b_str)\n",
    "        super_groups.setdefault(s_id, []).append(b_int)\n",
    "\n",
    "    # child lookup\n",
    "    id2var_base = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    for s_var in super_graph.var_nodes:\n",
    "        sid = str(s_var.variableID)\n",
    "        if sid not in super_groups:\n",
    "            continue\n",
    "        base_ids = super_groups[sid]\n",
    "\n",
    "        # === split super.mu to base ===\n",
    "        mu_super = s_var.mu\n",
    "        off = 0\n",
    "        for bid in base_ids:\n",
    "            v = id2var_base[bid]\n",
    "            d = v.dofs\n",
    "            mu_child = mu_super[off:off+d]\n",
    "            off += d\n",
    "\n",
    "            old_belief = v.belief\n",
    "\n",
    "            # 1. update mu\n",
    "            v.mu = mu_child\n",
    "\n",
    "            # 2. new belief（keep Σ unchanged，use new mu）\n",
    "            eta = v.belief.lam @ v.mu\n",
    "            new_belief = NdimGaussian(v.dofs, eta, v.belief.lam)\n",
    "            v.belief = new_belief\n",
    "            v.prior = NdimGaussian(v.dofs, 1e-10*eta, 1e-10*v.belief.lam)\n",
    "\n",
    "            # 3. Sync to adjacent factors (this step is important)\n",
    "            if v.adj_factors:\n",
    "                n_adj = len(v.adj_factors)\n",
    "                d_eta = new_belief.eta - old_belief.eta\n",
    "                d_lam = new_belief.lam - old_belief.lam\n",
    "\n",
    "                for f in v.adj_factors:\n",
    "                    if v in f.adj_var_nodes:\n",
    "                        idx = f.adj_var_nodes.index(v)\n",
    "                        # update adj_beliefs\n",
    "                        f.adj_beliefs[idx] = new_belief\n",
    "                        # correct coresponding message\n",
    "                        msg = f.messages[idx]\n",
    "                        msg.eta += d_eta / n_adj\n",
    "                        msg.lam += d_lam / n_adj\n",
    "                        f.messages[idx] = msg\n",
    "\n",
    "    return base_graph\n",
    "\n",
    "\n",
    "def top_down_modify_super_graph(layers):\n",
    "    \"\"\"\n",
    "    From the abs graph downward, project mu / Sigma back to the super graph,\n",
    "    and simultaneously update the super variables' beliefs and the adjacent\n",
    "    factors' adj_beliefs / messages.\n",
    "\n",
    "    Requirements:\n",
    "      - layers[-1] is abs, layers[-2] is super\n",
    "      - Factors at the abs level and the super level share the same factorID (one-to-one)\n",
    "      - The columns of B are orthonormal (from covariance eigenvectors; eigenvectors from np.linalg.eigh are orthogonal)\n",
    "    \"\"\"\n",
    "\n",
    "    abs_graph   = layers[-1][\"graph\"]\n",
    "    super_graph = layers[-2][\"graph\"]\n",
    "    Bs  = layers[-1][\"Bs\"]   # { super_id(int) -> B (d_super × r) }\n",
    "    ks  = layers[-1][\"ks\"]   # { super_id(int) -> k (d_super,) }\n",
    "    #k2s = layers[-1][\"k2s\"]  # { super_id(int) -> residual covariance (d_super × d_super) }\n",
    "\n",
    "    # Prebuild abs factor index: factorID -> Factor\n",
    "    #abs_f_by_id = {f.factorID: f for f in getattr(abs_graph, \"factors\", [])}\n",
    "\n",
    "    # ---- First project variables' mu / Sigma and update beliefs ----\n",
    "    for sn in super_graph.var_nodes:\n",
    "        sid = sn.variableID\n",
    "        if sid not in Bs or sid not in ks:\n",
    "            continue\n",
    "        B  = Bs[sid]    # (d_s × r)\n",
    "        k  = ks[sid]    # (d_s,)\n",
    "        #k2 = k2s[sid]   # (d_s × d_s)\n",
    "\n",
    "        # x_s = B x_a + k; Σ_s = B Σ_a Bᵀ + k2\n",
    "        mu_a    = abs_graph.var_nodes[sid].mu\n",
    "        mu_s    = B @ mu_a + k\n",
    "        sn.mu   = mu_s\n",
    "\n",
    "        old_belief = sn.belief\n",
    "        # Refresh super belief (natural parameters) with the new μ and Σ\n",
    "        eta = sn.belief.lam @ sn.mu\n",
    "        new_belief = NdimGaussian(sn.dofs, eta, sn.belief.lam)\n",
    "        sn.belief  = new_belief\n",
    "        sn.prior = NdimGaussian(sn.dofs, 1e-10*eta, 1e-10*sn.belief.lam)\n",
    "\n",
    "\n",
    "        # Iterate over super factors adjacent to this super variable\n",
    "        if sn.adj_factors:\n",
    "            n_adj = len(sn.adj_factors)\n",
    "            d_eta = new_belief.eta - old_belief.eta\n",
    "            d_lam = new_belief.lam - old_belief.lam\n",
    "\n",
    "            for f in sn.adj_factors:\n",
    "                if sn in f.adj_var_nodes:\n",
    "                    idx = f.adj_var_nodes.index(sn)\n",
    "                    # update adj_beliefs\n",
    "                    f.adj_beliefs[idx] = new_belief\n",
    "                    # correct coresponding message\n",
    "                    msg = f.messages[idx]\n",
    "                    msg.eta += d_eta / n_adj\n",
    "                    msg.lam += d_lam / n_adj\n",
    "                    f.messages[idx] = msg\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def refresh_gbp_results(layers):\n",
    "    \"\"\"\n",
    "    Precompute an affine map to the base plane for each layer:\n",
    "      base:   A_i = I2, b_i = 0\n",
    "      super:  A_s = (1/m) [A_c1, A_c2, ..., A_cm], b_s = (1/m) Σ b_cj\n",
    "      abs:    A_a = A_super(s) @ B_s,             b_a = A_super(s) @ k_s + b_super(s)\n",
    "    Then refresh gbp_result via pos = A @ mu + b.\n",
    "    Convention: use string keys everywhere (aligned with Cytoscape ids).\n",
    "    \"\"\"\n",
    "    if not layers:\n",
    "        return\n",
    "\n",
    "    # ---------- 1) Bottom-up: compute A, b for each layer ----------\n",
    "    for li, L in enumerate(layers):\n",
    "        g = L.get(\"graph\")\n",
    "        if g is None:\n",
    "            L.pop(\"A\", None); L.pop(\"b\", None); L.pop(\"gbp_result\", None)\n",
    "            continue\n",
    "\n",
    "        name = L[\"name\"]\n",
    "        # ---- base ----\n",
    "        if name.startswith(\"base\"):\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for v in g.var_nodes:\n",
    "                key = str(v.variableID)\n",
    "                L[\"A\"][key] = np.eye(2)\n",
    "                L[\"b\"][key] = np.zeros(2, dtype=float)\n",
    "\n",
    "        # ---- super ----\n",
    "        elif name.startswith(\"super\"):\n",
    "            parent = layers[li - 1]\n",
    "            node_map = L[\"node_map\"]  # { prev_id(str) -> super_id(str) }\n",
    "\n",
    "            # Grouping (preserve insertion order to match the concatenation order in build_super_graph)\n",
    "            groups = {}\n",
    "            for prev_id, s_id in node_map.items():\n",
    "                prev_id = str(prev_id); s_id = str(s_id)\n",
    "                groups.setdefault(s_id, []).append(prev_id)\n",
    "\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for s_id, children in groups.items():\n",
    "                m = len(children)\n",
    "                # Horizontal concatenation [A_c1, A_c2, ...]\n",
    "                A_blocks = [parent[\"A\"][cid] for cid in children]  # each block has shape 2×d_c\n",
    "                A_concat = np.hstack(A_blocks) if A_blocks else np.zeros((2, 0))\n",
    "                b_sum = sum((parent[\"b\"][cid] for cid in children), start=np.zeros(2, dtype=float))\n",
    "                L[\"A\"][s_id] = (1.0 / m) * A_concat\n",
    "                L[\"b\"][s_id] = (1.0 / m) * b_sum\n",
    "\n",
    "        # ---- abs ----\n",
    "        elif name.startswith(\"abs\"):\n",
    "            parent = layers[li - 1]  # the corresponding super layer\n",
    "            Bs, ks = L[\"Bs\"], L[\"ks\"]  # Note: keys are the super variableIDs (int)\n",
    "\n",
    "            # Build a mapping between super variableID (int) and the super string id (follow node list order)\n",
    "            # The order of nodes in the parent (super) and this (abs) layer is consistent (copy_to_abs preserves order)\n",
    "            int2sid = {i: str(parent[\"nodes\"][i][\"data\"][\"id\"]) for i in range(len(parent[\"nodes\"]))}\n",
    "\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for av in g.var_nodes:\n",
    "                sid_int = av.variableID              # super variableID (int)\n",
    "                s_id = int2sid.get(sid_int, str(sid_int))  # super string id (also the abs node id)\n",
    "                B = Bs[sid_int]                       # (sum d_c) × r\n",
    "                k = ks[sid_int]                       # (sum d_c,)\n",
    "\n",
    "                A_sup = parent[\"A\"][s_id]             # shape 2 × (sum d_c)\n",
    "                b_sup = parent[\"b\"][s_id]             # shape (2,)\n",
    "\n",
    "                L[\"A\"][s_id] = A_sup @ B              # 2 × r\n",
    "                L[\"b\"][s_id] = A_sup @ k + b_sup      # 2,\n",
    "\n",
    "        else:\n",
    "            # Unknown layer type\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "\n",
    "    # ---------- 2) Compute gbp_result ----------\n",
    "    for li, L in enumerate(layers):\n",
    "        g = L.get(\"graph\")\n",
    "        if g is None:\n",
    "            L.pop(\"gbp_result\", None)\n",
    "            continue\n",
    "\n",
    "        name = L[\"name\"]\n",
    "        res = {}\n",
    "\n",
    "        if name.startswith(\"base\"):\n",
    "            for v in g.var_nodes:\n",
    "                vid = str(v.variableID)\n",
    "                res[vid] = v.mu[:2].tolist()\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Directly use A_super, b_super mapping\n",
    "            # nodes order is consistent with var_nodes order\n",
    "            for i, v in enumerate(g.var_nodes):\n",
    "                s_id = str(L[\"nodes\"][i][\"data\"][\"id\"])\n",
    "                A, b = L[\"A\"][s_id], L[\"b\"][s_id]   # A: 2×(sum d_c)\n",
    "                res[s_id] = (A @ v.mu + b).tolist()\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            parent = layers[li - 1]\n",
    "            # Also align via string ids\n",
    "            for i, v in enumerate(g.var_nodes):\n",
    "                a_id = str(L[\"nodes\"][i][\"data\"][\"id\"])  # same text as the super s_id\n",
    "                A, b = L[\"A\"][a_id], L[\"b\"][a_id]        # A: 2×r\n",
    "                res[a_id] = (A @ v.mu + b).tolist()\n",
    "\n",
    "        L[\"gbp_result\"] = res\n",
    "\n",
    "\n",
    "\n",
    "def vloop(layers):\n",
    "    \"\"\"\n",
    "    Simplified V-cycle:\n",
    "    1) bottom-up: rebuild and iterate once for base / super / abs in order\n",
    "    2) top-down: propagate mu from super -> base\n",
    "    3) refresh gbp_result on each layer for UI use\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- bottom-up ----\n",
    "    #if layers and \"graph\" in layers[0]:\n",
    "    #    layers[0][\"graph\"].synchronous_iteration()\n",
    "        \n",
    "    for i in range(1, len(layers)):\n",
    "        name = layers[i][\"name\"]\n",
    "\n",
    "        if name.startswith(\"super1\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            # layers[i][\"graph\"] = build_super_graph(layers[:i+1])\n",
    "            #layers[i][\"graph\"].synchronous_iteration()\n",
    "            #bottom_up_modify_super_graph(layers[:i+1])\n",
    "            #build_super_graph(layers[:i+1])\n",
    "            #update_super_graph_linearized(layers[:i+1])\n",
    "            pass\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            layers[i][\"graph\"] = build_super_graph(layers[:i+1])\n",
    "            #layers[i][\"graph\"] = update_super_graph_linearized(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Rebuild abs using the previous super\n",
    "            abs_graph, Bs, ks, k2s = build_abs_graph(layers[:i+1])\n",
    "            layers[i][\"graph\"] = abs_graph\n",
    "            layers[i][\"Bs\"], layers[i][\"ks\"], layers[i][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "        # After build, one iteration per layer\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].residual_iteration_var_heap()\n",
    "            #layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "    # ---- top-down (pass mu) ----\n",
    "    for i in range(len(layers) - 1, 0, -1):\n",
    "        # After one iterations per layer, reproject\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].residual_iteration_var_heap()\n",
    "            #layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "        # this is very important, but dont know why yet\n",
    "        # so abs layer need more iterations\n",
    "        #if name.startswith(\"abs\"):\n",
    "            #layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "        name = layers[i][\"name\"]\n",
    "        if name.startswith(\"super\"):\n",
    "            # Split super.mu back to base/abs\n",
    "            top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Project abs.mu back to super\n",
    "            top_down_modify_super_graph(layers[:i+1])\n",
    "    \n",
    "\n",
    "    # ---- refresh gbp_result for UI ----\n",
    "    refresh_gbp_results(layers)\n",
    "\n",
    "\n",
    "\n",
    "def compute_energy(layers):\n",
    "    \"\"\"\n",
    "    energy = 0.5 * sum_i || mu_i[0:2] - GT_i[0:2] ||^2  over base layer variables\n",
    "    vectorized version (no per-node np calls)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_graph = layers[0].get(\"graph\", None)\n",
    "        var_nodes = getattr(base_graph, \"var_nodes\", None)\n",
    "        if base_graph is None or not var_nodes:\n",
    "            return \"Energy: -\"\n",
    "\n",
    "        # Stack mu[:2] and GT[:2] for all variables into (N, 2)\n",
    "        mus_2 = np.stack([np.asarray(v.mu[:2], dtype=float) for v in var_nodes], axis=0)\n",
    "        gts_2 = np.stack([np.asarray(v.GT[:2], dtype=float) for v in var_nodes], axis=0)\n",
    "\n",
    "        diff = mus_2 - gts_2                      # shape (N, 2)\n",
    "        total = 0.5 * np.sum(diff * diff)         # 0.5 * sum of squared norms\n",
    "\n",
    "        return f\"Energy: {float(total):.4f}\"\n",
    "    except Exception:\n",
    "        return \"Energy: -\"\n",
    "    \n",
    "\n",
    "class VGraph:\n",
    "    def __init__(self,\n",
    "                 layers,\n",
    "                 nonlinear_factors=True,\n",
    "                 eta_damping=0.2,\n",
    "                 r_reduced=2,\n",
    "                 beta=0.0,\n",
    "                 iters_since_relinear=0,\n",
    "                 num_undamped_iters=0,\n",
    "                 min_linear_iters=100,\n",
    "                 wild_thresh=0):\n",
    "\n",
    "        self.layers = layers\n",
    "        self.iters_since_relinear = iters_since_relinear\n",
    "        self.min_linear_iters = min_linear_iters\n",
    "        self.nonlinear_factors = nonlinear_factors\n",
    "        self.eta_damping = eta_damping\n",
    "        self.r_reduced = r_reduced\n",
    "        self.wild_thresh = wild_thresh\n",
    "\n",
    "        #self.energy_history = []\n",
    "        #self.error_history = []\n",
    "        #self.nmsgs_history = []\n",
    "        #self.mus = []\n",
    "\n",
    "\n",
    "    def vloop(self):\n",
    "        \"\"\"\n",
    "        Simplified V-cycle:\n",
    "        1) bottom-up: rebuild and iterate once for base / super / abs in order\n",
    "        2) top-down: propagate mu from super -> base\n",
    "        3) refresh gbp_result on each layer for UI use\n",
    "        \"\"\"\n",
    "\n",
    "        layers = self.layers\n",
    "\n",
    "        # ---- bottom-up ----\n",
    "        #if layers and \"graph\" in layers[0]:\n",
    "        #    layers[0][\"graph\"].synchronous_iteration()\n",
    "            \n",
    "        for i in range(1, len(layers)):\n",
    "            name = layers[i][\"name\"]\n",
    "\n",
    "            if name.startswith(\"super1\"):\n",
    "                # Update super using the previous base graph's new linearization points\n",
    "                pass\n",
    "\n",
    "            elif name.startswith(\"super\"):\n",
    "                #a = time.time()\n",
    "                # Update super using the previous layer's graph\n",
    "                layers[i][\"graph\"] = bottom_up_modify_super_graph(layers[:i+1], eta_damping=self.eta_damping)\n",
    "                #print(f\"Bottom-up {name} build time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            elif name.startswith(\"abs\"):\n",
    "                # Rebuild abs using the previous super\n",
    "                #a = time.time()\n",
    "                bottom_up_modify_abs_graph(layers[:i+1], eta_damping=self.eta_damping, r_reduced=self.r_reduced)\n",
    "                #print(f\"Bottom-up {name} build time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            # After build, one iteration per layer\n",
    "            if \"graph\" in layers[i]:\n",
    "                #a = time.time()\n",
    "                layers[i][\"graph\"].residual_iteration_var_heap()\n",
    "                #layers[i][\"graph\"].synchronous_iteration()\n",
    "                #print(f\"Bottom-up {name} iteration time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "        # ---- top-down (pass mu) ----\n",
    "        for i in range(len(layers) - 1, 0, -1):\n",
    "            # After one iterations per layer, reproject\n",
    "            if \"graph\" in layers[i]:\n",
    "                #a = time.time()\n",
    "                layers[i][\"graph\"].residual_iteration_var_heap()\n",
    "                #layers[i][\"graph\"].synchronous_iteration()\n",
    "                #print(f\"Top-down {layers[i]['name']} iteration time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            #if i == len(layers) - 1:\n",
    "            # extra iteration for abs layer\n",
    "            #    layers[i][\"graph\"].synchronous_iteration()\n",
    "            # this is very important, but dont know why yet\n",
    "            # so abs layer need more iterations\n",
    "            #if name.startswith(\"abs\"):\n",
    "            #    layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "            name = layers[i][\"name\"]\n",
    "            if name.startswith(\"super\"):\n",
    "                #a = time.time()\n",
    "                # Split super.mu back to base/abs\n",
    "                top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "                #print(f\"Top-down {name} to base/abs time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            elif name.startswith(\"abs\"):\n",
    "                # Project abs.mu back to super\n",
    "                #a = time.time()\n",
    "                top_down_modify_super_graph(layers[:i+1])\n",
    "                #print(f\"Top-down {name} to super time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "        # ---- refresh gbp_result for UI ----\n",
    "        #refresh_gbp_results(layers)\n",
    "        return layers\n",
    "vg = VGraph(layers)\n",
    "\n",
    "\n",
    "def energy_map(graph, include_priors: bool = True, include_factors: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    It is actually the sum of squares of distances.\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "\n",
    "    for v in graph.var_nodes[:graph.n_var_nodes]:\n",
    "        gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "        r = np.asarray(v.belief.mu()[0:2], dtype=float) - gt\n",
    "        total += 0.5 * float(r.T @ r)\n",
    "\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edefd26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntotal = 0\\nimport time \\nxxxx = time.time()\\neta, lam = layers[0][\"graph\"].joint_distribution_inf()\\nprint(\"time:\", time.time() - xxxx)\\nxxxx = time.time()\\nsigma = np.linalg.inv(lam)\\nmu = sigma @ eta\\nprint(\"time:\", time.time() - xxxx)\\na = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\\nfor i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\\n    gt = np.asarray(v.GT[0:2], dtype=float)\\n    r = np.asarray(a[i][0:2], dtype=float) - gt\\n    total += 0.5 * float(r.T @ r)\\nprint(total)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N = 128\n",
    "N = 512\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "\n",
    "\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "\n",
    "\n",
    "# construct GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "gbp_graph.num_undamped_iters = 0\n",
    "gbp_graph.min_linear_iters = 2000\n",
    "opts=[{\"label\":\"base\",\"value\":\"base\"}]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "total = 0\n",
    "import time \n",
    "xxxx = time.time()\n",
    "eta, lam = layers[0][\"graph\"].joint_distribution_inf()\n",
    "print(\"time:\", time.time() - xxxx)\n",
    "xxxx = time.time()\n",
    "sigma = np.linalg.inv(lam)\n",
    "mu = sigma @ eta\n",
    "print(\"time:\", time.time() - xxxx)\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd1b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2324.863742569365\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bc60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "225fc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 4087835.590065\n",
      "Iter 002 | Energy = 5788861.097861\n",
      "Iter 003 | Energy = 6754464.994073\n",
      "Iter 004 | Energy = 7123259.435550\n",
      "Iter 005 | Energy = 7133976.708586\n",
      "Iter 006 | Energy = 6728282.238865\n",
      "Iter 007 | Energy = 6182834.134467\n",
      "Iter 008 | Energy = 5790260.809859\n",
      "Iter 009 | Energy = 5508707.155163\n",
      "Iter 010 | Energy = 5270366.925706\n",
      "Iter 011 | Energy = 5073160.572633\n",
      "Iter 012 | Energy = 4781202.587695\n",
      "Iter 013 | Energy = 4336077.932775\n",
      "Iter 014 | Energy = 3760878.604000\n",
      "Iter 015 | Energy = 3033528.874587\n",
      "Iter 016 | Energy = 2307613.612665\n",
      "Iter 017 | Energy = 1588292.200891\n",
      "Iter 018 | Energy = 1177398.624133\n",
      "Iter 019 | Energy = 906707.462980\n",
      "Iter 020 | Energy = 624339.576158\n",
      "Iter 021 | Energy = 315698.902612\n",
      "Iter 022 | Energy = 2413.523474\n",
      "Iter 023 | Energy = 2368.382539\n",
      "Iter 024 | Energy = 2330.248232\n",
      "Iter 025 | Energy = 2324.343343\n",
      "Iter 026 | Energy = 2341.225088\n",
      "Iter 027 | Energy = 2384.383333\n",
      "Iter 028 | Energy = 2427.620679\n",
      "Iter 029 | Energy = 2460.184839\n",
      "Iter 030 | Energy = 2492.586765\n",
      "Iter 031 | Energy = 2509.843783\n",
      "Iter 032 | Energy = 2516.133874\n",
      "Iter 033 | Energy = 2522.404846\n",
      "Iter 034 | Energy = 2526.135049\n",
      "Iter 035 | Energy = 2525.662588\n",
      "Iter 036 | Energy = 2518.415121\n",
      "Iter 037 | Energy = 2506.741342\n",
      "Iter 038 | Energy = 2493.660841\n",
      "Iter 039 | Energy = 2481.961368\n",
      "Iter 040 | Energy = 2470.832282\n",
      "Iter 041 | Energy = 2463.750512\n",
      "Iter 042 | Energy = 2459.867788\n",
      "Iter 043 | Energy = 2456.881999\n",
      "Iter 044 | Energy = 2456.754799\n",
      "Iter 045 | Energy = 2457.725298\n",
      "Iter 046 | Energy = 2458.693240\n",
      "Iter 047 | Energy = 2461.775849\n",
      "Iter 048 | Energy = 2462.817162\n",
      "Iter 049 | Energy = 2462.104423\n",
      "Iter 050 | Energy = 2460.862930\n",
      "Iter 051 | Energy = 2456.907012\n",
      "Iter 052 | Energy = 2451.360414\n",
      "Iter 053 | Energy = 2444.346855\n",
      "Iter 054 | Energy = 2434.811330\n",
      "Iter 055 | Energy = 2425.228933\n",
      "Iter 056 | Energy = 2415.901808\n",
      "Iter 057 | Energy = 2407.021902\n",
      "Iter 058 | Energy = 2399.701320\n",
      "Iter 059 | Energy = 2393.663620\n",
      "Iter 060 | Energy = 2388.876652\n",
      "Iter 061 | Energy = 2385.696851\n",
      "Iter 062 | Energy = 2383.579427\n",
      "Iter 063 | Energy = 2382.418452\n",
      "Iter 064 | Energy = 2381.892765\n",
      "Iter 065 | Energy = 2381.675822\n",
      "Iter 066 | Energy = 2381.368681\n",
      "Iter 067 | Energy = 2381.046135\n",
      "Iter 068 | Energy = 2380.424135\n",
      "Iter 069 | Energy = 2379.467587\n",
      "Iter 070 | Energy = 2378.262806\n",
      "Iter 071 | Energy = 2376.745670\n",
      "Iter 072 | Energy = 2374.875034\n",
      "Iter 073 | Energy = 2372.983927\n",
      "Iter 074 | Energy = 2370.893012\n",
      "Iter 075 | Energy = 2368.840473\n",
      "Iter 076 | Energy = 2366.961293\n",
      "Iter 077 | Energy = 2365.206284\n",
      "Iter 078 | Energy = 2363.713305\n",
      "Iter 079 | Energy = 2362.515510\n",
      "Iter 080 | Energy = 2361.474032\n",
      "Iter 081 | Energy = 2360.700066\n",
      "Iter 082 | Energy = 2360.035774\n",
      "Iter 083 | Energy = 2359.426841\n",
      "Iter 084 | Energy = 2358.856093\n",
      "Iter 085 | Energy = 2358.237017\n",
      "Iter 086 | Energy = 2357.546656\n",
      "Iter 087 | Energy = 2356.808051\n",
      "Iter 088 | Energy = 2355.951211\n",
      "Iter 089 | Energy = 2355.021015\n",
      "Iter 090 | Energy = 2354.011204\n",
      "Iter 091 | Energy = 2352.948506\n",
      "Iter 092 | Energy = 2351.853263\n",
      "Iter 093 | Energy = 2350.768569\n",
      "Iter 094 | Energy = 2349.712137\n",
      "Iter 095 | Energy = 2348.707652\n",
      "Iter 096 | Energy = 2347.772529\n",
      "Iter 097 | Energy = 2346.916733\n",
      "Iter 098 | Energy = 2346.126618\n",
      "Iter 099 | Energy = 2345.417557\n",
      "Iter 100 | Energy = 2344.754773\n",
      "Iter 101 | Energy = 2344.134266\n",
      "Iter 102 | Energy = 2343.547599\n",
      "Iter 103 | Energy = 2342.972855\n",
      "Iter 104 | Energy = 2342.406281\n",
      "Iter 105 | Energy = 2341.846937\n",
      "Iter 106 | Energy = 2341.276481\n",
      "Iter 107 | Energy = 2340.709210\n",
      "Iter 108 | Energy = 2340.137042\n",
      "Iter 109 | Energy = 2339.563625\n",
      "Iter 110 | Energy = 2338.997956\n",
      "Iter 111 | Energy = 2338.441846\n",
      "Iter 112 | Energy = 2337.899274\n",
      "Iter 113 | Energy = 2337.379477\n",
      "Iter 114 | Energy = 2336.880802\n",
      "Iter 115 | Energy = 2336.408400\n",
      "Iter 116 | Energy = 2335.960858\n",
      "Iter 117 | Energy = 2335.538326\n",
      "Iter 118 | Energy = 2335.136472\n",
      "Iter 119 | Energy = 2334.753775\n",
      "Iter 120 | Energy = 2334.385751\n",
      "Iter 121 | Energy = 2334.028656\n",
      "Iter 122 | Energy = 2333.680154\n",
      "Iter 123 | Energy = 2333.338591\n",
      "Iter 124 | Energy = 2333.000345\n",
      "Iter 125 | Energy = 2332.667695\n",
      "Iter 126 | Energy = 2332.338234\n",
      "Iter 127 | Energy = 2332.013106\n",
      "Iter 128 | Energy = 2331.694007\n",
      "Iter 129 | Energy = 2331.380631\n",
      "Iter 130 | Energy = 2331.074564\n",
      "Iter 131 | Energy = 2330.777807\n",
      "Iter 132 | Energy = 2330.489352\n",
      "Iter 133 | Energy = 2330.211524\n",
      "Iter 134 | Energy = 2329.943821\n",
      "Iter 135 | Energy = 2329.685862\n",
      "Iter 136 | Energy = 2329.437718\n",
      "Iter 137 | Energy = 2329.198410\n",
      "Iter 138 | Energy = 2328.966768\n",
      "Iter 139 | Energy = 2328.742610\n",
      "Iter 140 | Energy = 2328.524553\n",
      "Iter 141 | Energy = 2328.312256\n",
      "Iter 142 | Energy = 2328.105169\n",
      "Iter 143 | Energy = 2327.903078\n",
      "Iter 144 | Energy = 2327.705586\n",
      "Iter 145 | Energy = 2327.512939\n",
      "Iter 146 | Energy = 2327.325047\n",
      "Iter 147 | Energy = 2327.142011\n",
      "Iter 148 | Energy = 2326.964095\n",
      "Iter 149 | Energy = 2326.791487\n",
      "Iter 150 | Energy = 2326.624095\n",
      "Iter 151 | Energy = 2326.462374\n",
      "Iter 152 | Energy = 2326.306015\n",
      "Iter 153 | Energy = 2326.155025\n",
      "Iter 154 | Energy = 2326.009380\n",
      "Iter 155 | Energy = 2325.868677\n",
      "Iter 156 | Energy = 2325.732710\n",
      "Iter 157 | Energy = 2325.601343\n",
      "Iter 158 | Energy = 2325.474062\n",
      "Iter 159 | Energy = 2325.350831\n",
      "Iter 160 | Energy = 2325.231371\n",
      "Iter 161 | Energy = 2325.115463\n",
      "Iter 162 | Energy = 2325.003068\n",
      "Iter 163 | Energy = 2324.894072\n",
      "Iter 164 | Energy = 2324.788359\n",
      "Iter 165 | Energy = 2324.685989\n",
      "Iter 166 | Energy = 2324.586863\n",
      "Iter 167 | Energy = 2324.490987\n",
      "Iter 168 | Energy = 2324.398342\n",
      "Iter 169 | Energy = 2324.308900\n",
      "Iter 170 | Energy = 2324.222592\n",
      "Iter 171 | Energy = 2324.139397\n",
      "Iter 172 | Energy = 2324.059215\n",
      "Iter 173 | Energy = 2323.981954\n",
      "Iter 174 | Energy = 2323.907529\n",
      "Iter 175 | Energy = 2323.835831\n",
      "Iter 176 | Energy = 2323.766728\n",
      "Iter 177 | Energy = 2323.700161\n",
      "Iter 178 | Energy = 2323.636001\n",
      "Iter 179 | Energy = 2323.574174\n",
      "Iter 180 | Energy = 2323.514624\n",
      "Iter 181 | Energy = 2323.457266\n",
      "Iter 182 | Energy = 2323.402053\n",
      "Iter 183 | Energy = 2323.348955\n",
      "Iter 184 | Energy = 2323.297898\n",
      "Iter 185 | Energy = 2323.248868\n",
      "Iter 186 | Energy = 2323.201818\n",
      "Iter 187 | Energy = 2323.156702\n",
      "Iter 188 | Energy = 2323.113488\n",
      "Iter 189 | Energy = 2323.072132\n",
      "Iter 190 | Energy = 2323.032577\n",
      "Iter 191 | Energy = 2322.994788\n",
      "Iter 192 | Energy = 2322.958702\n",
      "Iter 193 | Energy = 2322.924270\n",
      "Iter 194 | Energy = 2322.891440\n",
      "Iter 195 | Energy = 2322.860159\n",
      "Iter 196 | Energy = 2322.830374\n",
      "Iter 197 | Energy = 2322.802044\n",
      "Iter 198 | Energy = 2322.775121\n",
      "Iter 199 | Energy = 2322.749563\n",
      "Iter 200 | Energy = 2322.725336\n",
      "Iter 201 | Energy = 2322.702401\n",
      "Iter 202 | Energy = 2322.680723\n",
      "Iter 203 | Energy = 2322.660274\n",
      "Iter 204 | Energy = 2322.641017\n",
      "Iter 205 | Energy = 2322.622925\n",
      "Iter 206 | Energy = 2322.605967\n",
      "Iter 207 | Energy = 2322.590110\n",
      "Iter 208 | Energy = 2322.575324\n",
      "Iter 209 | Energy = 2322.561581\n",
      "Iter 210 | Energy = 2322.548845\n",
      "Iter 211 | Energy = 2322.537089\n",
      "Iter 212 | Energy = 2322.526281\n",
      "Iter 213 | Energy = 2322.516391\n",
      "Iter 214 | Energy = 2322.507390\n",
      "Iter 215 | Energy = 2322.499250\n",
      "Iter 216 | Energy = 2322.491942\n",
      "Iter 217 | Energy = 2322.485443\n",
      "Iter 218 | Energy = 2322.479727\n",
      "Iter 219 | Energy = 2322.474769\n",
      "Iter 220 | Energy = 2322.470547\n",
      "Iter 221 | Energy = 2322.467039\n",
      "Iter 222 | Energy = 2322.464223\n",
      "Iter 223 | Energy = 2322.462078\n",
      "Iter 224 | Energy = 2322.460584\n",
      "Iter 225 | Energy = 2322.459720\n",
      "Iter 226 | Energy = 2322.459467\n",
      "Iter 227 | Energy = 2322.459805\n",
      "Iter 228 | Energy = 2322.460714\n",
      "Iter 229 | Energy = 2322.462176\n",
      "Iter 230 | Energy = 2322.464172\n",
      "Iter 231 | Energy = 2322.466684\n",
      "Iter 232 | Energy = 2322.469695\n",
      "Iter 233 | Energy = 2322.473186\n",
      "Iter 234 | Energy = 2322.477140\n",
      "Iter 235 | Energy = 2322.481544\n",
      "Iter 236 | Energy = 2322.486379\n",
      "Iter 237 | Energy = 2322.491631\n",
      "Iter 238 | Energy = 2322.497285\n",
      "Iter 239 | Energy = 2322.503328\n",
      "Iter 240 | Energy = 2322.509744\n",
      "Iter 241 | Energy = 2322.516521\n",
      "Iter 242 | Energy = 2322.523646\n",
      "Iter 243 | Energy = 2322.531105\n",
      "Iter 244 | Energy = 2322.538886\n",
      "Iter 245 | Energy = 2322.546977\n",
      "Iter 246 | Energy = 2322.555365\n",
      "Iter 247 | Energy = 2322.564040\n",
      "Iter 248 | Energy = 2322.572989\n",
      "Iter 249 | Energy = 2322.582202\n",
      "Iter 250 | Energy = 2322.591667\n",
      "Iter 251 | Energy = 2322.601374\n",
      "Iter 252 | Energy = 2322.611313\n",
      "Iter 253 | Energy = 2322.621473\n",
      "Iter 254 | Energy = 2322.631846\n",
      "Iter 255 | Energy = 2322.642421\n",
      "Iter 256 | Energy = 2322.653189\n",
      "Iter 257 | Energy = 2322.664143\n",
      "Iter 258 | Energy = 2322.675272\n",
      "Iter 259 | Energy = 2322.686569\n",
      "Iter 260 | Energy = 2322.698025\n",
      "Iter 261 | Energy = 2322.709633\n",
      "Iter 262 | Energy = 2322.721385\n",
      "Iter 263 | Energy = 2322.733273\n",
      "Iter 264 | Energy = 2322.745290\n",
      "Iter 265 | Energy = 2322.757430\n",
      "Iter 266 | Energy = 2322.769684\n",
      "Iter 267 | Energy = 2322.782046\n",
      "Iter 268 | Energy = 2322.794511\n",
      "Iter 269 | Energy = 2322.807071\n",
      "Iter 270 | Energy = 2322.819720\n",
      "Iter 271 | Energy = 2322.832452\n",
      "Iter 272 | Energy = 2322.845262\n",
      "Iter 273 | Energy = 2322.858144\n",
      "Iter 274 | Energy = 2322.871092\n",
      "Iter 275 | Energy = 2322.884102\n",
      "Iter 276 | Energy = 2322.897167\n",
      "Iter 277 | Energy = 2322.910284\n",
      "Iter 278 | Energy = 2322.923446\n",
      "Iter 279 | Energy = 2322.936650\n",
      "Iter 280 | Energy = 2322.949891\n",
      "Iter 281 | Energy = 2322.963165\n",
      "Iter 282 | Energy = 2322.976467\n",
      "Iter 283 | Energy = 2322.989792\n",
      "Iter 284 | Energy = 2323.003138\n",
      "Iter 285 | Energy = 2323.016501\n",
      "Iter 286 | Energy = 2323.029875\n",
      "Iter 287 | Energy = 2323.043259\n",
      "Iter 288 | Energy = 2323.056647\n",
      "Iter 289 | Energy = 2323.070038\n",
      "Iter 290 | Energy = 2323.083427\n",
      "Iter 291 | Energy = 2323.096811\n",
      "Iter 292 | Energy = 2323.110187\n",
      "Iter 293 | Energy = 2323.123553\n",
      "Iter 294 | Energy = 2323.136905\n",
      "Iter 295 | Energy = 2323.150240\n",
      "Iter 296 | Energy = 2323.163557\n",
      "Iter 297 | Energy = 2323.176851\n",
      "Iter 298 | Energy = 2323.190121\n",
      "Iter 299 | Energy = 2323.203364\n",
      "Iter 300 | Energy = 2323.216578\n",
      "Iter 301 | Energy = 2323.229761\n",
      "Iter 302 | Energy = 2323.242911\n",
      "Iter 303 | Energy = 2323.256024\n",
      "Iter 304 | Energy = 2323.269100\n",
      "Iter 305 | Energy = 2323.282136\n",
      "Iter 306 | Energy = 2323.295131\n",
      "Iter 307 | Energy = 2323.308082\n",
      "Iter 308 | Energy = 2323.320988\n",
      "Iter 309 | Energy = 2323.333848\n",
      "Iter 310 | Energy = 2323.346659\n",
      "Iter 311 | Energy = 2323.359420\n",
      "Iter 312 | Energy = 2323.372130\n",
      "Iter 313 | Energy = 2323.384787\n",
      "Iter 314 | Energy = 2323.397390\n",
      "Iter 315 | Energy = 2323.409937\n",
      "Iter 316 | Energy = 2323.422428\n",
      "Iter 317 | Energy = 2323.434860\n",
      "Iter 318 | Energy = 2323.447234\n",
      "Iter 319 | Energy = 2323.459547\n",
      "Iter 320 | Energy = 2323.471800\n",
      "Iter 321 | Energy = 2323.483990\n",
      "Iter 322 | Energy = 2323.496117\n",
      "Iter 323 | Energy = 2323.508179\n",
      "Iter 324 | Energy = 2323.520177\n",
      "Iter 325 | Energy = 2323.532110\n",
      "Iter 326 | Energy = 2323.543976\n",
      "Iter 327 | Energy = 2323.555774\n",
      "Iter 328 | Energy = 2323.567505\n",
      "Iter 329 | Energy = 2323.579167\n",
      "Iter 330 | Energy = 2323.590760\n",
      "Iter 331 | Energy = 2323.602284\n",
      "Iter 332 | Energy = 2323.613737\n",
      "Iter 333 | Energy = 2323.625119\n",
      "Iter 334 | Energy = 2323.636431\n",
      "Iter 335 | Energy = 2323.647670\n",
      "Iter 336 | Energy = 2323.658838\n",
      "Iter 337 | Energy = 2323.669933\n",
      "Iter 338 | Energy = 2323.680955\n",
      "Iter 339 | Energy = 2323.691904\n",
      "Iter 340 | Energy = 2323.702780\n",
      "Iter 341 | Energy = 2323.713582\n",
      "Iter 342 | Energy = 2323.724310\n",
      "Iter 343 | Energy = 2323.734965\n",
      "Iter 344 | Energy = 2323.745544\n",
      "Iter 345 | Energy = 2323.756050\n",
      "Iter 346 | Energy = 2323.766481\n",
      "Iter 347 | Energy = 2323.776837\n",
      "Iter 348 | Energy = 2323.787119\n",
      "Iter 349 | Energy = 2323.797325\n",
      "Iter 350 | Energy = 2323.807457\n",
      "Iter 351 | Energy = 2323.817514\n",
      "Iter 352 | Energy = 2323.827496\n",
      "Iter 353 | Energy = 2323.837402\n",
      "Iter 354 | Energy = 2323.847235\n",
      "Iter 355 | Energy = 2323.856992\n",
      "Iter 356 | Energy = 2323.866674\n",
      "Iter 357 | Energy = 2323.876282\n",
      "Iter 358 | Energy = 2323.885815\n",
      "Iter 359 | Energy = 2323.895273\n",
      "Iter 360 | Energy = 2323.904657\n",
      "Iter 361 | Energy = 2323.913967\n",
      "Iter 362 | Energy = 2323.923203\n",
      "Iter 363 | Energy = 2323.932365\n",
      "Iter 364 | Energy = 2323.941453\n",
      "Iter 365 | Energy = 2323.950467\n",
      "Iter 366 | Energy = 2323.959408\n",
      "Iter 367 | Energy = 2323.968276\n",
      "Iter 368 | Energy = 2323.977071\n",
      "Iter 369 | Energy = 2323.985793\n",
      "Iter 370 | Energy = 2323.994443\n",
      "Iter 371 | Energy = 2324.003021\n",
      "Iter 372 | Energy = 2324.011526\n",
      "Iter 373 | Energy = 2324.019960\n",
      "Iter 374 | Energy = 2324.028323\n",
      "Iter 375 | Energy = 2324.036614\n",
      "Iter 376 | Energy = 2324.044835\n",
      "Iter 377 | Energy = 2324.052985\n",
      "Iter 378 | Energy = 2324.061064\n",
      "Iter 379 | Energy = 2324.069074\n",
      "Iter 380 | Energy = 2324.077015\n",
      "Iter 381 | Energy = 2324.084886\n",
      "Iter 382 | Energy = 2324.092688\n",
      "Iter 383 | Energy = 2324.100422\n",
      "Iter 384 | Energy = 2324.108088\n",
      "Iter 385 | Energy = 2324.115685\n",
      "Iter 386 | Energy = 2324.123216\n",
      "Iter 387 | Energy = 2324.130679\n",
      "Iter 388 | Energy = 2324.138075\n",
      "Iter 389 | Energy = 2324.145405\n",
      "Iter 390 | Energy = 2324.152669\n",
      "Iter 391 | Energy = 2324.159868\n",
      "Iter 392 | Energy = 2324.167001\n",
      "Iter 393 | Energy = 2324.174069\n",
      "Iter 394 | Energy = 2324.181073\n",
      "Iter 395 | Energy = 2324.188013\n",
      "Iter 396 | Energy = 2324.194889\n",
      "Iter 397 | Energy = 2324.201702\n",
      "Iter 398 | Energy = 2324.208453\n",
      "Iter 399 | Energy = 2324.215140\n",
      "Iter 400 | Energy = 2324.221766\n",
      "Iter 401 | Energy = 2324.228330\n",
      "Iter 402 | Energy = 2324.234833\n",
      "Iter 403 | Energy = 2324.241275\n",
      "Iter 404 | Energy = 2324.247656\n",
      "Iter 405 | Energy = 2324.253978\n",
      "Iter 406 | Energy = 2324.260240\n",
      "Iter 407 | Energy = 2324.266443\n",
      "Iter 408 | Energy = 2324.272587\n",
      "Iter 409 | Energy = 2324.278673\n",
      "Iter 410 | Energy = 2324.284701\n",
      "Iter 411 | Energy = 2324.290672\n",
      "Iter 412 | Energy = 2324.296586\n",
      "Iter 413 | Energy = 2324.302443\n",
      "Iter 414 | Energy = 2324.308243\n",
      "Iter 415 | Energy = 2324.313988\n",
      "Iter 416 | Energy = 2324.319678\n",
      "Iter 417 | Energy = 2324.325313\n",
      "Iter 418 | Energy = 2324.330893\n",
      "Iter 419 | Energy = 2324.336419\n",
      "Iter 420 | Energy = 2324.341891\n",
      "Iter 421 | Energy = 2324.347310\n",
      "Iter 422 | Energy = 2324.352677\n",
      "Iter 423 | Energy = 2324.357991\n",
      "Iter 424 | Energy = 2324.363253\n",
      "Iter 425 | Energy = 2324.368463\n",
      "Iter 426 | Energy = 2324.373622\n",
      "Iter 427 | Energy = 2324.378730\n",
      "Iter 428 | Energy = 2324.383789\n",
      "Iter 429 | Energy = 2324.388797\n",
      "Iter 430 | Energy = 2324.393755\n",
      "Iter 431 | Energy = 2324.398665\n",
      "Iter 432 | Energy = 2324.403526\n",
      "Iter 433 | Energy = 2324.408338\n",
      "Iter 434 | Energy = 2324.413103\n",
      "Iter 435 | Energy = 2324.417820\n",
      "Iter 436 | Energy = 2324.422490\n",
      "Iter 437 | Energy = 2324.427114\n",
      "Iter 438 | Energy = 2324.431691\n",
      "Iter 439 | Energy = 2324.436222\n",
      "Iter 440 | Energy = 2324.440708\n",
      "Iter 441 | Energy = 2324.445149\n",
      "Iter 442 | Energy = 2324.449545\n",
      "Iter 443 | Energy = 2324.453896\n",
      "Iter 444 | Energy = 2324.458204\n",
      "Iter 445 | Energy = 2324.462468\n",
      "Iter 446 | Energy = 2324.466689\n",
      "Iter 447 | Energy = 2324.470868\n",
      "Iter 448 | Energy = 2324.475004\n",
      "Iter 449 | Energy = 2324.479098\n",
      "Iter 450 | Energy = 2324.483150\n",
      "Iter 451 | Energy = 2324.487161\n",
      "Iter 452 | Energy = 2324.491132\n",
      "Iter 453 | Energy = 2324.495061\n",
      "Iter 454 | Energy = 2324.498951\n",
      "Iter 455 | Energy = 2324.502801\n",
      "Iter 456 | Energy = 2324.506611\n",
      "Iter 457 | Energy = 2324.510383\n",
      "Iter 458 | Energy = 2324.514115\n",
      "Iter 459 | Energy = 2324.517810\n",
      "Iter 460 | Energy = 2324.521466\n",
      "Iter 461 | Energy = 2324.525085\n",
      "Iter 462 | Energy = 2324.528666\n",
      "Iter 463 | Energy = 2324.532211\n",
      "Iter 464 | Energy = 2324.535719\n",
      "Iter 465 | Energy = 2324.539191\n",
      "Iter 466 | Energy = 2324.542627\n",
      "Iter 467 | Energy = 2324.546027\n",
      "Iter 468 | Energy = 2324.549392\n",
      "Iter 469 | Energy = 2324.552722\n",
      "Iter 470 | Energy = 2324.556018\n",
      "Iter 471 | Energy = 2324.559279\n",
      "Iter 472 | Energy = 2324.562507\n",
      "Iter 473 | Energy = 2324.565701\n",
      "Iter 474 | Energy = 2324.568862\n",
      "Iter 475 | Energy = 2324.571990\n",
      "Iter 476 | Energy = 2324.575085\n",
      "Iter 477 | Energy = 2324.578148\n",
      "Iter 478 | Energy = 2324.581179\n",
      "Iter 479 | Energy = 2324.584178\n",
      "Iter 480 | Energy = 2324.587146\n",
      "Iter 481 | Energy = 2324.590083\n",
      "Iter 482 | Energy = 2324.592989\n",
      "Iter 483 | Energy = 2324.595865\n",
      "Iter 484 | Energy = 2324.598710\n",
      "Iter 485 | Energy = 2324.601526\n",
      "Iter 486 | Energy = 2324.604312\n",
      "Iter 487 | Energy = 2324.607069\n",
      "Iter 488 | Energy = 2324.609797\n",
      "Iter 489 | Energy = 2324.612496\n",
      "Iter 490 | Energy = 2324.615166\n",
      "Iter 491 | Energy = 2324.617809\n",
      "Iter 492 | Energy = 2324.620424\n",
      "Iter 493 | Energy = 2324.623011\n",
      "Iter 494 | Energy = 2324.625571\n",
      "Iter 495 | Energy = 2324.628104\n",
      "Iter 496 | Energy = 2324.630610\n",
      "Iter 497 | Energy = 2324.633090\n",
      "Iter 498 | Energy = 2324.635543\n",
      "Iter 499 | Energy = 2324.637970\n",
      "Iter 500 | Energy = 2324.640372\n",
      "Iter 501 | Energy = 2324.642748\n",
      "Iter 502 | Energy = 2324.645100\n",
      "Iter 503 | Energy = 2324.647426\n",
      "Iter 504 | Energy = 2324.649727\n",
      "Iter 505 | Energy = 2324.652005\n",
      "Iter 506 | Energy = 2324.654258\n",
      "Iter 507 | Energy = 2324.656487\n",
      "Iter 508 | Energy = 2324.658692\n",
      "Iter 509 | Energy = 2324.660874\n",
      "Iter 510 | Energy = 2324.663033\n",
      "Iter 511 | Energy = 2324.665168\n",
      "Iter 512 | Energy = 2324.667281\n",
      "Iter 513 | Energy = 2324.669372\n",
      "Iter 514 | Energy = 2324.671440\n",
      "Iter 515 | Energy = 2324.673487\n",
      "Iter 516 | Energy = 2324.675511\n",
      "Iter 517 | Energy = 2324.677514\n",
      "Iter 518 | Energy = 2324.679495\n",
      "Iter 519 | Energy = 2324.681456\n",
      "Iter 520 | Energy = 2324.683395\n",
      "Iter 521 | Energy = 2324.685314\n",
      "Iter 522 | Energy = 2324.687212\n",
      "Iter 523 | Energy = 2324.689090\n",
      "Iter 524 | Energy = 2324.690948\n",
      "Iter 525 | Energy = 2324.692786\n",
      "Iter 526 | Energy = 2324.694604\n",
      "Iter 527 | Energy = 2324.696403\n",
      "Iter 528 | Energy = 2324.698183\n",
      "Iter 529 | Energy = 2324.699943\n",
      "Iter 530 | Energy = 2324.701685\n",
      "Iter 531 | Energy = 2324.703408\n",
      "Iter 532 | Energy = 2324.705113\n",
      "Iter 533 | Energy = 2324.706799\n",
      "Iter 534 | Energy = 2324.708468\n",
      "Iter 535 | Energy = 2324.710118\n",
      "Iter 536 | Energy = 2324.711751\n",
      "Iter 537 | Energy = 2324.713366\n",
      "Iter 538 | Energy = 2324.714964\n",
      "Iter 539 | Energy = 2324.716545\n",
      "Iter 540 | Energy = 2324.718109\n",
      "Iter 541 | Energy = 2324.719656\n",
      "Iter 542 | Energy = 2324.721186\n",
      "Iter 543 | Energy = 2324.722700\n",
      "Iter 544 | Energy = 2324.724198\n",
      "Iter 545 | Energy = 2324.725680\n",
      "Iter 546 | Energy = 2324.727146\n",
      "Iter 547 | Energy = 2324.728596\n",
      "Iter 548 | Energy = 2324.730030\n",
      "Iter 549 | Energy = 2324.731449\n",
      "Iter 550 | Energy = 2324.732853\n",
      "Iter 551 | Energy = 2324.734242\n",
      "Iter 552 | Energy = 2324.735615\n",
      "Iter 553 | Energy = 2324.736974\n",
      "Iter 554 | Energy = 2324.738319\n",
      "Iter 555 | Energy = 2324.739649\n",
      "Iter 556 | Energy = 2324.740964\n",
      "Iter 557 | Energy = 2324.742266\n",
      "Iter 558 | Energy = 2324.743553\n",
      "Iter 559 | Energy = 2324.744827\n",
      "Iter 560 | Energy = 2324.746087\n",
      "Iter 561 | Energy = 2324.747333\n",
      "Iter 562 | Energy = 2324.748566\n",
      "Iter 563 | Energy = 2324.749785\n",
      "Iter 564 | Energy = 2324.750992\n",
      "Iter 565 | Energy = 2324.752186\n",
      "Iter 566 | Energy = 2324.753366\n",
      "Iter 567 | Energy = 2324.754534\n",
      "Iter 568 | Energy = 2324.755690\n",
      "Iter 569 | Energy = 2324.756833\n",
      "Iter 570 | Energy = 2324.757963\n",
      "Iter 571 | Energy = 2324.759082\n",
      "Iter 572 | Energy = 2324.760188\n",
      "Iter 573 | Energy = 2324.761283\n",
      "Iter 574 | Energy = 2324.762365\n",
      "Iter 575 | Energy = 2324.763437\n",
      "Iter 576 | Energy = 2324.764496\n",
      "Iter 577 | Energy = 2324.765544\n",
      "Iter 578 | Energy = 2324.766581\n",
      "Iter 579 | Energy = 2324.767607\n",
      "Iter 580 | Energy = 2324.768621\n",
      "Iter 581 | Energy = 2324.769625\n",
      "Iter 582 | Energy = 2324.770618\n",
      "Iter 583 | Energy = 2324.771600\n",
      "Iter 584 | Energy = 2324.772572\n",
      "Iter 585 | Energy = 2324.773533\n",
      "Iter 586 | Energy = 2324.774484\n",
      "Iter 587 | Energy = 2324.775424\n",
      "Iter 588 | Energy = 2324.776355\n",
      "Iter 589 | Energy = 2324.777275\n",
      "Iter 590 | Energy = 2324.778186\n",
      "Iter 591 | Energy = 2324.779087\n",
      "Iter 592 | Energy = 2324.779978\n",
      "Iter 593 | Energy = 2324.780859\n",
      "Iter 594 | Energy = 2324.781731\n",
      "Iter 595 | Energy = 2324.782594\n",
      "Iter 596 | Energy = 2324.783447\n",
      "Iter 597 | Energy = 2324.784291\n",
      "Iter 598 | Energy = 2324.785126\n",
      "Iter 599 | Energy = 2324.785952\n",
      "Iter 600 | Energy = 2324.786769\n",
      "Iter 601 | Energy = 2324.787578\n",
      "Iter 602 | Energy = 2324.788377\n",
      "Iter 603 | Energy = 2324.789168\n",
      "Iter 604 | Energy = 2324.789951\n",
      "Iter 605 | Energy = 2324.790725\n",
      "Iter 606 | Energy = 2324.791491\n",
      "Iter 607 | Energy = 2324.792248\n",
      "Iter 608 | Energy = 2324.792998\n",
      "Iter 609 | Energy = 2324.793739\n",
      "Iter 610 | Energy = 2324.794472\n",
      "Iter 611 | Energy = 2324.795198\n",
      "Iter 612 | Energy = 2324.795916\n",
      "Iter 613 | Energy = 2324.796626\n",
      "Iter 614 | Energy = 2324.797328\n",
      "Iter 615 | Energy = 2324.798023\n",
      "Iter 616 | Energy = 2324.798710\n",
      "Iter 617 | Energy = 2324.799390\n",
      "Iter 618 | Energy = 2324.800063\n",
      "Iter 619 | Energy = 2324.800728\n",
      "Iter 620 | Energy = 2324.801387\n",
      "Iter 621 | Energy = 2324.802038\n",
      "Iter 622 | Energy = 2324.802682\n",
      "Iter 623 | Energy = 2324.803319\n",
      "Iter 624 | Energy = 2324.803950\n",
      "Iter 625 | Energy = 2324.804574\n",
      "Iter 626 | Energy = 2324.805191\n",
      "Iter 627 | Energy = 2324.805801\n",
      "Iter 628 | Energy = 2324.806405\n",
      "Iter 629 | Energy = 2324.807002\n",
      "Iter 630 | Energy = 2324.807593\n",
      "Iter 631 | Energy = 2324.808178\n",
      "Iter 632 | Energy = 2324.808756\n",
      "Iter 633 | Energy = 2324.809328\n",
      "Iter 634 | Energy = 2324.809895\n",
      "Iter 635 | Energy = 2324.810455\n",
      "Iter 636 | Energy = 2324.811009\n",
      "Iter 637 | Energy = 2324.811557\n",
      "Iter 638 | Energy = 2324.812099\n",
      "Iter 639 | Energy = 2324.812635\n",
      "Iter 640 | Energy = 2324.813166\n",
      "Iter 641 | Energy = 2324.813691\n",
      "Iter 642 | Energy = 2324.814210\n",
      "Iter 643 | Energy = 2324.814724\n",
      "Iter 644 | Energy = 2324.815232\n",
      "Iter 645 | Energy = 2324.815735\n",
      "Iter 646 | Energy = 2324.816233\n",
      "Iter 647 | Energy = 2324.816725\n",
      "Iter 648 | Energy = 2324.817212\n",
      "Iter 649 | Energy = 2324.817694\n",
      "Iter 650 | Energy = 2324.818170\n",
      "Iter 651 | Energy = 2324.818642\n",
      "Iter 652 | Energy = 2324.819108\n",
      "Iter 653 | Energy = 2324.819570\n",
      "Iter 654 | Energy = 2324.820026\n",
      "Iter 655 | Energy = 2324.820478\n",
      "Iter 656 | Energy = 2324.820925\n",
      "Iter 657 | Energy = 2324.821367\n",
      "Iter 658 | Energy = 2324.821804\n",
      "Iter 659 | Energy = 2324.822237\n",
      "Iter 660 | Energy = 2324.822665\n",
      "Iter 661 | Energy = 2324.823089\n",
      "Iter 662 | Energy = 2324.823508\n",
      "Iter 663 | Energy = 2324.823922\n",
      "Iter 664 | Energy = 2324.824333\n",
      "Iter 665 | Energy = 2324.824738\n",
      "Iter 666 | Energy = 2324.825140\n",
      "Iter 667 | Energy = 2324.825537\n",
      "Iter 668 | Energy = 2324.825930\n",
      "Iter 669 | Energy = 2324.826319\n",
      "Iter 670 | Energy = 2324.826704\n",
      "Iter 671 | Energy = 2324.827084\n",
      "Iter 672 | Energy = 2324.827461\n",
      "Iter 673 | Energy = 2324.827833\n",
      "Iter 674 | Energy = 2324.828202\n",
      "Iter 675 | Energy = 2324.828567\n",
      "Iter 676 | Energy = 2324.828928\n",
      "Iter 677 | Energy = 2324.829285\n",
      "Iter 678 | Energy = 2324.829638\n",
      "Iter 679 | Energy = 2324.829987\n",
      "Iter 680 | Energy = 2324.830333\n",
      "Iter 681 | Energy = 2324.830675\n",
      "Iter 682 | Energy = 2324.831014\n",
      "Iter 683 | Energy = 2324.831348\n",
      "Iter 684 | Energy = 2324.831680\n",
      "Iter 685 | Energy = 2324.832008\n",
      "Iter 686 | Energy = 2324.832332\n",
      "Iter 687 | Energy = 2324.832653\n",
      "Iter 688 | Energy = 2324.832970\n",
      "Iter 689 | Energy = 2324.833285\n",
      "Iter 690 | Energy = 2324.833596\n",
      "Iter 691 | Energy = 2324.833903\n",
      "Iter 692 | Energy = 2324.834207\n",
      "Iter 693 | Energy = 2324.834509\n",
      "Iter 694 | Energy = 2324.834806\n",
      "Iter 695 | Energy = 2324.835101\n",
      "Iter 696 | Energy = 2324.835393\n",
      "Iter 697 | Energy = 2324.835682\n",
      "Iter 698 | Energy = 2324.835967\n",
      "Iter 699 | Energy = 2324.836250\n",
      "Iter 700 | Energy = 2324.836529\n",
      "Iter 701 | Energy = 2324.836806\n",
      "Iter 702 | Energy = 2324.837080\n",
      "Iter 703 | Energy = 2324.837350\n",
      "Iter 704 | Energy = 2324.837618\n",
      "Iter 705 | Energy = 2324.837884\n",
      "Iter 706 | Energy = 2324.838146\n",
      "Iter 707 | Energy = 2324.838405\n",
      "Iter 708 | Energy = 2324.838662\n",
      "Iter 709 | Energy = 2324.838917\n",
      "Iter 710 | Energy = 2324.839168\n",
      "Iter 711 | Energy = 2324.839417\n",
      "Iter 712 | Energy = 2324.839663\n",
      "Iter 713 | Energy = 2324.839907\n",
      "Iter 714 | Energy = 2324.840148\n",
      "Iter 715 | Energy = 2324.840387\n",
      "Iter 716 | Energy = 2324.840623\n",
      "Iter 717 | Energy = 2324.840856\n",
      "Iter 718 | Energy = 2324.841087\n",
      "Iter 719 | Energy = 2324.841316\n",
      "Iter 720 | Energy = 2324.841542\n",
      "Iter 721 | Energy = 2324.841766\n",
      "Iter 722 | Energy = 2324.841988\n",
      "Iter 723 | Energy = 2324.842207\n",
      "Iter 724 | Energy = 2324.842424\n",
      "Iter 725 | Energy = 2324.842639\n",
      "Iter 726 | Energy = 2324.842852\n",
      "Iter 727 | Energy = 2324.843062\n",
      "Iter 728 | Energy = 2324.843270\n",
      "Iter 729 | Energy = 2324.843476\n",
      "Iter 730 | Energy = 2324.843680\n",
      "Iter 731 | Energy = 2324.843881\n",
      "Iter 732 | Energy = 2324.844081\n",
      "Iter 733 | Energy = 2324.844278\n",
      "Iter 734 | Energy = 2324.844474\n",
      "Iter 735 | Energy = 2324.844667\n",
      "Iter 736 | Energy = 2324.844858\n",
      "Iter 737 | Energy = 2324.845048\n",
      "Iter 738 | Energy = 2324.845235\n",
      "Iter 739 | Energy = 2324.845421\n",
      "Iter 740 | Energy = 2324.845604\n",
      "Iter 741 | Energy = 2324.845786\n",
      "Iter 742 | Energy = 2324.845965\n",
      "Iter 743 | Energy = 2324.846143\n",
      "Iter 744 | Energy = 2324.846319\n",
      "Iter 745 | Energy = 2324.846493\n",
      "Iter 746 | Energy = 2324.846666\n",
      "Iter 747 | Energy = 2324.846836\n",
      "Iter 748 | Energy = 2324.847005\n",
      "Iter 749 | Energy = 2324.847172\n",
      "Iter 750 | Energy = 2324.847338\n",
      "Iter 751 | Energy = 2324.847501\n",
      "Iter 752 | Energy = 2324.847663\n",
      "Iter 753 | Energy = 2324.847823\n",
      "Iter 754 | Energy = 2324.847982\n",
      "Iter 755 | Energy = 2324.848139\n",
      "Iter 756 | Energy = 2324.848294\n",
      "Iter 757 | Energy = 2324.848448\n",
      "Iter 758 | Energy = 2324.848600\n",
      "Iter 759 | Energy = 2324.848751\n",
      "Iter 760 | Energy = 2324.848900\n",
      "Iter 761 | Energy = 2324.849047\n",
      "Iter 762 | Energy = 2324.849193\n",
      "Iter 763 | Energy = 2324.849337\n",
      "Iter 764 | Energy = 2324.849480\n",
      "Iter 765 | Energy = 2324.849622\n",
      "Iter 766 | Energy = 2324.849762\n",
      "Iter 767 | Energy = 2324.849900\n",
      "Iter 768 | Energy = 2324.850038\n",
      "Iter 769 | Energy = 2324.850173\n",
      "Iter 770 | Energy = 2324.850308\n",
      "Iter 771 | Energy = 2324.850441\n",
      "Iter 772 | Energy = 2324.850572\n",
      "Iter 773 | Energy = 2324.850702\n",
      "Iter 774 | Energy = 2324.850831\n",
      "Iter 775 | Energy = 2324.850959\n",
      "Iter 776 | Energy = 2324.851085\n",
      "Iter 777 | Energy = 2324.851210\n",
      "Iter 778 | Energy = 2324.851334\n",
      "Iter 779 | Energy = 2324.851456\n",
      "Iter 780 | Energy = 2324.851577\n",
      "Iter 781 | Energy = 2324.851697\n",
      "Iter 782 | Energy = 2324.851816\n",
      "Iter 783 | Energy = 2324.851934\n",
      "Iter 784 | Energy = 2324.852050\n",
      "Iter 785 | Energy = 2324.852165\n",
      "Iter 786 | Energy = 2324.852279\n",
      "Iter 787 | Energy = 2324.852392\n",
      "Iter 788 | Energy = 2324.852503\n",
      "Iter 789 | Energy = 2324.852614\n",
      "Iter 790 | Energy = 2324.852723\n",
      "Iter 791 | Energy = 2324.852831\n",
      "Iter 792 | Energy = 2324.852938\n",
      "Iter 793 | Energy = 2324.853044\n",
      "Iter 794 | Energy = 2324.853149\n",
      "Iter 795 | Energy = 2324.853253\n",
      "Iter 796 | Energy = 2324.853356\n",
      "Iter 797 | Energy = 2324.853458\n",
      "Iter 798 | Energy = 2324.853558\n",
      "Iter 799 | Energy = 2324.853658\n",
      "Iter 800 | Energy = 2324.853757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2324.8539511359745"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basegraph = layers[0][\"graph\"]\n",
    "basegraph.eta_damping = 0\n",
    "energy_prev = total\n",
    "\n",
    "counter = 0\n",
    "#energy_prev = 0\n",
    "#energy_gt = 7812.353496639449\n",
    "\n",
    "#basegraph.synchronous_iteration()\n",
    "#for f in basegraph.factors:\n",
    "#    f.compute_messages(eta_damping=0)\n",
    "#for v in basegraph.var_nodes:\n",
    "#    v.update_belief()\n",
    "\n",
    "num_iters = 1000\n",
    "rand_flags = np.random.rand(num_iters) < 0\n",
    "for it in range(num_iters):\n",
    "    #basegraph.residual_iteration()\n",
    "    if rand_flags[it]:\n",
    "        basegraph.residual_iteration_var_heap()\n",
    "    else:\n",
    "        basegraph.synchronous_iteration()\n",
    "    #basegraph.wildfire_iteration()\n",
    "    #basegraph.synchronous_iteration()\n",
    "    energy = energy_map(basegraph, include_priors=True, include_factors=True)\n",
    "    if np.abs(energy_prev-energy) < 1e-2:\n",
    "        counter += 1\n",
    "        if counter >= 2:\n",
    "            break\n",
    "    #energy_prev = energy\n",
    "    print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")\n",
    "\n",
    "basegraph.synchronous_iteration()\n",
    "energy_map(basegraph, include_priors=True, include_factors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dcec503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 4312.940524\n",
      "Iter 002 | Energy = 2645.156113\n",
      "Iter 003 | Energy = 2382.716547\n",
      "Iter 004 | Energy = 2322.722731\n",
      "Iter 005 | Energy = 2320.100271\n",
      "Iter 006 | Energy = 2314.700506\n",
      "Iter 007 | Energy = 2317.230535\n",
      "Iter 008 | Energy = 2318.567125\n",
      "Iter 009 | Energy = 2321.075613\n",
      "Iter 010 | Energy = 2322.263874\n",
      "Iter 011 | Energy = 2322.876008\n",
      "Iter 012 | Energy = 2323.780061\n",
      "Iter 013 | Energy = 2324.097298\n",
      "Iter 014 | Energy = 2324.448423\n",
      "Iter 015 | Energy = 2324.790761\n",
      "Iter 016 | Energy = 2324.861514\n",
      "Iter 017 | Energy = 2324.824859\n",
      "Iter 018 | Energy = 2324.846015\n",
      "Iter 019 | Energy = 2324.844077\n",
      "Iter 020 | Energy = 2324.888932\n"
     ]
    }
   ],
   "source": [
    "N=512\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "\n",
    "\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "\n",
    "\n",
    "\n",
    "# Create GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "gbp_graph.num_undamped_iters = 0\n",
    "gbp_graph.min_linear_iters = 2000\n",
    "opts=[{\"label\":\"base\",\"value\":\"base\"}]\n",
    "\n",
    "\n",
    "kk = 14\n",
    "k_next = 1\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure base graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "\n",
    "abs_layer_idx = 2\n",
    "k = 1\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(\n",
    "    layers, r_reduced=2)\n",
    "\n",
    "\n",
    "k_next = 2\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "\n",
    "abs_layer_idx = 4\n",
    "k = 2\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(\n",
    "    layers, r_reduced=2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "k_next = 3\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "abs_layer_idx = 6\n",
    "k = 3\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(layers)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "k_next = 4\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "abs_layer_idx = 8\n",
    "k = 4\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(layers)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(2000):\n",
    "    layers[1][\"graph\"].synchronous_iteration()\n",
    "    layers[0][\"graph\"].synchronous_iteration()\n",
    "    layers[2][\"graph\"].synchronous_iteration()\n",
    "    #top_down_modify_super_graph(layers[:])\n",
    "    #top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {i+1:03d} | Energy = {energy:.6f}\")\n",
    "\"\"\"\n",
    "\n",
    "vg = VGraph(layers)\n",
    "energy_prev = total\n",
    "counter = 0\n",
    "for _ in range(1000):\n",
    "    vg.layers = layers\n",
    "    vg.r_reduced=2\n",
    "    vg.eta_damping = 0.4\n",
    "    vg.layers = vg.vloop()\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    if np.abs(energy_prev-energy) < 1e-2:\n",
    "        counter += 1\n",
    "        if counter >= 2:\n",
    "            break\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")\n",
    "    #energy_prev = energy\n",
    "refresh_gbp_results(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d617cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop       (for 每块小矩阵): 23.92969950014958 ms\n",
      "batch warm (提前 stack 好): 1.5643609999096952 ms\n",
      "batch cold (每次都 np.stack): 8.285792499955278 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# -------------------\n",
    "# 构造一个 toy example\n",
    "# -------------------\n",
    "B, m, n = 5000, 2, 4   # B = block 数量，m = 每块观测维度，n = 变量维度\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "J_list = [rng.normal(size=(m, n)) for _ in range(B)]\n",
    "L_list = [rng.normal(size=(m, m)) for _ in range(B)]\n",
    "# 让 L_i 正定一点\n",
    "L_list = [Li.T @ Li + 1e-3 * np.eye(m) for Li in L_list]\n",
    "z_list = [rng.normal(size=(m,)) for _ in range(B)]\n",
    "h_list = [rng.normal(size=(m,)) for _ in range(B)]\n",
    "x = rng.normal(size=(n,))\n",
    "\n",
    "# -------------------\n",
    "# 方案 A：你现在的 for-loop 小矩阵累加\n",
    "# -------------------\n",
    "def compute_loop(J_list, L_list, z_list, h_list, x):\n",
    "    n = x.shape[0]\n",
    "    lambda_factor = np.zeros((n, n))\n",
    "    eta_factor = np.zeros((n,))\n",
    "    for Ji, Li, zi, hi in zip(J_list, L_list, z_list, h_list):\n",
    "        ri = Ji @ x + zi - hi              # (m,)\n",
    "        lambda_factor += Ji.T @ Li @ Ji    # (n,n)\n",
    "        eta_factor += Ji.T @ (Li @ ri)     # (n,)\n",
    "    return lambda_factor, eta_factor\n",
    "\n",
    "# -------------------\n",
    "# 方案 B：batch 大矩阵版本（假设已经 stack 好）\n",
    "# -------------------\n",
    "def compute_batch(J, L, z, h, x):\n",
    "    \"\"\"\n",
    "    J: (B, m, n)\n",
    "    L: (B, m, m)\n",
    "    z: (B, m)\n",
    "    h: (B, m)\n",
    "    x: (n,)\n",
    "    \"\"\"\n",
    "    B_, m_, n_ = J.shape\n",
    "\n",
    "    # r_i = J_i x + z_i - h_i   -> (B, m)\n",
    "    r = J @ x                   # (B, m)\n",
    "    r = r + z - h               # (B, m)\n",
    "\n",
    "    # M_i = L_i J_i -> (B, m, n)\n",
    "    M = np.matmul(L, J)         # (B, m, n)\n",
    "\n",
    "    # Λ = sum_i J_i^T L_i J_i\n",
    "    # lam_blocks[b] = J_b^T L_b J_b\n",
    "    lam_blocks = np.einsum('bmi,bmj->bij', J, M)   # (B, n, n)\n",
    "    lambda_factor = lam_blocks.sum(axis=0)         # (n, n)\n",
    "\n",
    "    # η = sum_i J_i^T L_i r_i\n",
    "    Mr = np.einsum('bij,bi->bj', L, r)             # (B, m)  = L_i r_i\n",
    "    eta_blocks = np.einsum('bmi,bm->bi', J, Mr)    # (B, n)\n",
    "    eta_factor = eta_blocks.sum(axis=0)            # (n,)\n",
    "\n",
    "    return lambda_factor, eta_factor\n",
    "\n",
    "# 预先 stack 好（“warm” 情况）\n",
    "J = np.stack(J_list, axis=0)   # (B, m, n)\n",
    "L = np.stack(L_list, axis=0)   # (B, m, m)\n",
    "z = np.stack(z_list, axis=0)   # (B, m)\n",
    "h = np.stack(h_list, axis=0)   # (B, m)\n",
    "\n",
    "# -------------------\n",
    "# 方案 B'：把 np.stack 的时间也算进去（“cold”）\n",
    "# -------------------\n",
    "def compute_batch_cold(J_list, L_list, z_list, h_list, x):\n",
    "    J = np.stack(J_list, axis=0)\n",
    "    L = np.stack(L_list, axis=0)\n",
    "    z = np.stack(z_list, axis=0)\n",
    "    h = np.stack(h_list, axis=0)\n",
    "    return compute_batch(J, L, z, h, x)\n",
    "\n",
    "# -------------------\n",
    "# 校验数值一致\n",
    "# -------------------\n",
    "lam_A, eta_A = compute_loop(J_list, L_list, z_list, h_list, x)\n",
    "lam_B, eta_B = compute_batch(J, L, z, h, x)\n",
    "assert np.allclose(lam_A, lam_B, atol=1e-8)\n",
    "assert np.allclose(eta_A, eta_B, atol=1e-8)\n",
    "\n",
    "# -------------------\n",
    "# 简单基准测试\n",
    "# -------------------\n",
    "def bench(fn, iters=200):\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0) / iters\n",
    "\n",
    "print(\"loop       (for 每块小矩阵):\",\n",
    "      bench(lambda: compute_loop(J_list, L_list, z_list, h_list, x)) * 1e3, \"ms\")\n",
    "\n",
    "print(\"batch warm (提前 stack 好):\",\n",
    "      bench(lambda: compute_batch(J, L, z, h, x)) * 1e3, \"ms\")\n",
    "\n",
    "print(\"batch cold (每次都 np.stack):\",\n",
    "      bench(lambda: compute_batch_cold(J_list, L_list, z_list, h_list, x)) * 1e3, \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad5346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "nodes = [256, 512, 1024, 2048, 4096, 8196]\n",
    "\n",
    "iters_multi = [105, 77, 150, 100, 185, 304]\n",
    "iters_orig  = [868, 1669, 7566, 3434, 3449, 30000]  # lower bound for plot\n",
    "\n",
    "time_multi = [4.9899821281433105, 6.832485914230347, 28.867820739746094,\n",
    "              35.16724491119385, 156.85783433914185, 768.7591967582703]\n",
    "time_orig  = [10.840996980667114, 53.138646364212036, 593.8828203678131,\n",
    "              528.84259557724, 1184.7146832942963, 18000]  # lower bound for plot\n",
    "\n",
    "speedup_iters = [o/m for o, m in zip(iters_orig, iters_multi)]\n",
    "speedup_time  = [o/m for o, m in zip(time_orig, time_multi)]\n",
    "\n",
    "# Plot 1: iterations vs # of nodes\n",
    "plt.figure()\n",
    "plt.plot(nodes, iters_multi, marker='o', label='multi-level')\n",
    "plt.plot(nodes, iters_orig, marker='s', linestyle='--', label='original')\n",
    "\n",
    "# Label speedup above BLUE nodes (original curve)\n",
    "for x, y, s in zip(nodes, iters_orig, speedup_iters):\n",
    "    plt.text(x, y, f'{s:.2f}x', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('# of nodes')\n",
    "plt.ylabel('iterations')\n",
    "plt.title('Iterations vs # of Nodes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "# Plot 2: time vs # of nodes\n",
    "plt.figure()\n",
    "plt.plot(nodes, time_multi, marker='o', label='multi-level')\n",
    "plt.plot(nodes, time_orig, marker='s', linestyle='--', label='original')\n",
    "\n",
    "# Label speedup above BLUE nodes (original curve)\n",
    "for x, y, s in zip(nodes, time_orig, speedup_time):\n",
    "    plt.text(x, y, f'{s:.2f}x', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('# of nodes')\n",
    "plt.ylabel('time (s)')\n",
    "plt.title('Time vs # of Nodes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9bc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e42544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf06b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iteration time:  0.4568\n",
      "super1:  0.35009999999999997\n",
      "ratio:  0.7664185639229422\n",
      "\n",
      "total building and backing time:  1.1084999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"total iteration time: \", 0.1708+0.0386+0.0044+0.0015+0.0002+0.0001+0.0001+0.0018+0.0011+0.0145+0.0444+0.1793)\n",
    "print(\"super1: \", 0.1708+0.1793)\n",
    "print(\"ratio: \", 0.35009999999999997/0.4568)\n",
    "\n",
    "print(\"\")\n",
    "print(\"total building and backing time: \", 0.0774+0.1253+0.0925+0.4952+0.2424 + 0.0000+0.0003+0.0004+0.0081+0.0121+0.0548)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140348b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "aa = deepcopy(layers[1][\"graph\"])\n",
    "for i in range(1000):\n",
    "    aa.synchronous_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "for i in range(1000):\n",
    "    layers[-1][\"graph\"].synchronous_iteration()\n",
    "\n",
    "bb = deepcopy(layers[-1][\"graph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21979a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[2][\"graph\"] = deepcopy(bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd2bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.3736346  104.33323553]\n",
      "[ 44.3736346  104.33323553]\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(\n",
    "    layers[:3], eta_damping=0, r_reduced=2)\n",
    "\n",
    "#layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "print(layers[abs_layer_idx][\"graph\"].var_nodes[0].mu)\n",
    "print(bb.var_nodes[0].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.38048663 104.34497706]\n",
      "[ 44.3736346  104.33323553]\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"].compute_all_messages()\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "print(layers[abs_layer_idx][\"graph\"].var_nodes[0].mu)\n",
    "bb.synchronous_iteration\n",
    "print(bb.var_nodes[0].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2342.435012\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_super_graph(layers[:3])\n",
    "top_down_modify_base_and_abs_graph(layers[:2])\n",
    "\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cffe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.55637974e+00, -2.08956516e-16],\n",
       "       [-2.08957089e-16,  3.55637974e+00]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"].var_nodes[0].Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c9bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.55637974e+00, -2.08956489e-16],\n",
       "       [-2.08957608e-16,  3.55637974e+00]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.var_nodes[0].Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2328.725297\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "abs_graph, Bs, ks, k2s = bottom_up_modify_abs_graph(layers[:], eta_damping=0)\n",
    "layers[2][\"graph\"] = abs_graph\n",
    "layers[2][\"Bs\"], layers[2][\"ks\"], layers[2][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "layers[2][\"graph\"].synchronous_iteration()\n",
    "layers[2][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_super_graph(layers[:3])\n",
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_base_and_abs_graph(layers[:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74759123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2328.725279\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for i in range(1, len(layers)):\n",
    "        name = layers[i][\"name\"]\n",
    "\n",
    "        if name.startswith(\"super1\"):\n",
    "            # Update super using the previous base graph's new linearization points\n",
    "            pass\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            layers[i][\"graph\"] = build_super_graph(layers[:i+1], eta_damping=0)\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Rebuild abs using the previous super\n",
    "            abs_graph, Bs, ks, k2s = bottom_up_modify_abs_graph(layers[:i+1], eta_damping=0)\n",
    "            layers[i][\"graph\"] = abs_graph\n",
    "            layers[i][\"Bs\"], layers[i][\"ks\"], layers[i][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "        # After build, one iteration per layer\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "    # ---- top-down (pass mu) ----\n",
    "    for i in range(len(layers) - 1, 0, -1):\n",
    "        # After one iterations per layer, reproject\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "        # this is very important, but dont know why yet\n",
    "        # so abs layer need more iterations\n",
    "        #if name.startswith(\"abs\"):\n",
    "        #    layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "        name = layers[i][\"name\"]\n",
    "        if name.startswith(\"super\"):\n",
    "            # Split super.mu back to base/abs\n",
    "            top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Project abs.mu back to super\n",
    "            top_down_modify_super_graph(layers[:i+1])\n",
    "\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23715db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Energy = 2333.057456\n",
      "Iter 1000 | Energy = 2342.434528\n",
      "Iter 1000 | Energy = 2346.848939\n",
      "Iter 1000 | Energy = 2342.829773\n",
      "Iter 1000 | Energy = 2335.406501\n",
      "Iter 1000 | Energy = 2329.460781\n",
      "Iter 1000 | Energy = 2326.647628\n",
      "Iter 1000 | Energy = 2326.626961\n",
      "Iter 1000 | Energy = 2328.345039\n",
      "Iter 1000 | Energy = 2330.722005\n",
      "Iter 1000 | Energy = 2332.962662\n",
      "Iter 1000 | Energy = 2334.638546\n",
      "Iter 1000 | Energy = 2335.631414\n",
      "Iter 1000 | Energy = 2336.017356\n",
      "Iter 1000 | Energy = 2335.954211\n",
      "Iter 1000 | Energy = 2335.604993\n",
      "Iter 1000 | Energy = 2335.101330\n",
      "Iter 1000 | Energy = 2334.535153\n",
      "Iter 1000 | Energy = 2333.964155\n",
      "Iter 1000 | Energy = 2333.420888\n",
      "Iter 1000 | Energy = 2332.920827\n",
      "Iter 1000 | Energy = 2332.468334\n",
      "Iter 1000 | Energy = 2332.060933\n",
      "Iter 1000 | Energy = 2331.692470\n",
      "Iter 1000 | Energy = 2331.355442\n",
      "Iter 1000 | Energy = 2331.042599\n",
      "Iter 1000 | Energy = 2330.747874\n",
      "Iter 1000 | Energy = 2330.466759\n",
      "Iter 1000 | Energy = 2330.196290\n",
      "Iter 1000 | Energy = 2329.934812\n",
      "Iter 1000 | Energy = 2329.681658\n",
      "Iter 1000 | Energy = 2329.436830\n",
      "Iter 1000 | Energy = 2329.200709\n",
      "Iter 1000 | Energy = 2328.973831\n",
      "Iter 1000 | Energy = 2328.756714\n",
      "Iter 1000 | Energy = 2328.549747\n",
      "Iter 1000 | Energy = 2328.353128\n",
      "Iter 1000 | Energy = 2328.166851\n",
      "Iter 1000 | Energy = 2327.990716\n",
      "Iter 1000 | Energy = 2327.824369\n",
      "Iter 1000 | Energy = 2327.667349\n",
      "Iter 1000 | Energy = 2327.519130\n",
      "Iter 1000 | Energy = 2327.379160\n",
      "Iter 1000 | Energy = 2327.246897\n",
      "Iter 1000 | Energy = 2327.121824\n",
      "Iter 1000 | Energy = 2327.003463\n",
      "Iter 1000 | Energy = 2326.891382\n",
      "Iter 1000 | Energy = 2326.785194\n",
      "Iter 1000 | Energy = 2326.684551\n",
      "Iter 1000 | Energy = 2326.589143\n",
      "Iter 1000 | Energy = 2326.498690\n",
      "Iter 1000 | Energy = 2326.412933\n",
      "Iter 1000 | Energy = 2326.331635\n",
      "Iter 1000 | Energy = 2326.254574\n",
      "Iter 1000 | Energy = 2326.181536\n",
      "Iter 1000 | Energy = 2326.112322\n",
      "Iter 1000 | Energy = 2326.046737\n",
      "Iter 1000 | Energy = 2325.984597\n",
      "Iter 1000 | Energy = 2325.925723\n",
      "Iter 1000 | Energy = 2325.869946\n",
      "Iter 1000 | Energy = 2325.817103\n",
      "Iter 1000 | Energy = 2325.767039\n",
      "Iter 1000 | Energy = 2325.719608\n",
      "Iter 1000 | Energy = 2325.674670\n",
      "Iter 1000 | Energy = 2325.632093\n",
      "Iter 1000 | Energy = 2325.591752\n",
      "Iter 1000 | Energy = 2325.553529\n",
      "Iter 1000 | Energy = 2325.517313\n",
      "Iter 1000 | Energy = 2325.482997\n",
      "Iter 1000 | Energy = 2325.450483\n",
      "Iter 1000 | Energy = 2325.419675\n",
      "Iter 1000 | Energy = 2325.390484\n",
      "Iter 1000 | Energy = 2325.362825\n",
      "Iter 1000 | Energy = 2325.336619\n",
      "Iter 1000 | Energy = 2325.311788\n",
      "Iter 1000 | Energy = 2325.288261\n",
      "Iter 1000 | Energy = 2325.265970\n",
      "Iter 1000 | Energy = 2325.244849\n",
      "Iter 1000 | Energy = 2325.224838\n",
      "Iter 1000 | Energy = 2325.205877\n",
      "Iter 1000 | Energy = 2325.187912\n",
      "Iter 1000 | Energy = 2325.170891\n",
      "Iter 1000 | Energy = 2325.154763\n",
      "Iter 1000 | Energy = 2325.139482\n",
      "Iter 1000 | Energy = 2325.125004\n",
      "Iter 1000 | Energy = 2325.111286\n",
      "Iter 1000 | Energy = 2325.098288\n",
      "Iter 1000 | Energy = 2325.085973\n",
      "Iter 1000 | Energy = 2325.074304\n",
      "Iter 1000 | Energy = 2325.063248\n",
      "Iter 1000 | Energy = 2325.052773\n",
      "Iter 1000 | Energy = 2325.042848\n",
      "Iter 1000 | Energy = 2325.033444\n",
      "Iter 1000 | Energy = 2325.024533\n",
      "Iter 1000 | Energy = 2325.016091\n",
      "Iter 1000 | Energy = 2325.008092\n",
      "Iter 1000 | Energy = 2325.000513\n",
      "Iter 1000 | Energy = 2324.993331\n",
      "Iter 1000 | Energy = 2324.986527\n",
      "Iter 1000 | Energy = 2324.980080\n",
      "Iter 1000 | Energy = 2324.973972\n",
      "Iter 1000 | Energy = 2324.968184\n",
      "Iter 1000 | Energy = 2324.962701\n",
      "Iter 1000 | Energy = 2324.957505\n",
      "Iter 1000 | Energy = 2324.952582\n",
      "Iter 1000 | Energy = 2324.947918\n",
      "Iter 1000 | Energy = 2324.943498\n",
      "Iter 1000 | Energy = 2324.939311\n",
      "Iter 1000 | Energy = 2324.935343\n",
      "Iter 1000 | Energy = 2324.931584\n",
      "Iter 1000 | Energy = 2324.928022\n",
      "Iter 1000 | Energy = 2324.924647\n",
      "Iter 1000 | Energy = 2324.921449\n",
      "Iter 1000 | Energy = 2324.918419\n",
      "Iter 1000 | Energy = 2324.915549\n",
      "Iter 1000 | Energy = 2324.912829\n",
      "Iter 1000 | Energy = 2324.910251\n",
      "Iter 1000 | Energy = 2324.907810\n",
      "Iter 1000 | Energy = 2324.905496\n",
      "Iter 1000 | Energy = 2324.903304\n",
      "Iter 1000 | Energy = 2324.901227\n",
      "Iter 1000 | Energy = 2324.899259\n",
      "Iter 1000 | Energy = 2324.897394\n",
      "Iter 1000 | Energy = 2324.895627\n",
      "Iter 1000 | Energy = 2324.893953\n",
      "Iter 1000 | Energy = 2324.892367\n",
      "Iter 1000 | Energy = 2324.890864\n",
      "Iter 1000 | Energy = 2324.889440\n",
      "Iter 1000 | Energy = 2324.888091\n",
      "Iter 1000 | Energy = 2324.886813\n",
      "Iter 1000 | Energy = 2324.885602\n",
      "Iter 1000 | Energy = 2324.884454\n",
      "Iter 1000 | Energy = 2324.883367\n",
      "Iter 1000 | Energy = 2324.882336\n",
      "Iter 1000 | Energy = 2324.881360\n",
      "Iter 1000 | Energy = 2324.880435\n",
      "Iter 1000 | Energy = 2324.879559\n",
      "Iter 1000 | Energy = 2324.878729\n",
      "Iter 1000 | Energy = 2324.877942\n",
      "Iter 1000 | Energy = 2324.877196\n",
      "Iter 1000 | Energy = 2324.876490\n",
      "Iter 1000 | Energy = 2324.875821\n",
      "Iter 1000 | Energy = 2324.875187\n",
      "Iter 1000 | Energy = 2324.874586\n",
      "Iter 1000 | Energy = 2324.874017\n",
      "Iter 1000 | Energy = 2324.873477\n",
      "Iter 1000 | Energy = 2324.872966\n",
      "Iter 1000 | Energy = 2324.872482\n",
      "Iter 1000 | Energy = 2324.872023\n",
      "Iter 1000 | Energy = 2324.871589\n",
      "Iter 1000 | Energy = 2324.871177\n",
      "Iter 1000 | Energy = 2324.870787\n",
      "Iter 1000 | Energy = 2324.870417\n",
      "Iter 1000 | Energy = 2324.870066\n",
      "Iter 1000 | Energy = 2324.869735\n",
      "Iter 1000 | Energy = 2324.869420\n",
      "Iter 1000 | Energy = 2324.869122\n",
      "Iter 1000 | Energy = 2324.868840\n",
      "Iter 1000 | Energy = 2324.868572\n",
      "Iter 1000 | Energy = 2324.868319\n",
      "Iter 1000 | Energy = 2324.868078\n",
      "Iter 1000 | Energy = 2324.867851\n",
      "Iter 1000 | Energy = 2324.867635\n",
      "Iter 1000 | Energy = 2324.867431\n",
      "Iter 1000 | Energy = 2324.867237\n",
      "Iter 1000 | Energy = 2324.867054\n",
      "Iter 1000 | Energy = 2324.866880\n",
      "Iter 1000 | Energy = 2324.866716\n",
      "Iter 1000 | Energy = 2324.866560\n",
      "Iter 1000 | Energy = 2324.866412\n",
      "Iter 1000 | Energy = 2324.866272\n",
      "Iter 1000 | Energy = 2324.866139\n",
      "Iter 1000 | Energy = 2324.866013\n",
      "Iter 1000 | Energy = 2324.865894\n",
      "Iter 1000 | Energy = 2324.865781\n",
      "Iter 1000 | Energy = 2324.865674\n",
      "Iter 1000 | Energy = 2324.865573\n",
      "Iter 1000 | Energy = 2324.865477\n",
      "Iter 1000 | Energy = 2324.865386\n",
      "Iter 1000 | Energy = 2324.865300\n",
      "Iter 1000 | Energy = 2324.865218\n",
      "Iter 1000 | Energy = 2324.865141\n",
      "Iter 1000 | Energy = 2324.865067\n",
      "Iter 1000 | Energy = 2324.864998\n",
      "Iter 1000 | Energy = 2324.864932\n",
      "Iter 1000 | Energy = 2324.864870\n",
      "Iter 1000 | Energy = 2324.864811\n",
      "Iter 1000 | Energy = 2324.864755\n",
      "Iter 1000 | Energy = 2324.864701\n",
      "Iter 1000 | Energy = 2324.864651\n",
      "Iter 1000 | Energy = 2324.864604\n",
      "Iter 1000 | Energy = 2324.864558\n",
      "Iter 1000 | Energy = 2324.864516\n",
      "Iter 1000 | Energy = 2324.864475\n",
      "Iter 1000 | Energy = 2324.864437\n",
      "Iter 1000 | Energy = 2324.864400\n",
      "Iter 1000 | Energy = 2324.864366\n",
      "Iter 1000 | Energy = 2324.864333\n",
      "Iter 1000 | Energy = 2324.864302\n",
      "Iter 1000 | Energy = 2324.864273\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "for i in range(1):\n",
    "    layers[-1][\"graph\"].synchronous_iteration()\n",
    "    top_down_modify_super_graph(layers[:])\n",
    "    top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Energy = 2333.057544\n",
      "Iter 1000 | Energy = 2339.952725\n",
      "Iter 1000 | Energy = 2347.586783\n",
      "Iter 1000 | Energy = 2352.982718\n",
      "Iter 1000 | Energy = 2357.693991\n",
      "Iter 1000 | Energy = 2361.411014\n",
      "Iter 1000 | Energy = 2365.057877\n",
      "Iter 1000 | Energy = 2368.261650\n",
      "Iter 1000 | Energy = 2371.582692\n",
      "Iter 1000 | Energy = 2374.661040\n",
      "Iter 1000 | Energy = 2377.845726\n",
      "Iter 1000 | Energy = 2380.855475\n",
      "Iter 1000 | Energy = 2383.912300\n",
      "Iter 1000 | Energy = 2386.818810\n",
      "Iter 1000 | Energy = 2389.717175\n",
      "Iter 1000 | Energy = 2392.477801\n",
      "Iter 1000 | Energy = 2395.191398\n",
      "Iter 1000 | Energy = 2397.777201\n",
      "Iter 1000 | Energy = 2400.292543\n",
      "Iter 1000 | Energy = 2402.689672\n",
      "Iter 1000 | Energy = 2405.004386\n",
      "Iter 1000 | Energy = 2407.210328\n",
      "Iter 1000 | Energy = 2409.329563\n",
      "Iter 1000 | Energy = 2411.349136\n",
      "Iter 1000 | Energy = 2413.282492\n",
      "Iter 1000 | Energy = 2415.124784\n",
      "Iter 1000 | Energy = 2416.884155\n",
      "Iter 1000 | Energy = 2418.560459\n",
      "Iter 1000 | Energy = 2420.158657\n",
      "Iter 1000 | Energy = 2421.681164\n",
      "Iter 1000 | Energy = 2423.131086\n",
      "Iter 1000 | Energy = 2424.512092\n",
      "Iter 1000 | Energy = 2425.826246\n",
      "Iter 1000 | Energy = 2427.077689\n",
      "Iter 1000 | Energy = 2428.267934\n",
      "Iter 1000 | Energy = 2429.401148\n",
      "Iter 1000 | Energy = 2430.478569\n",
      "Iter 1000 | Energy = 2431.504155\n",
      "Iter 1000 | Energy = 2432.479022\n",
      "Iter 1000 | Energy = 2433.406803\n",
      "Iter 1000 | Energy = 2434.288568\n",
      "Iter 1000 | Energy = 2435.127586\n",
      "Iter 1000 | Energy = 2435.924912\n",
      "Iter 1000 | Energy = 2436.683451\n",
      "Iter 1000 | Energy = 2437.404254\n",
      "Iter 1000 | Energy = 2438.089883\n",
      "Iter 1000 | Energy = 2438.741377\n",
      "Iter 1000 | Energy = 2439.360990\n",
      "Iter 1000 | Energy = 2439.949741\n",
      "Iter 1000 | Energy = 2440.509609\n",
      "Iter 1000 | Energy = 2441.041583\n",
      "Iter 1000 | Energy = 2441.547402\n",
      "Iter 1000 | Energy = 2442.028017\n",
      "Iter 1000 | Energy = 2442.484955\n",
      "Iter 1000 | Energy = 2442.919122\n",
      "Iter 1000 | Energy = 2443.331864\n",
      "Iter 1000 | Energy = 2443.724038\n",
      "Iter 1000 | Energy = 2444.096829\n",
      "Iter 1000 | Energy = 2444.451042\n",
      "Iter 1000 | Energy = 2444.787726\n",
      "Iter 1000 | Energy = 2445.107631\n",
      "Iter 1000 | Energy = 2445.411687\n",
      "Iter 1000 | Energy = 2445.700589\n",
      "Iter 1000 | Energy = 2445.975163\n",
      "Iter 1000 | Energy = 2446.236054\n",
      "Iter 1000 | Energy = 2446.483995\n",
      "Iter 1000 | Energy = 2446.719578\n",
      "Iter 1000 | Energy = 2446.943460\n",
      "Iter 1000 | Energy = 2447.156182\n",
      "Iter 1000 | Energy = 2447.358332\n",
      "Iter 1000 | Energy = 2447.550405\n",
      "Iter 1000 | Energy = 2447.732926\n",
      "Iter 1000 | Energy = 2447.906349\n",
      "Iter 1000 | Energy = 2448.071144\n",
      "Iter 1000 | Energy = 2448.227722\n",
      "Iter 1000 | Energy = 2448.376508\n",
      "Iter 1000 | Energy = 2448.517875\n",
      "Iter 1000 | Energy = 2448.652204\n",
      "Iter 1000 | Energy = 2448.779835\n",
      "Iter 1000 | Energy = 2448.901109\n",
      "Iter 1000 | Energy = 2449.016336\n",
      "Iter 1000 | Energy = 2449.125822\n",
      "Iter 1000 | Energy = 2449.229849\n",
      "Iter 1000 | Energy = 2449.328691\n",
      "Iter 1000 | Energy = 2449.422605\n",
      "Iter 1000 | Energy = 2449.511837\n",
      "Iter 1000 | Energy = 2449.596620\n",
      "Iter 1000 | Energy = 2449.677176\n",
      "Iter 1000 | Energy = 2449.753714\n",
      "Iter 1000 | Energy = 2449.826436\n",
      "Iter 1000 | Energy = 2449.895530\n",
      "Iter 1000 | Energy = 2449.961180\n",
      "Iter 1000 | Energy = 2450.023554\n",
      "Iter 1000 | Energy = 2450.082818\n",
      "Iter 1000 | Energy = 2450.139126\n",
      "Iter 1000 | Energy = 2450.192625\n",
      "Iter 1000 | Energy = 2450.243455\n",
      "Iter 1000 | Energy = 2450.291750\n",
      "Iter 1000 | Energy = 2450.337635\n",
      "Iter 1000 | Energy = 2450.381231\n",
      "Iter 1000 | Energy = 2450.422653\n",
      "Iter 1000 | Energy = 2450.462008\n",
      "Iter 1000 | Energy = 2450.499399\n",
      "Iter 1000 | Energy = 2450.534925\n",
      "Iter 1000 | Energy = 2450.568678\n",
      "Iter 1000 | Energy = 2450.600747\n",
      "Iter 1000 | Energy = 2450.631216\n",
      "Iter 1000 | Energy = 2450.660165\n",
      "Iter 1000 | Energy = 2450.687669\n",
      "Iter 1000 | Energy = 2450.713801\n",
      "Iter 1000 | Energy = 2450.738629\n",
      "Iter 1000 | Energy = 2450.762218\n",
      "Iter 1000 | Energy = 2450.784630\n",
      "Iter 1000 | Energy = 2450.805923\n",
      "Iter 1000 | Energy = 2450.826154\n",
      "Iter 1000 | Energy = 2450.845375\n",
      "Iter 1000 | Energy = 2450.863637\n",
      "Iter 1000 | Energy = 2450.880988\n",
      "Iter 1000 | Energy = 2450.897473\n",
      "Iter 1000 | Energy = 2450.913135\n",
      "Iter 1000 | Energy = 2450.928015\n",
      "Iter 1000 | Energy = 2450.942153\n",
      "Iter 1000 | Energy = 2450.955585\n",
      "Iter 1000 | Energy = 2450.968347\n",
      "Iter 1000 | Energy = 2450.980472\n",
      "Iter 1000 | Energy = 2450.991992\n",
      "Iter 1000 | Energy = 2451.002937\n",
      "Iter 1000 | Energy = 2451.013336\n",
      "Iter 1000 | Energy = 2451.023215\n",
      "Iter 1000 | Energy = 2451.032602\n",
      "Iter 1000 | Energy = 2451.041520\n",
      "Iter 1000 | Energy = 2451.049993\n",
      "Iter 1000 | Energy = 2451.058043\n",
      "Iter 1000 | Energy = 2451.065691\n",
      "Iter 1000 | Energy = 2451.072958\n",
      "Iter 1000 | Energy = 2451.079862\n",
      "Iter 1000 | Energy = 2451.086421\n",
      "Iter 1000 | Energy = 2451.092653\n",
      "Iter 1000 | Energy = 2451.098574\n",
      "Iter 1000 | Energy = 2451.104199\n",
      "Iter 1000 | Energy = 2451.109544\n",
      "Iter 1000 | Energy = 2451.114622\n",
      "Iter 1000 | Energy = 2451.119446\n",
      "Iter 1000 | Energy = 2451.124030\n",
      "Iter 1000 | Energy = 2451.128384\n",
      "Iter 1000 | Energy = 2451.132522\n",
      "Iter 1000 | Energy = 2451.136453\n",
      "Iter 1000 | Energy = 2451.140188\n",
      "Iter 1000 | Energy = 2451.143736\n",
      "Iter 1000 | Energy = 2451.147107\n",
      "Iter 1000 | Energy = 2451.150310\n",
      "Iter 1000 | Energy = 2451.153353\n",
      "Iter 1000 | Energy = 2451.156244\n",
      "Iter 1000 | Energy = 2451.158991\n",
      "Iter 1000 | Energy = 2451.161601\n",
      "Iter 1000 | Energy = 2451.164080\n",
      "Iter 1000 | Energy = 2451.166436\n",
      "Iter 1000 | Energy = 2451.168674\n",
      "Iter 1000 | Energy = 2451.170801\n",
      "Iter 1000 | Energy = 2451.172821\n",
      "Iter 1000 | Energy = 2451.174740\n",
      "Iter 1000 | Energy = 2451.176564\n",
      "Iter 1000 | Energy = 2451.178297\n",
      "Iter 1000 | Energy = 2451.179943\n",
      "Iter 1000 | Energy = 2451.181507\n",
      "Iter 1000 | Energy = 2451.182993\n",
      "Iter 1000 | Energy = 2451.184405\n",
      "Iter 1000 | Energy = 2451.185746\n",
      "Iter 1000 | Energy = 2451.187020\n",
      "Iter 1000 | Energy = 2451.188231\n",
      "Iter 1000 | Energy = 2451.189381\n",
      "Iter 1000 | Energy = 2451.190474\n",
      "Iter 1000 | Energy = 2451.191512\n",
      "Iter 1000 | Energy = 2451.192499\n",
      "Iter 1000 | Energy = 2451.193436\n",
      "Iter 1000 | Energy = 2451.194326\n",
      "Iter 1000 | Energy = 2451.195173\n",
      "Iter 1000 | Energy = 2451.195976\n",
      "Iter 1000 | Energy = 2451.196740\n",
      "Iter 1000 | Energy = 2451.197466\n",
      "Iter 1000 | Energy = 2451.198155\n",
      "Iter 1000 | Energy = 2451.198810\n",
      "Iter 1000 | Energy = 2451.199432\n",
      "Iter 1000 | Energy = 2451.200023\n",
      "Iter 1000 | Energy = 2451.200585\n",
      "Iter 1000 | Energy = 2451.201118\n",
      "Iter 1000 | Energy = 2451.201625\n",
      "Iter 1000 | Energy = 2451.202107\n",
      "Iter 1000 | Energy = 2451.202565\n",
      "Iter 1000 | Energy = 2451.203000\n",
      "Iter 1000 | Energy = 2451.203413\n",
      "Iter 1000 | Energy = 2451.203805\n",
      "Iter 1000 | Energy = 2451.204178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mBs\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mks\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mk2s\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mbottom_up_modify_abs_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m].synchronous_iteration()\n\u001b[32m      4\u001b[39m     top_down_modify_super_graph(layers[:])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1290\u001b[39m, in \u001b[36mbottom_up_modify_abs_graph\u001b[39m\u001b[34m(layers, r_reduced, eta_damping)\u001b[39m\n\u001b[32m   1288\u001b[39m i, j = [v.variableID \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f.adj_var_nodes]\n\u001b[32m   1289\u001b[39m vi, vj = abs_var_nodes[i], abs_var_nodes[j]\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m abs_f = \u001b[43mFactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeas_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1291\u001b[39m abs_f.type = \u001b[33m\"\u001b[39m\u001b[33mabs_between\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1292\u001b[39m abs_f.adj_beliefs = [vi.belief, vj.belief]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:720\u001b[39m, in \u001b[36mFactor.__init__\u001b[39m\u001b[34m(self, factor_id, adj_var_nodes, measurement, measurement_lambda, meas_fn, jac_fn, loss, mahalanobis_threshold, wildfire, *args)\u001b[39m\n\u001b[32m    718\u001b[39m     \u001b[38;5;28mself\u001b[39m.adj_beliefs.append(NdimGaussian(adj_var_node.dofs))\n\u001b[32m    719\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages.append(NdimGaussian(adj_var_node.dofs))\u001b[38;5;66;03m#, eta=adj_var_node.prior.eta, lam=adj_var_node.prior.lam))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages_prior.append(\u001b[43mNdimGaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_var_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdofs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages_dist.append(np.zeros(adj_var_node.dofs))\n\u001b[32m    723\u001b[39m \u001b[38;5;28mself\u001b[39m.factor = NdimGaussian(\u001b[38;5;28mself\u001b[39m.dofs_conditional_vars)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/utils/gaussian.py:16\u001b[39m, in \u001b[36mNdimGaussian.__init__\u001b[39m\u001b[34m(self, dimensionality, eta, lam)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.lam = lam\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28mself\u001b[39m.lam = np.zeros([\u001b[38;5;28mself\u001b[39m.dim, \u001b[38;5;28mself\u001b[39m.dim])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "    layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "    top_down_modify_super_graph(layers[:])\n",
    "    top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b8fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 531 | Energy = 2335.263449\n"
     ]
    }
   ],
   "source": [
    "top_down_modify_super_graph(layers[:])\n",
    "top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 531 | Energy = 2334.490358\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825805e-09,  7.00557252e-09])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(layers[0][\"graph\"].var_nodes[0].adj_factors[1].adj_beliefs[0].lam, layers[0][\"graph\"].var_nodes[0].adj_factors[1].adj_beliefs[0].eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd50e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825829e-09,  7.00557253e-09])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e157ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825799e-09,  7.00557250e-09,  3.94963401e+00, -2.51772335e+01,\n",
       "        2.59936671e+01, -3.96819499e+01,  3.85359407e+01, -6.20493563e+01,\n",
       "        1.33215562e+01, -7.12420831e+01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[1][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7b2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825829e-09,  7.00557253e-09])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abc516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5cfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Energy: 2348.0945'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_energy(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03313253012048193"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2401-2324)/2324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2481.58433706"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2402*(1.03313253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.988972036403319\n",
      "Iter 1000 | Energy = 7.815849\n",
      "Iter 1000 | Energy = 6.885167\n",
      "Iter 1000 | Energy = 6.902868\n",
      "Iter 1000 | Energy = 6.909297\n",
      "Iter 1000 | Energy = 6.910688\n",
      "Iter 1000 | Energy = 6.911066\n",
      "Iter 1000 | Energy = 6.911152\n",
      "Iter 1000 | Energy = 6.911174\n",
      "Iter 1000 | Energy = 6.911179\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n"
     ]
    }
   ],
   "source": [
    "N=6\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "# Create GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(layers[0][\"nodes\"], layers[0][\"edges\"], k=2, layer_idx=1, tail_heavy=True)\n",
    "layers.append({\"name\":f\"super{1}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "layers[0][\"graph\"].synchronous_iteration()\n",
    "layers[1][\"graph\"] = build_super_graph(layers,eta_damping=0)\n",
    "supergraph = layers[-1][\"graph\"]\n",
    "\n",
    "\n",
    "total = 0\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n",
    "\n",
    "abs_nodes, abs_edges = copy_to_abs(layers[1][\"nodes\"], layers[1][\"edges\"], 2)\n",
    "\n",
    "# Ensure super graph has run at least once\n",
    "#layers[1][\"graph\"].synchronous_iteration() \n",
    "r = 2\n",
    "layers.append({\"name\":f\"abs{1}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[2][\"graph\"], layers[2][\"Bs\"], layers[2][\"ks\"], layers[2][\"k2s\"] = build_abs_graph(layers, r_reduced=r)\n",
    "\n",
    "vg = VGraph(layers, eta_damping=0)\n",
    "for i in range(50):\n",
    "    vg.layers = layers\n",
    "    vg.layers = vg.vloop()\n",
    "    layers = vg.layers\n",
    "    refresh_gbp_results(layers)\n",
    "    energy = supergraph.energy_map(include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matmul time: 0.0009918212890625 seconds\n",
      "jax devices: [CudaDevice(id=0)]\n",
      "Result device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "\n",
    "@jit\n",
    "def matmul(x, y):\n",
    "    return x @ y\n",
    "\n",
    "x = jnp.ones((2000, 8000))\n",
    "y = jnp.ones((8000, 2000))\n",
    "\n",
    "# 预热（第一次会 JIT 编译）\n",
    "_ = matmul(x, y).block_until_ready()\n",
    "\n",
    "t0 = time.time()\n",
    "out = matmul(x, y).block_until_ready()\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Matmul time:\", t1 - t0, \"seconds\")\n",
    "print(\"jax devices:\", jax.devices())\n",
    "print(\"Result device:\", out.device)   # ✅ 这里不要加 ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7172e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    out = matmul(x, y).block_until_ready()\n",
    "t1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.ones((2000, 8000))\n",
    "y = np.ones((8000, 2000))\n",
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    out = x@y\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055d3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnvidia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcusparse\u001b[39;00m  \u001b[38;5;66;03m# 先把 wheel 里的 cusparse 模块 import 进来\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 找到 pip 安装的 cuSPARSE 动态库所在目录\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m cusparse_lib_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnvidia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcusparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcusparse_lib_dir =\u001b[39m\u001b[38;5;124m\"\u001b[39m, cusparse_lib_dir)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 把 LD_LIBRARY_PATH 显式设置成这个目录（再附带上原来的其它目录）\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import nvidia.cusparse  # 先把 wheel 里的 cusparse 模块 import 进来\n",
    "\n",
    "# 找到 pip 安装的 cuSPARSE 动态库所在目录\n",
    "cusparse_lib_dir = str(pathlib.Path(nvidia.cusparse.__file__).parent)\n",
    "print(\"cusparse_lib_dir =\", cusparse_lib_dir)\n",
    "\n",
    "# 把 LD_LIBRARY_PATH 显式设置成这个目录（再附带上原来的其它目录）\n",
    "old = os.environ.get(\"LD_LIBRARY_PATH\") or \"\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = cusparse_lib_dir + (\":\" + old if old else \"\")\n",
    "print(\"LD_LIBRARY_PATH =\", os.environ[\"LD_LIBRARY_PATH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a395886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008997083362999205\n"
     ]
    }
   ],
   "source": [
    "print((6.988972036403319-6.911181)/6.988972036403319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 010 | Energy = 6.911181\n"
     ]
    }
   ],
   "source": [
    "energy = layers[1][\"graph\"].energy_map(include_priors=True, include_factors=True)\n",
    "print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bcb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.24417217, -24.77807379])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[2][\"graph\"].var_nodes[0].mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
