{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db67ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output, State, no_update\n",
    "import dash_cytoscape as cyto\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "# ==== GBP import ====\n",
    "from gbp.gbp import *\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"Factor Graph SVD Abs&Recovery\"\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# SLAM-like base graph\n",
    "# -----------------------\n",
    "def make_slam_like_graph(N=100, step_size=25, loop_prob=0.05, loop_radius=50, prior_prop=0.0, seed=None):\n",
    "    if seed is None :\n",
    "        rng = np.random.default_rng()  # ✅ Ensure we have an RNG\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    nodes, edges = [], []\n",
    "    positions = []\n",
    "    x, y = 0.0, 0.0\n",
    "    positions.append((x, y))\n",
    "\n",
    "    # ✅ Deterministic-by-RNG: trajectory generation\n",
    "    for _ in range(1, int(N)):\n",
    "        dx, dy = rng.standard_normal(2)  # replace np.random.randn\n",
    "        norm = np.sqrt(dx**2 + dy**2) + 1e-6\n",
    "        dx, dy = dx / norm * float(step_size), dy / norm * float(step_size)\n",
    "        x, y = x + dx, y + dy\n",
    "        positions.append((x, y))\n",
    "\n",
    "    # Sequential edges along the path\n",
    "    for i, (px, py) in enumerate(positions):\n",
    "        nodes.append({\n",
    "            \"data\": {\"id\": f\"{i}\", \"layer\": 0, \"dim\": 2, \"num_base\": 1},\n",
    "            \"position\": {\"x\": float(px), \"y\": float(py)}\n",
    "        })\n",
    "\n",
    "    for i in range(int(N) - 1):\n",
    "        edges.append({\"data\": {\"source\": f\"{i}\", \"target\": f\"{i+1}\"}})\n",
    "\n",
    "    # ✅ Deterministic-by-RNG: loop-closure edges\n",
    "    for i in range(int(N)):\n",
    "        for j in range(i + 5, int(N)):\n",
    "            if rng.random() < float(loop_prob):  # replace np.random.rand\n",
    "                xi, yi = positions[i]\n",
    "                xj, yj = positions[j]\n",
    "                if np.hypot(xi - xj, yi - yj) < float(loop_radius):\n",
    "                    edges.append({\"data\": {\"source\": f\"{i}\", \"target\": f\"{j}\"}})\n",
    "\n",
    "    # ✅ Sample priors using the same RNG\n",
    "    if prior_prop <= 0.0:\n",
    "        strong_ids = {0}\n",
    "    elif prior_prop >= 1.0:\n",
    "        strong_ids = set(range(N))\n",
    "    else:\n",
    "        k = max(1, int(np.floor(prior_prop * N)))\n",
    "        strong_ids = set(rng.choice(N, size=k, replace=False).tolist())\n",
    "\n",
    "    # Add edges for nodes with strong priors\n",
    "    for i in strong_ids:\n",
    "        edges.append({\"data\": {\"source\": f\"{i}\", \"target\": \"prior\"}})\n",
    "\n",
    "    edges.append({\"data\": {\"source\": f\"{0}\", \"target\": \"anchor\"}}) \n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Grid aggregation\n",
    "# -----------------------\n",
    "def fuse_to_super_grid(prev_nodes, prev_edges, gx, gy, layer_idx):\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "    xmin, ymin = positions.min(axis=0); xmax, ymax = positions.max(axis=0)\n",
    "    cell_w = (xmax - xmin) / gx if gx > 0 else 1.0\n",
    "    cell_h = (ymax - ymin) / gy if gy > 0 else 1.0\n",
    "    if cell_w == 0: cell_w = 1.0\n",
    "    if cell_h == 0: cell_h = 1.0\n",
    "    cell_map = {}\n",
    "    for idx, n in enumerate(prev_nodes):\n",
    "        x, y = n[\"position\"][\"x\"], n[\"position\"][\"y\"]\n",
    "        cx = min(int((x - xmin) / cell_w), gx - 1)\n",
    "        cy = min(int((y - ymin) / cell_h), gy - 1)\n",
    "        cid = cx + cy * gx\n",
    "        cell_map.setdefault(cid, []).append(idx)\n",
    "    super_nodes, node_map = [], {}\n",
    "    for cid, indices in cell_map.items():\n",
    "        pts = positions[indices]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in indices]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in indices]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums))\n",
    "        nid = str(len(super_nodes))\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val   # Inherit the sum\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        for i in indices:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            elif su == sv:\n",
    "                eid = tuple(sorted((su, \"prior\")))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = tuple(sorted((su, \"prior\")))\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "# -----------------------\n",
    "# K-Means aggregation\n",
    "# -----------------------\n",
    "def fuse_to_super_kmeans(prev_nodes, prev_edges, k, layer_idx, max_iters=20, tol=1e-6, seed=0):\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "    n = positions.shape[0]\n",
    "    if k <= 0: \n",
    "        k = 1\n",
    "    k = min(k, n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # -------- Improved initialization --------\n",
    "    # Randomly sample k points without replacement to ensure each cluster starts with a distinct point\n",
    "    init_idx = rng.choice(n, size=k, replace=False)\n",
    "    centers = positions[init_idx]\n",
    "\n",
    "    # Lloyd iterations\n",
    "    for _ in range(max_iters):\n",
    "        d2 = ((positions[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)\n",
    "        assign = np.argmin(d2, axis=1)\n",
    "\n",
    "        # -------- Empty-cluster fix --------\n",
    "        counts = np.bincount(assign, minlength=k)\n",
    "        empty_clusters = np.where(counts == 0)[0]\n",
    "        for ci in empty_clusters:\n",
    "            # Find the largest cluster\n",
    "            big_cluster = np.argmax(counts)\n",
    "            big_idxs = np.where(assign == big_cluster)[0]\n",
    "            # Steal one point over\n",
    "            steal_idx = big_idxs[0]\n",
    "            assign[steal_idx] = ci\n",
    "            counts[big_cluster] -= 1\n",
    "            counts[ci] += 1\n",
    "\n",
    "        moved = 0.0\n",
    "        for ci in range(k):\n",
    "            idxs = np.where(assign == ci)[0]\n",
    "            new_c = positions[idxs].mean(axis=0)\n",
    "            moved = max(moved, float(np.linalg.norm(new_c - centers[ci])))\n",
    "            centers[ci] = new_c\n",
    "        if moved < tol:\n",
    "            break\n",
    "\n",
    "    # Final assign (redo once to be safe)\n",
    "    d2 = ((positions[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)\n",
    "    assign = np.argmin(d2, axis=1)\n",
    "\n",
    "    counts = np.bincount(assign, minlength=k)\n",
    "    empty_clusters = np.where(counts == 0)[0]\n",
    "    for ci in empty_clusters:\n",
    "        big_cluster = np.argmax(counts)\n",
    "        big_idxs = np.where(assign == big_cluster)[0]\n",
    "        steal_idx = big_idxs[0]\n",
    "        assign[steal_idx] = ci\n",
    "        counts[big_cluster] -= 1\n",
    "        counts[ci] += 1\n",
    "\n",
    "    # ---------- Build the super graph ----------\n",
    "    super_nodes, node_map = [], {}\n",
    "    for ci in range(k):\n",
    "        idxs = np.where(assign == ci)[0]\n",
    "        pts = positions[idxs]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in idxs]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in idxs]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums)) \n",
    "        nid = f\"{ci}\"\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val   # Inherit the sum\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        for i in idxs:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            else:\n",
    "                eid = (su, \"prior\")\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = (su, \"prior\")\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "\n",
    "def copy_to_abs(super_nodes, super_edges, layer_idx):\n",
    "    abs_nodes = []\n",
    "    for n in super_nodes:\n",
    "        nid = n[\"data\"][\"id\"].replace(\"s\", \"a\", 1)\n",
    "        abs_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": n[\"data\"][\"dim\"],\n",
    "                \"num_base\": n[\"data\"].get(\"num_base\", 1)  # Inherit\n",
    "            },\n",
    "            \"position\": {\"x\": n[\"position\"][\"x\"], \"y\": n[\"position\"][\"y\"]}\n",
    "        })\n",
    "    abs_edges = []\n",
    "    for e in super_edges:\n",
    "        abs_edges.append({\"data\": {\n",
    "            \"source\": e[\"data\"][\"source\"].replace(\"s\", \"a\", 1),\n",
    "            \"target\": e[\"data\"][\"target\"].replace(\"s\", \"a\", 1)\n",
    "        }})\n",
    "    return abs_nodes, abs_edges\n",
    "\n",
    "# -----------------------\n",
    "# Sequential merge (tail group absorbs remainder)\n",
    "# -----------------------\n",
    "def fuse_to_super_order(prev_nodes, prev_edges, k, layer_idx, tail_heavy=True):\n",
    "    \"\"\"\n",
    "    Sequentially split prev_nodes in current order into k groups; the last group absorbs the remainder (tail_heavy=True).\n",
    "    Reuse existing rules for aggregating dim/num_base, deduplicating edges, and propagating prior.\n",
    "    \"\"\"\n",
    "    n = len(prev_nodes)\n",
    "    if k <= 0: k = 1\n",
    "    k = min(k, n)\n",
    "\n",
    "    # Group sizes\n",
    "    base = n // k\n",
    "    rem  = n %  k\n",
    "    if rem > 0:\n",
    "        sizes = [k]*(base) + [rem]     # Tail absorbs remainder: ..., last += rem\n",
    "    else:\n",
    "        sizes = [k]*(base)\n",
    "\n",
    "    # Build groups: record indices per group\n",
    "    groups = []\n",
    "    start = 0\n",
    "    for s in sizes:\n",
    "        groups.append(list(range(start, start+s)))\n",
    "        start += s\n",
    "\n",
    "    # ---- Build super_nodes & node_map ----\n",
    "    positions = np.array([[n[\"position\"][\"x\"], n[\"position\"][\"y\"]] for n in prev_nodes], dtype=float)\n",
    "\n",
    "    super_nodes, node_map = [], {}\n",
    "    for gi, idxs in enumerate(groups):\n",
    "        pts = positions[idxs]\n",
    "        mean_x, mean_y = pts.mean(axis=0)\n",
    "\n",
    "        child_dims = [prev_nodes[i][\"data\"][\"dim\"] for i in idxs]\n",
    "        child_nums = [prev_nodes[i][\"data\"].get(\"num_base\", 1) for i in idxs]\n",
    "        dim_val = int(max(1, sum(child_dims)))\n",
    "        num_val = int(sum(child_nums))\n",
    "\n",
    "        nid = f\"{gi}\"  # Same as kmeans: use group index as id (string)\n",
    "        super_nodes.append({\n",
    "            \"data\": {\n",
    "                \"id\": nid,\n",
    "                \"layer\": layer_idx,\n",
    "                \"dim\": dim_val,\n",
    "                \"num_base\": num_val\n",
    "            },\n",
    "            \"position\": {\"x\": float(mean_x), \"y\": float(mean_y)}\n",
    "        })\n",
    "        # Build base-id -> super-id mapping (note: ids are strings throughout)\n",
    "        for i in idxs:\n",
    "            node_map[prev_nodes[i][\"data\"][\"id\"]] = nid\n",
    "\n",
    "    # ---- Super edges: keep and deduplicate inter-group edges; intra-group edges collapse to prior; prior edges roll up to their owning super ----\n",
    "    super_edges, seen = [], set()\n",
    "    for e in prev_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if (v != \"prior\") and (v != \"anchor\"):\n",
    "            su, sv = node_map[u], node_map[v]\n",
    "            if su != sv:\n",
    "                eid = tuple(sorted((su, sv)))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": sv}})\n",
    "                    seen.add(eid)\n",
    "            else:\n",
    "                # Intra-group pairwise edge → group prior (consistent with grid/kmeans handling)\n",
    "                eid = tuple(sorted((su, \"prior\")))\n",
    "                if eid not in seen:\n",
    "                    super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                    seen.add(eid)\n",
    "        else:\n",
    "            su = node_map[u]\n",
    "            eid = tuple(sorted((su, \"prior\")))\n",
    "            if eid not in seen:\n",
    "                super_edges.append({\"data\": {\"source\": su, \"target\": \"prior\"}})\n",
    "                seen.add(eid)\n",
    "\n",
    "    return super_nodes, super_edges, node_map\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Tools\n",
    "# -----------------------\n",
    "def parse_layer_name(name):\n",
    "    if name == \"base\": return (\"base\", 0)\n",
    "    m = re.match(r\"(super|abs)(\\d+)$\", name)\n",
    "    return (m.group(1), int(m.group(2))) if m else (\"base\", 0)\n",
    "\n",
    "def highest_pair_idx(names):\n",
    "    hi = 0\n",
    "    for nm in names:\n",
    "        kind, k = parse_layer_name(nm)\n",
    "        if kind in (\"super\",\"abs\"): hi = max(hi, k)\n",
    "    return hi\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Initialization & Boundary\n",
    "# -----------------------\n",
    "def init_layers(N=100, step_size=25, loop_prob=0.05, loop_radius=50, prior_prop=0.0, seed=None):\n",
    "    base_nodes, base_edges = make_slam_like_graph(N, step_size, loop_prob, loop_radius, prior_prop, seed)\n",
    "    return [{\"name\": \"base\", \"nodes\": base_nodes, \"edges\": base_edges}]\n",
    "\n",
    "VIEW_W, VIEW_H = 960, 600\n",
    "ASPECT = VIEW_W / VIEW_H\n",
    "AXIS_PAD=20.0\n",
    "# ==== Blobal Status ====\n",
    "layers = init_layers()\n",
    "\n",
    "\n",
    "def adjust_bounds_to_aspect(xmin, xmax, ymin, ymax, aspect):\n",
    "    cx=(xmin+xmax)/2; cy=(ymin+ymax)/2\n",
    "    dx=xmax-xmin; dy=ymax-ymin\n",
    "    if dx<=0: dx=1\n",
    "    if dy<=0: dy=1\n",
    "    if dx/dy > aspect:\n",
    "        dy_new=dx/aspect\n",
    "        return xmin,xmax,cy-dy_new/2,cy+dy_new/2\n",
    "    else:\n",
    "        dx_new=dy*aspect\n",
    "        return cx-dx_new/2,cx+dx_new/2,ymin,ymax\n",
    "\n",
    "def reset_global_bounds(base_nodes):\n",
    "    global GLOBAL_XMIN, GLOBAL_XMAX, GLOBAL_YMIN, GLOBAL_YMAX\n",
    "    global GLOBAL_XMIN_ADJ, GLOBAL_XMAX_ADJ, GLOBAL_YMIN_ADJ, GLOBAL_YMAX_ADJ\n",
    "    xs=[n[\"position\"][\"x\"] for n in base_nodes] or [0.0]\n",
    "    ys=[n[\"position\"][\"y\"] for n in base_nodes] or [0.0]\n",
    "    GLOBAL_XMIN,GLOBAL_XMAX=min(xs),max(xs)\n",
    "    GLOBAL_YMIN,GLOBAL_YMAX=min(ys),max(ys)\n",
    "    GLOBAL_XMIN_ADJ,GLOBAL_XMAX_ADJ,GLOBAL_YMIN_ADJ,GLOBAL_YMAX_ADJ=adjust_bounds_to_aspect(\n",
    "        GLOBAL_XMIN,GLOBAL_XMAX,GLOBAL_YMIN,GLOBAL_YMAX,ASPECT)\n",
    "\n",
    "# ==== Blobal Status ====\n",
    "layers = init_layers()\n",
    "pair_idx = 0\n",
    "reset_global_bounds(layers[0][\"nodes\"])\n",
    "gbp_graph = None\n",
    "\n",
    "# -----------------------\n",
    "# GBP Graph Construction\n",
    "# -----------------------\n",
    "def build_noisy_pose_graph(\n",
    "    nodes,\n",
    "    edges,\n",
    "    prior_sigma: float = 10,\n",
    "    odom_sigma: float = 10,\n",
    "    tiny_prior: float = 1e-12,\n",
    "    seed=None,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Construct a 2D pose-only factor graph (linear, Gaussian) and inject noise.\n",
    "    Parameters:\n",
    "      prior_sigma : standard deviation of the strong prior (smaller = stronger)\n",
    "      odom_sigma  : standard deviation of odometry measurement noise\n",
    "      prior_prop  : 0.0 = anchor only; (0,1) = randomly select by proportion; >=1.0 = all\n",
    "      tiny_prior  : a tiny prior added to all nodes to prevent singularity\n",
    "      seed        : random seed (for reproducibility)\n",
    "    \"\"\"\n",
    "\n",
    "    fg = FactorGraph(nonlinear_factors=False, eta_damping=0)\n",
    "\n",
    "    var_nodes = []\n",
    "    I2 = np.eye(2, dtype=float)\n",
    "    N = len(nodes)\n",
    "\n",
    "    # ---- Pre-generate noise ----\n",
    "    prior_noises = {}\n",
    "    odom_noises = {}\n",
    "\n",
    "    if seed is None:\n",
    "        rng = np.random.default_rng()\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Generate noise for all edges\n",
    "    for e in edges:\n",
    "        src = e[\"data\"][\"source\"]; dst = e[\"data\"][\"target\"]\n",
    "        # Binary edge\n",
    "        if (dst != \"prior\") and (dst != \"anchor\"):\n",
    "            odom_noises[(int(src[:]), int(dst[:]))] = rng.normal(0.0, odom_sigma, size=2)\n",
    "        # Unary edge (strong prior)\n",
    "        elif dst == \"prior\":\n",
    "            prior_noises[int(src[:])] = rng.normal(0.0, prior_sigma, size=2)\n",
    "\n",
    "\n",
    "    # ---- variable nodes ----\n",
    "    for i, n in enumerate(nodes):\n",
    "        v = VariableNode(i, dofs=2)\n",
    "        v.GT = np.array([n[\"position\"][\"x\"], n[\"position\"][\"y\"]], dtype=float)\n",
    "\n",
    "        # Tiny prior\n",
    "        v.prior.lam = tiny_prior * I2\n",
    "        v.prior.eta = np.zeros(2, dtype=float)\n",
    "\n",
    "        var_nodes.append(v)\n",
    "\n",
    "    fg.var_nodes = var_nodes\n",
    "    fg.n_var_nodes = len(var_nodes)\n",
    "\n",
    "\n",
    "    # ---- prior factors ----\n",
    "    def meas_fn_unary(x, *args):\n",
    "        return [x]\n",
    "    def jac_fn_unary(x, *args):\n",
    "        return [np.eye(2)]\n",
    "    # ---- odometry factors ----\n",
    "    def meas_fn(xy, *args):\n",
    "        return [xy[2:] - xy[:2]]\n",
    "    def jac_fn(xy, *args):\n",
    "        return [np.array([[-1, 0, 1, 0],\n",
    "                         [ 0,-1, 0, 1]], dtype=float)]\n",
    "    \n",
    "    factors = []\n",
    "    fid = 0\n",
    "\n",
    "    for e in edges:\n",
    "        src = e[\"data\"][\"source\"]; dst = e[\"data\"][\"target\"]\n",
    "        if (dst != \"prior\") and (dst != \"anchor\"):\n",
    "            i, j = int(src[:]), int(dst[:])\n",
    "            vi, vj = var_nodes[i], var_nodes[j]\n",
    "\n",
    "            meas = (vj.GT - vi.GT) + odom_noises[(i, j)]\n",
    "\n",
    "            meas_lambda = np.eye(len(meas))/ (odom_sigma**2)\n",
    "            f = Factor(fid, [vi, vj], [meas], [meas_lambda], meas_fn, jac_fn)\n",
    "            f.type = \"base\"\n",
    "            linpoint = np.r_[vi.GT, vj.GT]\n",
    "            f.compute_factor(linpoint=linpoint, update_self=True)\n",
    "\n",
    "            factors.append(f)\n",
    "            vi.adj_factors.append(f)\n",
    "            vj.adj_factors.append(f)\n",
    "            fid += 1\n",
    "\n",
    "        elif dst == \"prior\":\n",
    "            i = int(src[:])\n",
    "            vi = var_nodes[i]\n",
    "            z = vi.GT + prior_noises[i]\n",
    "\n",
    "            z_lambda = np.eye(len(meas))/ (prior_sigma**2)\n",
    "            f = Factor(fid, [vi], [z], [z_lambda], meas_fn_unary, jac_fn_unary)\n",
    "            f.type = \"prior\"\n",
    "            f.compute_factor(linpoint=z, update_self=True)\n",
    "\n",
    "            factors.append(f)\n",
    "            vi.adj_factors.append(f)\n",
    "            fid += 1\n",
    "\n",
    "    # anchor for initial position\n",
    "    v0 = var_nodes[0]\n",
    "    z = v0.GT\n",
    "\n",
    "    z_lambda = np.eye(len(meas))/ ((1e-4)**2)\n",
    "    f = Factor(fid, [v0], [z], [z_lambda], meas_fn_unary, jac_fn_unary)\n",
    "    f.type = \"prior\"\n",
    "    f.compute_factor(linpoint=z, update_self=True)\n",
    "\n",
    "    factors.append(f)\n",
    "    v0.adj_factors.append(f)\n",
    "    fid += 1\n",
    "\n",
    "    fg.factors = factors\n",
    "    fg.n_factor_nodes = len(factors)\n",
    "    return fg\n",
    "\n",
    "\n",
    "def build_super_graph(layers, eta_damping=0.4):\n",
    "    \"\"\"\n",
    "    Construct the super graph based on the base graph in layers[-2] and the super-grouping in layers[-1].\n",
    "    Requirement: layers[-2][\"graph\"] is an already-built base graph (with unary/binary factors).\n",
    "    layers[-1][\"node_map\"]: { base_node_id (str, e.g., 'b12') -> super_node_id (str) }\n",
    "    \"\"\"\n",
    "    # ---------- Extract base & super ----------\n",
    "    base_graph = layers[-2][\"graph\"]\n",
    "    super_nodes = layers[-1][\"nodes\"]\n",
    "    super_edges = layers[-1][\"edges\"]\n",
    "    node_map    = layers[-1][\"node_map\"]   # 'bN' -> 'sX_...'\n",
    "\n",
    "    # base: id(int) -> VariableNode, handy to query dofs and mu\n",
    "    id2var = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    # ---------- super_id -> [base_id(int)] ----------\n",
    "    super_groups = {}\n",
    "    for b_str, s_id in node_map.items():\n",
    "        b_int = int(b_str)\n",
    "        super_groups.setdefault(s_id, []).append(b_int)\n",
    "\n",
    "\n",
    "    # ---------- For each super group, build a (start, dofs) table ----------\n",
    "    # local_idx[sid][bid] = (start, dofs), total_dofs[sid] = sum(dofs)\n",
    "    local_idx   = {}\n",
    "    total_dofs  = {}\n",
    "    for sid, group in super_groups.items():\n",
    "        off = 0\n",
    "        local_idx[sid] = {}\n",
    "        for bid in group:\n",
    "            d = id2var[bid].dofs\n",
    "            local_idx[sid][bid] = (off, d)\n",
    "            off += d\n",
    "        total_dofs[sid] = off\n",
    "\n",
    "    def precompute_super_factor_maps(base_graph, node_map, super_groups):\n",
    "        \"\"\"\n",
    "        base_graph: 你的 base FactorGraph\n",
    "        node_map:   { base_id(str) -> super_id(str) }\n",
    "        super_groups: { super_id(str) -> [base_id(int), ...] }\n",
    "        \"\"\"\n",
    "        # in_group：super_id -> [fid, ...]\n",
    "        group2factors_allin = { sid: [] for sid in super_groups }\n",
    "\n",
    "        # cross： (sidA, sidB) (order) -> [fid, ...]\n",
    "        pairgroups2factors  = defaultdict(list)\n",
    "\n",
    "        for fid, f in enumerate(base_graph.factors):\n",
    "            vids = [v.variableID for v in f.adj_var_nodes]\n",
    "\n",
    "            # unary factor：must \"in_group\"\n",
    "            if len(vids) == 1:\n",
    "                bid = vids[0]\n",
    "                sid = node_map[str(bid)]\n",
    "                group2factors_allin[sid].append(fid)\n",
    "                continue\n",
    "\n",
    "            # binary factor：see two sides drops in which super groups\n",
    "            if len(vids) == 2:\n",
    "                i, j = vids\n",
    "                si, sj = node_map[str(i)], node_map[str(j)]\n",
    "                if si == sj:\n",
    "                    # same，still \"in_group\"\n",
    "                    group2factors_allin[si].append(fid)\n",
    "                else:\n",
    "                    # \"cross\"：let key be ordered (min, max)\n",
    "                    key = (si, sj) if si < sj else (sj, si)\n",
    "                    pairgroups2factors[key].append(fid)\n",
    "                continue\n",
    "\n",
    "            # add logic here if higher order factors\n",
    "            # else:\n",
    "            #     ...\n",
    "\n",
    "        return group2factors_allin, pairgroups2factors\n",
    "\n",
    "    # super_groups (you already have)： {sid: [base_id,...]}\n",
    "    group2factors_allin, pairgroups2factors = precompute_super_factor_maps(\n",
    "        base_graph, node_map, super_groups)\n",
    "    layers[-1][\"group2factors_allin\"] = group2factors_allin\n",
    "    layers[-1][\"pairgroups2factors\"]  = pairgroups2factors\n",
    "\n",
    "    # ---------- Create super VariableNodes ----------\n",
    "    fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "\n",
    "    super_var_nodes = {}\n",
    "    for i, sn in enumerate(super_nodes):\n",
    "        sid = sn[\"data\"][\"id\"]\n",
    "        dofs = total_dofs.get(sid, 0)\n",
    "\n",
    "        v = VariableNode(i, dofs=dofs)\n",
    "        gt_vec = np.zeros(dofs)\n",
    "        mu_blocks = []\n",
    "        Sigma_blocks = []\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            # === Stack base GT ===\n",
    "            gt_base = getattr(id2var[bid], \"GT\", None)\n",
    "            if gt_base is None or len(gt_base) != d:\n",
    "                gt_base = np.zeros(d)\n",
    "            gt_vec[st:st+d] = gt_base\n",
    "\n",
    "            # === Stack base belief ===\n",
    "            vb = id2var[bid]\n",
    "            mu_blocks.append(vb.mu)\n",
    "            Sigma_blocks.append(vb.Sigma)\n",
    "\n",
    "        super_var_nodes[sid] = v\n",
    "        v.GT = gt_vec\n",
    "\n",
    "        mu_super = np.concatenate(mu_blocks) if mu_blocks else np.zeros(dofs)\n",
    "        Sigma_super = block_diag(*Sigma_blocks) if Sigma_blocks else np.eye(dofs)\n",
    "        lam = np.linalg.inv(Sigma_super)\n",
    "        eta = lam @ mu_super\n",
    "        v.mu = mu_super\n",
    "        v.Sigma = Sigma_super\n",
    "        v.belief = NdimGaussian(dofs, eta, lam)\n",
    "        v.prior.lam = 1e-12 * lam\n",
    "        v.prior.eta = 1e-12 * eta\n",
    "\n",
    "        fg.var_nodes.append(v)\n",
    "\n",
    "    fg.n_var_nodes = len(fg.var_nodes)\n",
    "\n",
    "    # ---------- Utility: assemble a group's linpoint (using base belief means) ----------\n",
    "    def make_linpoint_for_group(sid):\n",
    "        x = np.zeros(total_dofs[sid])\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            mu = getattr(id2var[bid], \"mu\", None)\n",
    "            if mu is None or len(mu) != d:\n",
    "                mu = np.zeros(d)\n",
    "            x[st:st+d] = mu\n",
    "        return x\n",
    "\n",
    "    # ---------- 3) super prior (in-group unary + in-group binary) ----------\n",
    "    def make_super_prior_factor(sid, base_factors, group2factors_allin):\n",
    "        idx_map = local_idx[sid]\n",
    "        ncols   = total_dofs[sid]\n",
    "\n",
    "        # ✅ Retrieve the factor object directly from the cached fid list.\n",
    "        factor_ids = group2factors_allin[sid]\n",
    "        in_group   = [base_factors[fid] for fid in factor_ids]\n",
    "\n",
    "        def meas_fn_super_prior(x_super, *args):\n",
    "            meas_fn = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "                # Assemble this factor's local x\n",
    "                x_loc_list = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "                meas_fn.extend(f.meas_fn(x_loc))   \n",
    "\n",
    "            return meas_fn if meas_fn else np.zeros(0)\n",
    "\n",
    "        def jac_fn_super_prior(x_super, *args):\n",
    "            Jrows = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "                # Build this factor's local x for (potentially) nonlinear Jacobian\n",
    "                x_loc_list = []\n",
    "                dims = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    dims.append(d)\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "\n",
    "                Jloc = f.jac_fn(x_loc)\n",
    "\n",
    "                # isinstance(Jloc, (list, tuple)):\n",
    "                lens   = [J.shape[0] for J in Jloc]     \n",
    "                Jlocs = np.vstack(Jloc)                   \n",
    "                rows = np.zeros((Jlocs.shape[0], ncols))\n",
    "                c0 = 0\n",
    "                for vid, d in zip(vids, dims):\n",
    "                    st, _ = idx_map[vid]\n",
    "                    rows[:, st:st+d] = Jlocs[:, c0:c0+d]\n",
    "                    c0 += d\n",
    "                cuts = np.cumsum(lens)[:-1]                  \n",
    "                rows = np.split(rows, cuts, axis=0) \n",
    "                Jrows.extend(rows)  \n",
    "\n",
    "            return Jrows if Jrows else np.zeros((0, ncols))\n",
    "\n",
    "        # z_super: each base factor's z\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "\n",
    "        for f in in_group:\n",
    "            ext_z(f.measurement)        \n",
    "            ext_l(f.measurement_lambda) \n",
    "\n",
    "        return meas_fn_super_prior, jac_fn_super_prior, z_super, z_super_lambda \n",
    "\n",
    "    # ---------- 4) super between (cross-group binary) ----------\n",
    "    def make_super_between_factor(sidA, sidB, base_factors, pairgroups2factors):\n",
    "        groupA, groupB = super_groups[sidA], super_groups[sidB]\n",
    "        idxA, idxB     = local_idx[sidA], local_idx[sidB]\n",
    "        nA, nB         = total_dofs[sidA], total_dofs[sidB]\n",
    "\n",
    "        # ✅ Retrieve the list of binary factor IDs from the cache, using an ordered key.\n",
    "        key = (sidA, sidB) if sidA < sidB else (sidB, sidA)\n",
    "        factor_ids = pairgroups2factors.get(key, [])\n",
    "        cross = [base_factors[fid] for fid in factor_ids]\n",
    "\n",
    "\n",
    "        def meas_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            meas_fn = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                meas_fn.extend(f.meas_fn(x_loc))   \n",
    "            return meas_fn\n",
    "\n",
    "        def jac_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            Jrows = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                    left_start, right_start = si, nA + sj\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                    left_start, right_start = nA + si, sj\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                Jloc = f.jac_fn(x_loc)\n",
    "\n",
    "                #isinstance(Jloc, (list, tuple)):\n",
    "                lens   = [J.shape[0] for J in Jloc]\n",
    "                cuts = np.cumsum(lens)[:-1]  \n",
    "                Jlocs = np.vstack(Jloc)                   \n",
    "                rows = np.zeros((Jlocs.shape[0], nA + nB))\n",
    "                rows[:, left_start:left_start+di] = Jlocs[:, :di]\n",
    "                rows[:, right_start:right_start+dj] = Jlocs[:, di:di+dj]\n",
    "                rows = np.split(rows, cuts, axis=0) \n",
    "                Jrows.extend(rows)                  \n",
    "\n",
    "            return Jrows\n",
    "\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "\n",
    "        for f in cross:\n",
    "            ext_z(f.measurement)        \n",
    "            ext_l(f.measurement_lambda) \n",
    "\n",
    "        return meas_fn_super_between, jac_fn_super_between, z_super, z_super_lambda\n",
    "\n",
    "\n",
    "    for e in super_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if v == \"prior\":\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_prior_factor(u, base_graph.factors, group2factors_allin)\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_prior\"\n",
    "            lin0 = make_linpoint_for_group(u)\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "            \n",
    "        else:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_between_factor(u, v, base_graph.factors, pairgroups2factors)\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u], super_var_nodes[v]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_between\"\n",
    "            lin0 = np.concatenate([make_linpoint_for_group(u), make_linpoint_for_group(v)])\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "            super_var_nodes[v].adj_factors.append(f)\n",
    "\n",
    "    fg.n_factor_nodes = len(fg.factors)\n",
    "    return fg\n",
    "\n",
    "\n",
    "def build_abs_graph(\n",
    "    layers,\n",
    "    r_reduced = 2,\n",
    "    eta_damping=0.4):\n",
    "\n",
    "    abs_var_nodes = {}\n",
    "    Bs = {}\n",
    "    ks = {}\n",
    "    k2s = {}\n",
    "\n",
    "    # === 1. Build Abstraction Variables ===\n",
    "    abs_fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "    sup_fg = layers[-2][\"graph\"]\n",
    "\n",
    "    for sn in sup_fg.var_nodes:\n",
    "        if sn.dofs <= r_reduced:\n",
    "            r = sn.dofs  # No reduction if dofs already <= r\n",
    "        else:\n",
    "            r = r_reduced\n",
    "\n",
    "        sid = sn.variableID\n",
    "        varis_sup_mu = sn.mu\n",
    "        varis_sup_sigma = sn.Sigma\n",
    "        \n",
    "        # Step 1: Eigen decomposition of the covariance matrix\n",
    "        eigvals, eigvecs = np.linalg.eigh(varis_sup_sigma)\n",
    "\n",
    "        # Step 2: Sort eigenvalues and eigenvectors in descending order of eigenvalues\n",
    "        idx = np.argsort(eigvals)[::-1]      # Get indices of sorted eigenvalues (largest first)\n",
    "        eigvals = eigvals[idx]               # Reorder eigenvalues\n",
    "        eigvecs = eigvecs[:, idx]            # Reorder corresponding eigenvectors\n",
    "\n",
    "        # Step 3: Select the top-k eigenvectors to form the projection matrix (principal subspace)\n",
    "        B_reduced = eigvecs[:, :r]                 # B_reduced: shape (sup_dof, r), projects r to sup_dof\n",
    "        #B_reduced = np.eye(B_reduced.shape[0])\n",
    "        Bs[sid] = B_reduced                        # Store the projection matrix for this variable\n",
    "\n",
    "        # Step 4: Project eta and Lam onto the reduced 2D subspace\n",
    "        varis_abs_mu = B_reduced.T @ varis_sup_mu          # Projected natural mean: shape (2,)\n",
    "        varis_abs_sigma = B_reduced.T @ varis_sup_sigma @ B_reduced  # Projected covariance: shape (2, 2)\n",
    "        ks[sid] = varis_sup_mu - B_reduced @ varis_abs_mu  # Store the mean offset for this variable\n",
    "        #k2s[sid] = varis_sup_sigma - B_reduced @ varis_abs_sigma @ B_reduced.T  # Residual covariance\n",
    "\n",
    "        varis_abs_lam = np.linalg.inv(varis_abs_sigma)  # Inverse covariance (precision matrix): shape (2, 2)\n",
    "        varis_abs_eta = varis_abs_lam @ varis_abs_mu  # Natural parameters: shape (2,)\n",
    "\n",
    "        v = VariableNode(sid, dofs=r)\n",
    "        v.GT = sn.GT\n",
    "        #v.prior.lam = 1e-10 * varis_abs_lam\n",
    "        #v.prior.eta = 1e-10 * varis_abs_eta\n",
    "        v.mu = varis_abs_mu\n",
    "        v.Sigma = varis_abs_sigma\n",
    "        v.belief = NdimGaussian(r, varis_abs_eta, varis_abs_lam)\n",
    "\n",
    "        abs_var_nodes[sid] = v\n",
    "        abs_fg.var_nodes.append(v)\n",
    "    abs_fg.n_var_nodes = len(abs_fg.var_nodes)\n",
    "\n",
    "\n",
    "    # === 2. Abstract Prior ===\n",
    "    def make_abs_prior_factor(sup_factor):\n",
    "        abs_id = sup_factor.adj_var_nodes[0].variableID\n",
    "        B = Bs[abs_id]\n",
    "        k = ks[abs_id]\n",
    "\n",
    "        def meas_fn_abs_prior(x_abs, *args):\n",
    "            return sup_factor.meas_fn(B @ x_abs + k)\n",
    "        \n",
    "        def jac_fn_abs_prior(x_abs, *args):\n",
    "            Jloc = sup_factor.jac_fn(B @ x_abs + k)\n",
    "            lens = [J.shape[0] for J in Jloc]\n",
    "            cuts = np.cumsum(lens)[:-1]  \n",
    "            return np.split(np.vstack(Jloc)@B, cuts, axis=0) \n",
    "\n",
    "        return meas_fn_abs_prior, jac_fn_abs_prior, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "    \n",
    "\n",
    "\n",
    "    # === 3. Abstract Between ===\n",
    "    def make_abs_between_factor(sup_factor):\n",
    "        vids = [v.variableID for v in sup_factor.adj_var_nodes]\n",
    "        i, j = vids # two variable IDs\n",
    "        ni = abs_var_nodes[i].dofs\n",
    "        Bi, Bj = Bs[i], Bs[j]\n",
    "        ki, kj = ks[i], ks[j]                       \n",
    "    \n",
    "\n",
    "        def meas_fn_super_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            return sup_factor.meas_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "\n",
    "        def jac_fn_super_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            J_sup = sup_factor.jac_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "            lens   = [J.shape[0] for J in J_sup]\n",
    "            cuts = np.cumsum(lens)[:-1]  \n",
    "            J_sup = np.vstack(J_sup)\n",
    "\n",
    "            J_abs = np.zeros((J_sup.shape[0], ni + xj.shape[0]))\n",
    "            J_abs[:, :ni] = J_sup[:, :Bi.shape[0]] @ Bi\n",
    "            J_abs[:, ni:] = J_sup[:, Bi.shape[0]:] @ Bj\n",
    "            return np.split(J_abs, cuts, axis=0) \n",
    "        \n",
    "        return meas_fn_super_between, jac_fn_super_between, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "    \n",
    "\n",
    "    for f in sup_fg.factors:\n",
    "        if len(f.adj_var_nodes) == 1:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_prior_factor(f)\n",
    "            v = abs_var_nodes[f.adj_var_nodes[0].variableID]\n",
    "            abs_f = Factor(f.factorID, [v], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_prior\"\n",
    "            abs_f.adj_beliefs = [v.belief]\n",
    "\n",
    "            lin0 = v.mu\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            v.adj_factors.append(abs_f)\n",
    "\n",
    "        elif len(f.adj_var_nodes) == 2:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_between_factor(f)\n",
    "            i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "            vi, vj = abs_var_nodes[i], abs_var_nodes[j]\n",
    "            abs_f = Factor(f.factorID, [vi, vj], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_between\"\n",
    "            abs_f.adj_beliefs = [vi.belief, vj.belief]\n",
    "\n",
    "            lin0 = np.concatenate([vi.mu, vj.mu])\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            vi.adj_factors.append(abs_f)\n",
    "            vj.adj_factors.append(abs_f)\n",
    "\n",
    "    abs_fg.n_factor_nodes = len(abs_fg.factors)\n",
    "\n",
    "\n",
    "    return abs_fg, Bs, ks, k2s\n",
    "\n",
    "\n",
    "def bottom_up_modify_abs_graph(\n",
    "    layers,\n",
    "    r_reduced = 2,\n",
    "    eta_damping=0.4):\n",
    "\n",
    "    abs_var_nodes = {}\n",
    "    Bs = {}\n",
    "    ks = {}\n",
    "    k2s = {}\n",
    "\n",
    "    # === 1. Build Abstraction Variables ===\n",
    "    abs_fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "    abs_fg_old = layers[-1][\"graph\"]\n",
    "    sup_fg = layers[-2][\"graph\"]\n",
    "\n",
    "    for sn in sup_fg.var_nodes:\n",
    "        if sn.dofs <= r_reduced:\n",
    "            r = sn.dofs  # No reduction if dofs already <= r\n",
    "        else:\n",
    "            r = r_reduced\n",
    "\n",
    "        sid = sn.variableID\n",
    "        varis_sup_mu = sn.mu\n",
    "        varis_sup_sigma = sn.Sigma\n",
    "        \n",
    "        # Step 1: Eigen decomposition of the covariance matrix\n",
    "        #eigvals, eigvecs = np.linalg.eigh(varis_sup_sigma)\n",
    "\n",
    "        # Step 2: Sort eigenvalues and eigenvectors in descending order of eigenvalues\n",
    "        #idx = np.argsort(eigvals)[::-1]      # Get indices of sorted eigenvalues (largest first)\n",
    "        #eigvals = eigvals[idx]               # Reorder eigenvalues\n",
    "        #eigvecs = eigvecs[:, idx]            # Reorder corresponding eigenvectors\n",
    "\n",
    "        # Step 3: Select the top-k eigenvectors to form the projection matrix (principal subspace)\n",
    "        #B_reduced = eigvecs[:, :r]                 # B_reduced: shape (sup_dof, r), projects r to sup_dof\n",
    "        B_reduced = layers[-1][\"Bs\"][sid]\n",
    "        #B_reduced = np.eye(B_reduced.shape[0])\n",
    "        Bs[sid] = B_reduced                        # Store the projection matrix for this variable\n",
    "\n",
    "        # Step 4: Project eta and Lam onto the reduced 2D subspace\n",
    "        varis_abs_mu = B_reduced.T @ varis_sup_mu          # Projected natural mean: shape (2,)\n",
    "        varis_abs_sigma = B_reduced.T @ varis_sup_sigma @ B_reduced  # Projected covariance: shape (2, 2)\n",
    "\n",
    "        ks[sid] = varis_sup_mu - B_reduced @ varis_abs_mu  # Store the mean offset for this variable\n",
    "        #k2s[sid] = varis_sup_sigma - B_reduced @ varis_abs_sigma @ B_reduced.T  # Residual covariance\n",
    "\n",
    "        varis_abs_lam = np.linalg.inv(varis_abs_sigma)  # Inverse covariance (precision matrix): shape (2, 2)\n",
    "\n",
    "        #varis_abs_lam = abs_fg_old.var_nodes[sid].belief.lam\n",
    "        varis_abs_eta = varis_abs_lam @ varis_abs_mu  # Natural parameters: shape (2,)\n",
    "\n",
    "        v = VariableNode(sid, dofs=r)\n",
    "        v.GT = sn.GT\n",
    "        #v.prior.lam = 1e-10 * varis_abs_lam\n",
    "        #v.prior.eta = 1e-10 * varis_abs_eta\n",
    "        v.mu = varis_abs_mu\n",
    "        v.Sigma = abs_fg_old.var_nodes[sid].Sigma\n",
    "        v.Sigma = varis_abs_sigma\n",
    "        v.belief = NdimGaussian(r, varis_abs_eta, varis_abs_lam)\n",
    "\n",
    "        abs_var_nodes[sid] = v\n",
    "        abs_fg.var_nodes.append(v)\n",
    "    abs_fg.n_var_nodes = len(abs_fg.var_nodes)\n",
    "\n",
    "\n",
    "    # === 2. Abstract Prior ===\n",
    "    def make_abs_prior_factor(sup_factor):\n",
    "        abs_id = sup_factor.adj_var_nodes[0].variableID\n",
    "        B = Bs[abs_id]\n",
    "        k = ks[abs_id]\n",
    "\n",
    "        def meas_fn_abs_prior(x_abs, *args):\n",
    "            return sup_factor.meas_fn(B @ x_abs + k)\n",
    "        \n",
    "        def jac_fn_abs_prior(x_abs, *args):\n",
    "            Jloc = sup_factor.jac_fn(B @ x_abs + k)\n",
    "            lens = [J.shape[0] for J in Jloc]\n",
    "            cuts = np.cumsum(lens)[:-1]  \n",
    "            return np.split(np.vstack(Jloc)@B, cuts, axis=0) \n",
    "\n",
    "        return meas_fn_abs_prior, jac_fn_abs_prior, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "    \n",
    "\n",
    "\n",
    "    # === 3. Abstract Between ===\n",
    "    def make_abs_between_factor(sup_factor):\n",
    "        vids = [v.variableID for v in sup_factor.adj_var_nodes]\n",
    "        i, j = vids # two variable IDs\n",
    "        ni = abs_var_nodes[i].dofs\n",
    "        Bi, Bj = Bs[i], Bs[j]\n",
    "        ki, kj = ks[i], ks[j]                       \n",
    "    \n",
    "\n",
    "        def meas_fn_abs_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            return sup_factor.meas_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "\n",
    "        def jac_fn_abs_between(xij, *args):\n",
    "            xi, xj = xij[:ni], xij[ni:]\n",
    "            J_sup = sup_factor.jac_fn(np.concatenate([Bi @ xi + ki, Bj @ xj + kj]))\n",
    "            lens = [J.shape[0] for J in J_sup]\n",
    "            cuts = np.cumsum(lens)[:-1]  \n",
    "            J_sup = np.vstack(J_sup)\n",
    "\n",
    "            J_abs = np.zeros((J_sup.shape[0], ni + xj.shape[0]))\n",
    "            J_abs[:, :ni] = J_sup[:, :Bi.shape[0]] @ Bi\n",
    "            J_abs[:, ni:] = J_sup[:, Bi.shape[0]:] @ Bj\n",
    "            return np.split(J_abs, cuts, axis=0) \n",
    "        \n",
    "        return meas_fn_abs_between, jac_fn_abs_between, sup_factor.measurement, sup_factor.measurement_lambda\n",
    "    \n",
    "\n",
    "    for f in sup_fg.factors:\n",
    "        if len(f.adj_var_nodes) == 1:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_prior_factor(f)\n",
    "            v = abs_var_nodes[f.adj_var_nodes[0].variableID]\n",
    "            abs_f = Factor(f.factorID, [v], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_prior\"\n",
    "            abs_f.adj_beliefs = [v.belief]\n",
    "\n",
    "            lin0 = v.mu\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            abs_f.messages = abs_fg_old.factors[f.factorID].messages\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            v.adj_factors.append(abs_f)\n",
    "\n",
    "        elif len(f.adj_var_nodes) == 2:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_abs_between_factor(f)\n",
    "            i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "            vi, vj = abs_var_nodes[i], abs_var_nodes[j]\n",
    "            abs_f = Factor(f.factorID, [vi, vj], z, z_lambda, meas_fn, jac_fn)\n",
    "            abs_f.type = \"abs_between\"\n",
    "            abs_f.adj_beliefs = [vi.belief, vj.belief]\n",
    "\n",
    "            lin0 = np.concatenate([vi.mu, vj.mu])\n",
    "            abs_f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            abs_f.messages = abs_fg_old.factors[f.factorID].messages\n",
    "            abs_fg.factors.append(abs_f)\n",
    "            vi.adj_factors.append(abs_f)\n",
    "            vj.adj_factors.append(abs_f)\n",
    "\n",
    "    abs_fg.n_factor_nodes = len(abs_fg.factors)\n",
    "\n",
    "\n",
    "    return abs_fg, Bs, ks, k2s\n",
    "\n",
    "\n",
    "def bottom_up_modify_super_graph(layers, eta_damping=0.4):\n",
    "    \"\"\"\n",
    "    Update super-node means (mu) from base nodes,\n",
    "    and simultaneously adjust variable beliefs and adjacent messages.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Extract base & super ----------\n",
    "    base_graph = layers[-2][\"graph\"]\n",
    "    super_nodes = layers[-1][\"nodes\"]\n",
    "    super_edges = layers[-1][\"edges\"]\n",
    "    node_map    = layers[-1][\"node_map\"]   # 'bN' -> 'sX_...'\n",
    "    super_fg    = layers[-1][\"graph\"]\n",
    "    group2factors_allin = layers[-1][\"group2factors_allin\"] \n",
    "    pairgroups2factors = layers[-1][\"pairgroups2factors\"]  \n",
    "\n",
    "    # base: id(int) -> VariableNode, handy to query dofs and mu\n",
    "    id2var = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    # ---------- super_id -> [base_id(int)] ----------\n",
    "    super_groups = {}\n",
    "    for b_str, s_id in node_map.items():\n",
    "        b_int = int(b_str)\n",
    "        super_groups.setdefault(s_id, []).append(b_int)\n",
    "\n",
    "\n",
    "    # ---------- For each super group, build a (start, dofs) table ----------\n",
    "    # local_idx[sid][bid] = (start, dofs), total_dofs[sid] = sum(dofs)\n",
    "    local_idx   = {}\n",
    "    total_dofs  = {}\n",
    "    for sid, group in super_groups.items():\n",
    "        off = 0\n",
    "        local_idx[sid] = {}\n",
    "        for bid in group:\n",
    "            d = id2var[bid].dofs\n",
    "            local_idx[sid][bid] = (off, d)\n",
    "            off += d\n",
    "        total_dofs[sid] = off\n",
    "\n",
    "\n",
    "    # ---------- Create super VariableNodes ----------\n",
    "    fg = FactorGraph(nonlinear_factors=False, eta_damping=eta_damping)\n",
    "\n",
    "    super_var_nodes = {}\n",
    "    for i, sn in enumerate(super_nodes):\n",
    "        sid = sn[\"data\"][\"id\"]\n",
    "        dofs = total_dofs.get(sid, 0)\n",
    "\n",
    "        v = VariableNode(i, dofs=dofs)\n",
    "        gt_vec = np.zeros(dofs)\n",
    "        mu_blocks = []\n",
    "        Sigma_blocks = []\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            # === Stack base GT ===\n",
    "            gt_base = getattr(id2var[bid], \"GT\", None)\n",
    "            if gt_base is None or len(gt_base) != d:\n",
    "                gt_base = np.zeros(d)\n",
    "            gt_vec[st:st+d] = gt_base\n",
    "\n",
    "            # === Stack base belief ===\n",
    "            vb = id2var[bid]\n",
    "            mu_blocks.append(vb.mu)\n",
    "            Sigma_blocks.append(vb.Sigma)\n",
    "\n",
    "        super_var_nodes[sid] = v\n",
    "        v.GT = gt_vec\n",
    "\n",
    "        mu_super = np.concatenate(mu_blocks) if mu_blocks else np.zeros(dofs)\n",
    "        Sigma_super = block_diag(*Sigma_blocks) if Sigma_blocks else np.eye(dofs)\n",
    "        lam = np.linalg.inv(Sigma_super)\n",
    "        eta = lam @ mu_super\n",
    "        v.mu = mu_super\n",
    "        v.Sigma = Sigma_super\n",
    "        v.belief = NdimGaussian(dofs, eta, lam)\n",
    "        v.prior.lam = 1e-12 * lam\n",
    "        v.prior.eta = 1e-12 * eta\n",
    "\n",
    "        fg.var_nodes.append(v)\n",
    "\n",
    "    fg.n_var_nodes = len(fg.var_nodes)\n",
    "\n",
    "    # ---------- Utility: assemble a group's linpoint (using base belief means) ----------\n",
    "    def make_linpoint_for_group(sid):\n",
    "        x = np.zeros(total_dofs[sid])\n",
    "        for bid, (st, d) in local_idx[sid].items():\n",
    "            mu = getattr(id2var[bid], \"mu\", None)\n",
    "            if mu is None or len(mu) != d:\n",
    "                mu = np.zeros(d)\n",
    "            x[st:st+d] = mu\n",
    "        return x\n",
    "\n",
    "    # ---------- 3) super prior (in-group unary + in-group binary) ----------\n",
    "    def make_super_prior_factor(sid, base_factors, group2factors_allin):\n",
    "        idx_map = local_idx[sid]\n",
    "        ncols   = total_dofs[sid]\n",
    "\n",
    "        # Retrieve the factor object directly from the cached fid list.\n",
    "        factor_ids = group2factors_allin[sid]\n",
    "        in_group   = [base_factors[fid] for fid in factor_ids]\n",
    "\n",
    "        def meas_fn_super_prior(x_super, *args):\n",
    "            meas_fn = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "                # Assemble this factor's local x\n",
    "                x_loc_list = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "                meas_fn.extend(f.meas_fn(x_loc))\n",
    "            return meas_fn if meas_fn else np.zeros(0)\n",
    "\n",
    "        def jac_fn_super_prior(x_super, *args):\n",
    "            Jrows = []\n",
    "            for f in in_group:\n",
    "                vids = [v.variableID for v in f.adj_var_nodes]\n",
    "                # Build this factor's local x for (potentially) nonlinear Jacobian\n",
    "                x_loc_list = []\n",
    "                dims = []\n",
    "                for vid in vids:\n",
    "                    st, d = idx_map[vid]\n",
    "                    dims.append(d)\n",
    "                    x_loc_list.append(x_super[st:st+d])\n",
    "                x_loc = np.concatenate(x_loc_list) if x_loc_list else np.zeros(0)\n",
    "\n",
    "                Jloc = f.jac_fn(x_loc)\n",
    "\n",
    "                # isinstance(Jloc, (list, tuple)):\n",
    "                lens   = [J.shape[0] for J in Jloc]     \n",
    "                Jlocs = np.vstack(Jloc)                   \n",
    "                rows = np.zeros((Jlocs.shape[0], ncols))\n",
    "                c0 = 0\n",
    "                for vid, d in zip(vids, dims):\n",
    "                    st, _ = idx_map[vid]\n",
    "                    rows[:, st:st+d] = Jlocs[:, c0:c0+d]\n",
    "                    c0 += d\n",
    "                cuts = np.cumsum(lens)[:-1]                  \n",
    "                rows = np.split(rows, cuts, axis=0) \n",
    "                Jrows.extend(rows)  \n",
    "            return Jrows if Jrows else np.zeros((0, ncols))\n",
    "\n",
    "        # z_super: concatenate each base factor's z\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "\n",
    "        for f in in_group:\n",
    "            ext_z(f.measurement)        \n",
    "            ext_l(f.measurement_lambda) \n",
    "\n",
    "        return meas_fn_super_prior, jac_fn_super_prior, z_super, z_super_lambda \n",
    "\n",
    "    # ---------- 4) super between (cross-group binary) ----------\n",
    "    def make_super_between_factor(sidA, sidB, base_factors, pairgroups2factors):\n",
    "        groupA, groupB = super_groups[sidA], super_groups[sidB]\n",
    "        idxA, idxB     = local_idx[sidA], local_idx[sidB]\n",
    "        nA, nB         = total_dofs[sidA], total_dofs[sidB]\n",
    "\n",
    "        # Retrieve binary factor IDs from the cache using an ordered key.\n",
    "        key = (sidA, sidB) if sidA < sidB else (sidB, sidA)\n",
    "        factor_ids = pairgroups2factors.get(key, [])\n",
    "        cross = [base_factors[fid] for fid in factor_ids]\n",
    "\n",
    "\n",
    "        def meas_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            meas_fn = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                meas_fn.extend(f.meas_fn(x_loc))\n",
    "            return meas_fn \n",
    "\n",
    "        def jac_fn_super_between(xAB, *args):\n",
    "            xA, xB = xAB[:nA], xAB[nA:]\n",
    "            Jrows = []\n",
    "            for f in cross:\n",
    "                i, j = [v.variableID for v in f.adj_var_nodes]\n",
    "                if i in groupA:\n",
    "                    si, di = idxA[i]\n",
    "                    sj, dj = idxB[j]\n",
    "                    xi = xA[si:si+di]\n",
    "                    xj = xB[sj:sj+dj]\n",
    "                    left_start, right_start = si, nA + sj\n",
    "                else:\n",
    "                    si, di = idxB[i]\n",
    "                    sj, dj = idxA[j]\n",
    "                    xi = xB[si:si+di]\n",
    "                    xj = xA[sj:sj+dj]\n",
    "                    left_start, right_start = nA + si, sj\n",
    "                x_loc = np.concatenate([xi, xj])\n",
    "                Jloc = f.jac_fn(x_loc)\n",
    "\n",
    "                #isinstance(Jloc, (list, tuple)):\n",
    "                lens = [J.shape[0] for J in Jloc]\n",
    "                cuts = np.cumsum(lens)[:-1]  \n",
    "                Jlocs = np.vstack(Jloc)                   \n",
    "                rows = np.zeros((Jlocs.shape[0], nA + nB))\n",
    "                rows[:, left_start:left_start+di] = Jlocs[:, :di]\n",
    "                rows[:, right_start:right_start+dj] = Jlocs[:, di:di+dj]\n",
    "                rows = np.split(rows, cuts, axis=0) \n",
    "                Jrows.extend(rows)   \n",
    "            return Jrows \n",
    "\n",
    "        z_super, z_super_lambda = [], []\n",
    "        ext_z, ext_l = z_super.extend, z_super_lambda.extend\n",
    "\n",
    "        for f in cross:\n",
    "            ext_z(f.measurement)        \n",
    "            ext_l(f.measurement_lambda) \n",
    "\n",
    "        return meas_fn_super_between, jac_fn_super_between, z_super, z_super_lambda\n",
    "\n",
    "\n",
    "\n",
    "    for e in super_edges:\n",
    "        u, v = e[\"data\"][\"source\"], e[\"data\"][\"target\"]\n",
    "\n",
    "        if v == \"prior\":\n",
    "            #a = time.time()\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_prior_factor(u, base_graph.factors, group2factors_allin)\n",
    "            #if layers[-1][\"name\"] == \"super3\":\n",
    "            #    print(f\"aaaaaaaaaa {time.time()-a:.4f}s\")\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_prior\"\n",
    "            lin0 = make_linpoint_for_group(u)\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            #if layers[-1][\"name\"] == \"super3\":\n",
    "            #    print(f\"bbbbbbbbbb {time.time()-a:.4f}s\")\n",
    "            f.messages = super_fg.factors[len(fg.factors)].messages\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "\n",
    "        else:\n",
    "            meas_fn, jac_fn, z, z_lambda = make_super_between_factor(u, v, base_graph.factors, pairgroups2factors)\n",
    "            f = Factor(len(fg.factors), [super_var_nodes[u], super_var_nodes[v]], z, z_lambda, meas_fn, jac_fn)\n",
    "            f.adj_beliefs = [vn.belief for vn in f.adj_var_nodes]\n",
    "            f.type = \"super_between\"\n",
    "            lin0 = np.concatenate([make_linpoint_for_group(u), make_linpoint_for_group(v)])\n",
    "            f.compute_factor(linpoint=lin0, update_self=True)\n",
    "            f.messages = super_fg.factors[len(fg.factors)].messages\n",
    "            fg.factors.append(f)\n",
    "            super_var_nodes[u].adj_factors.append(f)\n",
    "            super_var_nodes[v].adj_factors.append(f)\n",
    "\n",
    "\n",
    "    fg.n_factor_nodes = len(fg.factors)\n",
    "    return fg\n",
    "\n",
    "\n",
    "def top_down_modify_base_and_abs_graph(layers):\n",
    "    \"\"\"\n",
    "    From the super graph downward, split μ to the base graph,\n",
    "    and simultaneously update the base variables' beliefs and the adjacent factors'\n",
    "    adj_beliefs / messages.\n",
    "\n",
    "    Assume layers[-1] is the super layer and layers[-2] is the base layer.\n",
    "    \"\"\"\n",
    "    super_graph = layers[-1][\"graph\"]\n",
    "    base_graph = layers[-2][\"graph\"]\n",
    "    node_map   = layers[-1][\"node_map\"]  # { base_id(str) -> super_id(str) }\n",
    "\n",
    "\n",
    "    # super_id -> [base_id(int)]\n",
    "    super_groups = {}\n",
    "    for b_str, s_id in node_map.items():\n",
    "        b_int = int(b_str)\n",
    "        super_groups.setdefault(s_id, []).append(b_int)\n",
    "\n",
    "    # child lookup\n",
    "    id2var_base = {vn.variableID: vn for vn in base_graph.var_nodes}\n",
    "\n",
    "    for s_var in super_graph.var_nodes:\n",
    "        sid = str(s_var.variableID)\n",
    "        if sid not in super_groups:\n",
    "            continue\n",
    "        base_ids = super_groups[sid]\n",
    "\n",
    "        # === split super.mu to base ===\n",
    "        mu_super = s_var.mu\n",
    "        off = 0\n",
    "        for bid in base_ids:\n",
    "            v = id2var_base[bid]\n",
    "            d = v.dofs\n",
    "            mu_child = mu_super[off:off+d]\n",
    "            off += d\n",
    "\n",
    "            old_belief = v.belief\n",
    "\n",
    "            # 1. update mu\n",
    "            v.mu = mu_child\n",
    "\n",
    "            # 2. new belief（keep Σ unchanged，use new mu）\n",
    "            eta = v.belief.lam @ v.mu\n",
    "            new_belief = NdimGaussian(v.dofs, eta, v.belief.lam)\n",
    "            v.belief = new_belief\n",
    "            v.prior = NdimGaussian(v.dofs, 1e-10*eta, 1e-10*v.belief.lam)\n",
    "\n",
    "            # 3. Sync to adjacent factors (this step is important)\n",
    "            if v.adj_factors:\n",
    "                n_adj = len(v.adj_factors)\n",
    "                d_eta = new_belief.eta - old_belief.eta\n",
    "                d_lam = new_belief.lam - old_belief.lam\n",
    "\n",
    "                for f in v.adj_factors:\n",
    "                    if v in f.adj_var_nodes:\n",
    "                        idx = f.adj_var_nodes.index(v)\n",
    "                        # update adj_beliefs\n",
    "                        f.adj_beliefs[idx] = new_belief\n",
    "                        # correct coresponding message\n",
    "                        msg = f.messages[idx]\n",
    "                        msg.eta += d_eta / n_adj\n",
    "                        msg.lam += d_lam / n_adj\n",
    "                        f.messages[idx] = msg\n",
    "\n",
    "    return base_graph\n",
    "\n",
    "\n",
    "def top_down_modify_super_graph(layers):\n",
    "    \"\"\"\n",
    "    From the abs graph downward, project mu / Sigma back to the super graph,\n",
    "    and simultaneously update the super variables' beliefs and the adjacent\n",
    "    factors' adj_beliefs / messages.\n",
    "\n",
    "    Requirements:\n",
    "      - layers[-1] is abs, layers[-2] is super\n",
    "      - Factors at the abs level and the super level share the same factorID (one-to-one)\n",
    "      - The columns of B are orthonormal (from covariance eigenvectors; eigenvectors from np.linalg.eigh are orthogonal)\n",
    "    \"\"\"\n",
    "\n",
    "    abs_graph   = layers[-1][\"graph\"]\n",
    "    super_graph = layers[-2][\"graph\"]\n",
    "    Bs  = layers[-1][\"Bs\"]   # { super_id(int) -> B (d_super × r) }\n",
    "    ks  = layers[-1][\"ks\"]   # { super_id(int) -> k (d_super,) }\n",
    "    #k2s = layers[-1][\"k2s\"]  # { super_id(int) -> residual covariance (d_super × d_super) }\n",
    "\n",
    "    # Prebuild abs factor index: factorID -> Factor\n",
    "    #abs_f_by_id = {f.factorID: f for f in getattr(abs_graph, \"factors\", [])}\n",
    "\n",
    "    # ---- First project variables' mu / Sigma and update beliefs ----\n",
    "    for sn in super_graph.var_nodes:\n",
    "        sid = sn.variableID\n",
    "        if sid not in Bs or sid not in ks:\n",
    "            continue\n",
    "        B  = Bs[sid]    # (d_s × r)\n",
    "        k  = ks[sid]    # (d_s,)\n",
    "        #k2 = k2s[sid]   # (d_s × d_s)\n",
    "\n",
    "        # x_s = B x_a + k; Σ_s = B Σ_a Bᵀ + k2\n",
    "        mu_a    = abs_graph.var_nodes[sid].mu\n",
    "        mu_s    = B @ mu_a + k\n",
    "        sn.mu   = mu_s\n",
    "\n",
    "        old_belief = sn.belief\n",
    "        # Refresh super belief (natural parameters) with the new μ and Σ\n",
    "        eta = sn.belief.lam @ sn.mu\n",
    "        new_belief = NdimGaussian(sn.dofs, eta, sn.belief.lam)\n",
    "        sn.belief  = new_belief\n",
    "        sn.prior = NdimGaussian(sn.dofs, 1e-10*eta, 1e-10*sn.belief.lam)\n",
    "\n",
    "\n",
    "        # Iterate over super factors adjacent to this super variable\n",
    "        if sn.adj_factors:\n",
    "            n_adj = len(sn.adj_factors)\n",
    "            d_eta = new_belief.eta - old_belief.eta\n",
    "            d_lam = new_belief.lam - old_belief.lam\n",
    "\n",
    "            for f in sn.adj_factors:\n",
    "                if sn in f.adj_var_nodes:\n",
    "                    idx = f.adj_var_nodes.index(sn)\n",
    "                    # update adj_beliefs\n",
    "                    f.adj_beliefs[idx] = new_belief\n",
    "                    # correct coresponding message\n",
    "                    msg = f.messages[idx]\n",
    "                    msg.eta += d_eta / n_adj\n",
    "                    msg.lam += d_lam / n_adj\n",
    "                    f.messages[idx] = msg\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def refresh_gbp_results(layers):\n",
    "    \"\"\"\n",
    "    Precompute an affine map to the base plane for each layer:\n",
    "      base:   A_i = I2, b_i = 0\n",
    "      super:  A_s = (1/m) [A_c1, A_c2, ..., A_cm], b_s = (1/m) Σ b_cj\n",
    "      abs:    A_a = A_super(s) @ B_s,             b_a = A_super(s) @ k_s + b_super(s)\n",
    "    Then refresh gbp_result via pos = A @ mu + b.\n",
    "    Convention: use string keys everywhere (aligned with Cytoscape ids).\n",
    "    \"\"\"\n",
    "    if not layers:\n",
    "        return\n",
    "\n",
    "    # ---------- 1) Bottom-up: compute A, b for each layer ----------\n",
    "    for li, L in enumerate(layers):\n",
    "        g = L.get(\"graph\")\n",
    "        if g is None:\n",
    "            L.pop(\"A\", None); L.pop(\"b\", None); L.pop(\"gbp_result\", None)\n",
    "            continue\n",
    "\n",
    "        name = L[\"name\"]\n",
    "        # ---- base ----\n",
    "        if name.startswith(\"base\"):\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for v in g.var_nodes:\n",
    "                key = str(v.variableID)\n",
    "                L[\"A\"][key] = np.eye(2)\n",
    "                L[\"b\"][key] = np.zeros(2, dtype=float)\n",
    "\n",
    "        # ---- super ----\n",
    "        elif name.startswith(\"super\"):\n",
    "            parent = layers[li - 1]\n",
    "            node_map = L[\"node_map\"]  # { prev_id(str) -> super_id(str) }\n",
    "\n",
    "            # Grouping (preserve insertion order to match the concatenation order in build_super_graph)\n",
    "            groups = {}\n",
    "            for prev_id, s_id in node_map.items():\n",
    "                prev_id = str(prev_id); s_id = str(s_id)\n",
    "                groups.setdefault(s_id, []).append(prev_id)\n",
    "\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for s_id, children in groups.items():\n",
    "                m = len(children)\n",
    "                # Horizontal concatenation [A_c1, A_c2, ...]\n",
    "                A_blocks = [parent[\"A\"][cid] for cid in children]  # each block has shape 2×d_c\n",
    "                A_concat = np.hstack(A_blocks) if A_blocks else np.zeros((2, 0))\n",
    "                b_sum = sum((parent[\"b\"][cid] for cid in children), start=np.zeros(2, dtype=float))\n",
    "                L[\"A\"][s_id] = (1.0 / m) * A_concat\n",
    "                L[\"b\"][s_id] = (1.0 / m) * b_sum\n",
    "\n",
    "        # ---- abs ----\n",
    "        elif name.startswith(\"abs\"):\n",
    "            parent = layers[li - 1]  # the corresponding super layer\n",
    "            Bs, ks = L[\"Bs\"], L[\"ks\"]  # Note: keys are the super variableIDs (int)\n",
    "\n",
    "            # Build a mapping between super variableID (int) and the super string id (follow node list order)\n",
    "            # The order of nodes in the parent (super) and this (abs) layer is consistent (copy_to_abs preserves order)\n",
    "            int2sid = {i: str(parent[\"nodes\"][i][\"data\"][\"id\"]) for i in range(len(parent[\"nodes\"]))}\n",
    "\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "            for av in g.var_nodes:\n",
    "                sid_int = av.variableID              # super variableID (int)\n",
    "                s_id = int2sid.get(sid_int, str(sid_int))  # super string id (also the abs node id)\n",
    "                B = Bs[sid_int]                       # (sum d_c) × r\n",
    "                k = ks[sid_int]                       # (sum d_c,)\n",
    "\n",
    "                A_sup = parent[\"A\"][s_id]             # shape 2 × (sum d_c)\n",
    "                b_sup = parent[\"b\"][s_id]             # shape (2,)\n",
    "\n",
    "                L[\"A\"][s_id] = A_sup @ B              # 2 × r\n",
    "                L[\"b\"][s_id] = A_sup @ k + b_sup      # 2,\n",
    "\n",
    "        else:\n",
    "            # Unknown layer type\n",
    "            L[\"A\"], L[\"b\"] = {}, {}\n",
    "\n",
    "    # ---------- 2) Compute gbp_result ----------\n",
    "    for li, L in enumerate(layers):\n",
    "        g = L.get(\"graph\")\n",
    "        if g is None:\n",
    "            L.pop(\"gbp_result\", None)\n",
    "            continue\n",
    "\n",
    "        name = L[\"name\"]\n",
    "        res = {}\n",
    "\n",
    "        if name.startswith(\"base\"):\n",
    "            for v in g.var_nodes:\n",
    "                vid = str(v.variableID)\n",
    "                res[vid] = v.mu[:2].tolist()\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Directly use A_super, b_super mapping\n",
    "            # nodes order is consistent with var_nodes order\n",
    "            for i, v in enumerate(g.var_nodes):\n",
    "                s_id = str(L[\"nodes\"][i][\"data\"][\"id\"])\n",
    "                A, b = L[\"A\"][s_id], L[\"b\"][s_id]   # A: 2×(sum d_c)\n",
    "                res[s_id] = (A @ v.mu + b).tolist()\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            parent = layers[li - 1]\n",
    "            # Also align via string ids\n",
    "            for i, v in enumerate(g.var_nodes):\n",
    "                a_id = str(L[\"nodes\"][i][\"data\"][\"id\"])  # same text as the super s_id\n",
    "                A, b = L[\"A\"][a_id], L[\"b\"][a_id]        # A: 2×r\n",
    "                res[a_id] = (A @ v.mu + b).tolist()\n",
    "\n",
    "        L[\"gbp_result\"] = res\n",
    "\n",
    "\n",
    "\n",
    "def vloop(layers):\n",
    "    \"\"\"\n",
    "    Simplified V-cycle:\n",
    "    1) bottom-up: rebuild and iterate once for base / super / abs in order\n",
    "    2) top-down: propagate mu from super -> base\n",
    "    3) refresh gbp_result on each layer for UI use\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- bottom-up ----\n",
    "    #if layers and \"graph\" in layers[0]:\n",
    "    #    layers[0][\"graph\"].synchronous_iteration()\n",
    "        \n",
    "    for i in range(1, len(layers)):\n",
    "        name = layers[i][\"name\"]\n",
    "\n",
    "        if name.startswith(\"super1\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            # layers[i][\"graph\"] = build_super_graph(layers[:i+1])\n",
    "            #layers[i][\"graph\"].synchronous_iteration()\n",
    "            #bottom_up_modify_super_graph(layers[:i+1])\n",
    "            #build_super_graph(layers[:i+1])\n",
    "            #update_super_graph_linearized(layers[:i+1])\n",
    "            pass\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            layers[i][\"graph\"] = build_super_graph(layers[:i+1])\n",
    "            #layers[i][\"graph\"] = update_super_graph_linearized(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Rebuild abs using the previous super\n",
    "            abs_graph, Bs, ks, k2s = build_abs_graph(layers[:i+1])\n",
    "            layers[i][\"graph\"] = abs_graph\n",
    "            layers[i][\"Bs\"], layers[i][\"ks\"], layers[i][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "        # After build, one iteration per layer\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "    # ---- top-down (pass mu) ----\n",
    "    for i in range(len(layers) - 1, 0, -1):\n",
    "        # After one iterations per layer, reproject\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "        # this is very important, but dont know why yet\n",
    "        # so abs layer need more iterations\n",
    "        #if name.startswith(\"abs\"):\n",
    "            #layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "        name = layers[i][\"name\"]\n",
    "        if name.startswith(\"super\"):\n",
    "            # Split super.mu back to base/abs\n",
    "            top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Project abs.mu back to super\n",
    "            top_down_modify_super_graph(layers[:i+1])\n",
    "    \n",
    "\n",
    "    # ---- refresh gbp_result for UI ----\n",
    "    refresh_gbp_results(layers)\n",
    "\n",
    "\n",
    "\n",
    "def compute_energy(layers):\n",
    "    \"\"\"\n",
    "    energy = 0.5 * sum_i || mu_i[0:2] - GT_i[0:2] ||^2  over base layer variables\n",
    "    vectorized version (no per-node np calls)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_graph = layers[0].get(\"graph\", None)\n",
    "        var_nodes = getattr(base_graph, \"var_nodes\", None)\n",
    "        if base_graph is None or not var_nodes:\n",
    "            return \"Energy: -\"\n",
    "\n",
    "        # Stack mu[:2] and GT[:2] for all variables into (N, 2)\n",
    "        mus_2 = np.stack([np.asarray(v.mu[:2], dtype=float) for v in var_nodes], axis=0)\n",
    "        gts_2 = np.stack([np.asarray(v.GT[:2], dtype=float) for v in var_nodes], axis=0)\n",
    "\n",
    "        diff = mus_2 - gts_2                      # shape (N, 2)\n",
    "        total = 0.5 * np.sum(diff * diff)         # 0.5 * sum of squared norms\n",
    "\n",
    "        return f\"Energy: {float(total):.4f}\"\n",
    "    except Exception:\n",
    "        return \"Energy: -\"\n",
    "    \n",
    "\n",
    "class VGraph:\n",
    "    def __init__(self,\n",
    "                 layers,\n",
    "                 nonlinear_factors=True,\n",
    "                 eta_damping=0.2,\n",
    "                 r_reduced=2,\n",
    "                 beta=0.0,\n",
    "                 iters_since_relinear=0,\n",
    "                 num_undamped_iters=0,\n",
    "                 min_linear_iters=100,\n",
    "                 wild_thresh=0):\n",
    "\n",
    "        self.layers = layers\n",
    "        self.iters_since_relinear = iters_since_relinear\n",
    "        self.min_linear_iters = min_linear_iters\n",
    "        self.nonlinear_factors = nonlinear_factors\n",
    "        self.eta_damping = eta_damping\n",
    "        self.r_reduced = r_reduced\n",
    "        self.wild_thresh = wild_thresh\n",
    "\n",
    "        #self.energy_history = []\n",
    "        #self.error_history = []\n",
    "        #self.nmsgs_history = []\n",
    "        #self.mus = []\n",
    "\n",
    "\n",
    "    def vloop(self):\n",
    "        \"\"\"\n",
    "        Simplified V-cycle:\n",
    "        1) bottom-up: rebuild and iterate once for base / super / abs in order\n",
    "        2) top-down: propagate mu from super -> base\n",
    "        3) refresh gbp_result on each layer for UI use\n",
    "        \"\"\"\n",
    "\n",
    "        layers = self.layers\n",
    "\n",
    "        # ---- bottom-up ----\n",
    "        #if layers and \"graph\" in layers[0]:\n",
    "        #    layers[0][\"graph\"].synchronous_iteration()\n",
    "            \n",
    "        for i in range(1, len(layers)):\n",
    "            name = layers[i][\"name\"]\n",
    "\n",
    "            if name.startswith(\"super1\"):\n",
    "                # Update super using the previous base graph's new linearization points\n",
    "                pass\n",
    "\n",
    "            elif name.startswith(\"super\"):\n",
    "                a = time.time()\n",
    "                # Update super using the previous layer's graph\n",
    "                layers[i][\"graph\"] = bottom_up_modify_super_graph(layers[:i+1], eta_damping=self.eta_damping)\n",
    "                print(f\"Bottom-up {name} build time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            elif name.startswith(\"abs\"):\n",
    "                # Rebuild abs using the previous super\n",
    "                a = time.time()\n",
    "                abs_graph, Bs, ks, k2s = bottom_up_modify_abs_graph(layers[:i+1], eta_damping=self.eta_damping, r_reduced=self.r_reduced)\n",
    "                layers[i][\"graph\"] = abs_graph\n",
    "                layers[i][\"Bs\"], layers[i][\"ks\"], layers[i][\"k2s\"] = Bs, ks, k2s\n",
    "                print(f\"Bottom-up {name} build time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            # After build, one iteration per layer\n",
    "            if \"graph\" in layers[i]:\n",
    "                a = time.time()\n",
    "                layers[i][\"graph\"].synchronous_iteration()\n",
    "                print(f\"Bottom-up {name} iteration time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "        # ---- top-down (pass mu) ----\n",
    "        for i in range(len(layers) - 1, 0, -1):\n",
    "            # After one iterations per layer, reproject\n",
    "            if \"graph\" in layers[i]:\n",
    "                #a = time.time()\n",
    "                layers[i][\"graph\"].synchronous_iteration()\n",
    "                #print(f\"Top-down {layers[i]['name']} iteration time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            #if i == len(layers) - 1:\n",
    "            # extra iteration for abs layer\n",
    "            #    layers[i][\"graph\"].synchronous_iteration()\n",
    "            # this is very important, but dont know why yet\n",
    "            # so abs layer need more iterations\n",
    "            #if name.startswith(\"abs\"):\n",
    "            #    layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "            name = layers[i][\"name\"]\n",
    "            if name.startswith(\"super\"):\n",
    "                #a = time.time()\n",
    "                # Split super.mu back to base/abs\n",
    "                top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "                #print(f\"Top-down {name} to base/abs time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "            elif name.startswith(\"abs\"):\n",
    "                # Project abs.mu back to super\n",
    "                #a = time.time()\n",
    "                top_down_modify_super_graph(layers[:i+1])\n",
    "                #print(f\"Top-down {name} to super time: {time.time() - a:.4f} sec\")\n",
    "\n",
    "        # ---- refresh gbp_result for UI ----\n",
    "        #refresh_gbp_results(layers)\n",
    "        return layers\n",
    "vg = VGraph(layers)\n",
    "\n",
    "\n",
    "def energy_map(graph, include_priors: bool = True, include_factors: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    It is actually the sum of squares of distances.\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "\n",
    "    for v in graph.var_nodes[:graph.n_var_nodes]:\n",
    "        gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "        r = np.asarray(v.mu[0:2], dtype=float) - gt\n",
    "        total += 0.5 * float(r.T @ r)\n",
    "\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edefd26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntotal = 0\\nimport time \\nxxxx = time.time()\\neta, lam = layers[0][\"graph\"].joint_distribution_inf()\\nprint(\"time:\", time.time() - xxxx)\\nxxxx = time.time()\\nsigma = np.linalg.inv(lam)\\nmu = sigma @ eta\\nprint(\"time:\", time.time() - xxxx)\\na = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\\nfor i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\\n    gt = np.asarray(v.GT[0:2], dtype=float)\\n    r = np.asarray(a[i][0:2], dtype=float) - gt\\n    total += 0.5 * float(r.T @ r)\\nprint(total)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=5000\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "\n",
    "\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "\n",
    "\n",
    "# construct GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "gbp_graph.num_undamped_iters = 0\n",
    "gbp_graph.min_linear_iters = 2000\n",
    "opts=[{\"label\":\"base\",\"value\":\"base\"}]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "total = 0\n",
    "import time \n",
    "xxxx = time.time()\n",
    "eta, lam = layers[0][\"graph\"].joint_distribution_inf()\n",
    "print(\"time:\", time.time() - xxxx)\n",
    "xxxx = time.time()\n",
    "sigma = np.linalg.inv(lam)\n",
    "mu = sigma @ eta\n",
    "print(\"time:\", time.time() - xxxx)\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd1b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13134.55713806725\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a0dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    for j in range(9000):\n",
    "        aaa = np.eye(10)\n",
    "        aaa = np.eye(10)\n",
    "        a = np.zeros((4,2))@np.zeros((2,2))@np.zeros((2,4))\n",
    "        a = np.zeros((4,2)) @ ( np.zeros((2,2))  @  (np.zeros((2,4)) @ np.zeros((4,1)) + np.zeros((2,1)) + np.zeros((2,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cc5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta, lam = layers[0][\"graph\"].joint_distribution_inf()\n",
    "mu = np.linalg.solve(lam, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225fc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 8955871233.618103\n",
      "Iter 002 | Energy = 8363239030.078079\n",
      "Iter 003 | Energy = 6554350571.501195\n",
      "Iter 004 | Energy = 3960628660.479564\n",
      "Iter 005 | Energy = 2237701022.551816\n",
      "Iter 006 | Energy = 1497892832.970353\n",
      "Iter 007 | Energy = 1140055046.437793\n",
      "Iter 008 | Energy = 857662876.849732\n",
      "Iter 009 | Energy = 661742787.088285\n",
      "Iter 010 | Energy = 543925066.675839\n",
      "Iter 011 | Energy = 430756574.774735\n",
      "Iter 012 | Energy = 328946621.589218\n",
      "Iter 013 | Energy = 244235462.204485\n",
      "Iter 014 | Energy = 193331206.754777\n",
      "Iter 015 | Energy = 150222292.905770\n",
      "Iter 016 | Energy = 110268323.481665\n",
      "Iter 017 | Energy = 85372846.295140\n",
      "Iter 018 | Energy = 68956218.571267\n",
      "Iter 019 | Energy = 63225266.845110\n",
      "Iter 020 | Energy = 54618169.111695\n",
      "Iter 021 | Energy = 40246057.549037\n",
      "Iter 022 | Energy = 28745897.676445\n",
      "Iter 023 | Energy = 20123262.463086\n",
      "Iter 024 | Energy = 14375856.980433\n",
      "Iter 025 | Energy = 8630848.151923\n",
      "Iter 026 | Energy = 2885286.430125\n",
      "Iter 027 | Energy = 14470.078337\n",
      "Iter 028 | Energy = 14294.500881\n",
      "Iter 029 | Energy = 14159.384307\n",
      "Iter 030 | Energy = 14029.456649\n",
      "Iter 031 | Energy = 13904.956565\n",
      "Iter 032 | Energy = 13788.606357\n",
      "Iter 033 | Energy = 13682.733780\n",
      "Iter 034 | Energy = 13588.489688\n",
      "Iter 035 | Energy = 13505.884562\n",
      "Iter 036 | Energy = 13434.105156\n",
      "Iter 037 | Energy = 13371.862925\n",
      "Iter 038 | Energy = 13317.690779\n",
      "Iter 039 | Energy = 13270.147748\n",
      "Iter 040 | Energy = 13227.938230\n",
      "Iter 041 | Energy = 13189.976267\n",
      "Iter 042 | Energy = 13155.411603\n",
      "Iter 043 | Energy = 13123.620701\n",
      "Iter 044 | Energy = 13094.169605\n",
      "Iter 045 | Energy = 13066.763318\n",
      "Iter 046 | Energy = 13041.196727\n",
      "Iter 047 | Energy = 13017.316278\n",
      "Iter 048 | Energy = 12994.995015\n",
      "Iter 049 | Energy = 12974.119253\n",
      "Iter 050 | Energy = 12954.583197\n",
      "Iter 051 | Energy = 12936.287748\n",
      "Iter 052 | Energy = 12919.140740\n",
      "Iter 053 | Energy = 12903.057199\n",
      "Iter 054 | Energy = 12887.959279\n",
      "Iter 055 | Energy = 12873.775939\n",
      "Iter 056 | Energy = 12860.442569\n",
      "Iter 057 | Energy = 12847.900595\n",
      "Iter 058 | Energy = 12836.097084\n",
      "Iter 059 | Energy = 12824.984325\n",
      "Iter 060 | Energy = 12814.519425\n",
      "Iter 061 | Energy = 12804.663922\n",
      "Iter 062 | Energy = 12795.383434\n",
      "Iter 063 | Energy = 12786.647320\n",
      "Iter 064 | Energy = 12778.428307\n",
      "Iter 065 | Energy = 12770.702085\n",
      "Iter 066 | Energy = 12763.446832\n",
      "Iter 067 | Energy = 12756.642703\n",
      "Iter 068 | Energy = 12750.271303\n",
      "Iter 069 | Energy = 12744.315202\n",
      "Iter 070 | Energy = 12738.757517\n",
      "Iter 071 | Energy = 12733.581591\n",
      "Iter 072 | Energy = 12728.770801\n",
      "Iter 073 | Energy = 12724.308470\n",
      "Iter 074 | Energy = 12720.177885\n",
      "Iter 075 | Energy = 12716.362391\n",
      "Iter 076 | Energy = 12712.845528\n",
      "Iter 077 | Energy = 12709.611192\n",
      "Iter 078 | Energy = 12706.643784\n",
      "Iter 079 | Energy = 12703.928334\n",
      "Iter 080 | Energy = 12701.450592\n",
      "Iter 081 | Energy = 12699.197074\n",
      "Iter 082 | Energy = 12697.155075\n",
      "Iter 083 | Energy = 12695.312646\n",
      "Iter 084 | Energy = 12693.658552\n",
      "Iter 085 | Energy = 12692.182220\n",
      "Iter 086 | Energy = 12690.873672\n",
      "Iter 087 | Energy = 12689.723475\n",
      "Iter 088 | Energy = 12688.722688\n",
      "Iter 089 | Energy = 12687.862818\n",
      "Iter 090 | Energy = 12687.135791\n",
      "Iter 091 | Energy = 12686.533929\n",
      "Iter 092 | Energy = 12686.049925\n",
      "Iter 093 | Energy = 12685.676839\n",
      "Iter 094 | Energy = 12685.408079\n",
      "Iter 095 | Energy = 12685.237392\n",
      "Iter 096 | Energy = 12685.158852\n",
      "Iter 097 | Energy = 12685.166848\n",
      "Iter 098 | Energy = 12685.256069\n",
      "Iter 099 | Energy = 12685.421488\n",
      "Iter 100 | Energy = 12685.658350\n",
      "Iter 101 | Energy = 12685.962153\n",
      "Iter 102 | Energy = 12686.328635\n",
      "Iter 103 | Energy = 12686.753762\n",
      "Iter 104 | Energy = 12687.233714\n",
      "Iter 105 | Energy = 12687.764875\n",
      "Iter 106 | Energy = 12688.343820\n",
      "Iter 107 | Energy = 12688.967312\n",
      "Iter 108 | Energy = 12689.632287\n",
      "Iter 109 | Energy = 12690.335850\n",
      "Iter 110 | Energy = 12691.075266\n",
      "Iter 111 | Energy = 12691.847953\n",
      "Iter 112 | Energy = 12692.651472\n",
      "Iter 113 | Energy = 12693.483525\n",
      "Iter 114 | Energy = 12694.341943\n",
      "Iter 115 | Energy = 12695.224680\n",
      "Iter 116 | Energy = 12696.129807\n",
      "Iter 117 | Energy = 12697.055505\n",
      "Iter 118 | Energy = 12698.000055\n",
      "Iter 119 | Energy = 12698.961838\n",
      "Iter 120 | Energy = 12699.939324\n",
      "Iter 121 | Energy = 12700.931070\n",
      "Iter 122 | Energy = 12701.935712\n",
      "Iter 123 | Energy = 12702.951960\n",
      "Iter 124 | Energy = 12703.978598\n",
      "Iter 125 | Energy = 12705.014475\n",
      "Iter 126 | Energy = 12706.058505\n",
      "Iter 127 | Energy = 12707.109660\n",
      "Iter 128 | Energy = 12708.166972\n",
      "Iter 129 | Energy = 12709.229523\n",
      "Iter 130 | Energy = 12710.296451\n",
      "Iter 131 | Energy = 12711.366941\n",
      "Iter 132 | Energy = 12712.440224\n",
      "Iter 133 | Energy = 12713.515577\n",
      "Iter 134 | Energy = 12714.592319\n",
      "Iter 135 | Energy = 12715.669809\n",
      "Iter 136 | Energy = 12716.747446\n",
      "Iter 137 | Energy = 12717.824663\n",
      "Iter 138 | Energy = 12718.900930\n",
      "Iter 139 | Energy = 12719.975750\n",
      "Iter 140 | Energy = 12721.048658\n",
      "Iter 141 | Energy = 12722.119216\n",
      "Iter 142 | Energy = 12723.187019\n",
      "Iter 143 | Energy = 12724.251687\n",
      "Iter 144 | Energy = 12725.312864\n",
      "Iter 145 | Energy = 12726.370220\n",
      "Iter 146 | Energy = 12727.423451\n",
      "Iter 147 | Energy = 12728.472270\n",
      "Iter 148 | Energy = 12729.516414\n",
      "Iter 149 | Energy = 12730.555640\n",
      "Iter 150 | Energy = 12731.589722\n",
      "Iter 151 | Energy = 12732.618454\n",
      "Iter 152 | Energy = 12733.641644\n",
      "Iter 153 | Energy = 12734.659120\n",
      "Iter 154 | Energy = 12735.670723\n",
      "Iter 155 | Energy = 12736.676306\n",
      "Iter 156 | Energy = 12737.675741\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#energy_gt = 7812.353496639449\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2000\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mbasegraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronous_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     energy \u001b[38;5;241m=\u001b[39m energy_map(basegraph, include_priors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_factors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(energy_prev\u001b[38;5;241m-\u001b[39menergy) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-2\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:220\u001b[0m, in \u001b[0;36mFactorGraph.synchronous_iteration\u001b[0;34m(self, factors, level, local_relin, robustify)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinear_factors \u001b[38;5;129;01mand\u001b[39;00m local_relin:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelinearise_factors(factors)\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_all_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_relin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_relin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1e-9\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_all_beliefs(\u001b[38;5;28mvars\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:101\u001b[0m, in \u001b[0;36mFactorGraph.compute_all_messages\u001b[0;34m(self, factors, level, local_relin)\u001b[0m\n\u001b[1;32m     99\u001b[0m     factor\u001b[38;5;241m.\u001b[39mcompute_messages(factor\u001b[38;5;241m.\u001b[39meta_damping)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mfactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meta_damping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:924\u001b[0m, in \u001b[0;36mFactor.compute_messages\u001b[0;34m(self, eta_damping)\u001b[0m\n\u001b[1;32m    921\u001b[0m lnono \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(lnono\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 924\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlnono\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlnono shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lnono\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/numpy/linalg/_linalg.py:837\u001b[0m, in \u001b[0;36mcholesky\u001b[0;34m(a, upper)\u001b[0m\n\u001b[1;32m    835\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[1;32m    836\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43merrstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_raise_linalgerror_nonposdef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvalid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m              \u001b[49m\u001b[43mover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdivide\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    839\u001b[0m     r \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/numpy/_core/_ufunc_config.py:430\u001b[0m, in \u001b[0;36merrstate.__init__\u001b[0;34m(self, call, all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03merrstate(**kwargs)\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_all\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_divide\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_over\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_under\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_invalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, call\u001b[38;5;241m=\u001b[39m_Unspecified,\n\u001b[1;32m    431\u001b[0m              \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call \u001b[38;5;241m=\u001b[39m call\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basegraph = layers[0][\"graph\"]\n",
    "basegraph.eta_damping = 0.4\n",
    "energy_prev = 2324.863742569365\n",
    "\n",
    "counter = 0\n",
    "#energy_gt = 7812.353496639449\n",
    "for it in range(2000):\n",
    "    basegraph.synchronous_iteration()\n",
    "    energy = energy_map(basegraph, include_priors=True, include_factors=True)\n",
    "\n",
    "    if np.abs(energy_prev-energy) < 1e-2:\n",
    "        counter += 1\n",
    "        if counter >= 2:\n",
    "            break\n",
    "    #energy_prev = energy\n",
    "    print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42add78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dcec503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom-up super1 iteration time: 0.4015 sec\n",
      "Bottom-up abs1 build time: 0.1906 sec\n",
      "Bottom-up abs1 iteration time: 0.0459 sec\n",
      "Bottom-up super2 build time: 0.1623 sec\n",
      "Bottom-up super2 iteration time: 0.0681 sec\n",
      "Bottom-up abs2 build time: 0.1591 sec\n",
      "Bottom-up abs2 iteration time: 0.0010 sec\n",
      "Bottom-up super3 build time: 0.1735 sec\n",
      "Bottom-up super3 iteration time: 0.0007 sec\n",
      "Bottom-up abs3 build time: 0.1685 sec\n",
      "Bottom-up abs3 iteration time: 0.0002 sec\n",
      "Iter 001 | Energy = 8668423.948079\n",
      "Bottom-up super1 iteration time: 0.1551 sec\n",
      "Bottom-up abs1 build time: 0.1707 sec\n",
      "Bottom-up abs1 iteration time: 0.0429 sec\n",
      "Bottom-up super2 build time: 0.1627 sec\n",
      "Bottom-up super2 iteration time: 0.0667 sec\n",
      "Bottom-up abs2 build time: 0.1542 sec\n",
      "Bottom-up abs2 iteration time: 0.0014 sec\n",
      "Bottom-up super3 build time: 0.1667 sec\n",
      "Bottom-up super3 iteration time: 0.0006 sec\n",
      "Bottom-up abs3 build time: 0.1769 sec\n",
      "Bottom-up abs3 iteration time: 0.0002 sec\n",
      "Iter 002 | Energy = 17988.177201\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    145\u001b[39m vg.r_reduced=\u001b[32m2\u001b[39m\n\u001b[32m    146\u001b[39m vg.eta_damping = \u001b[32m0.4\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m vg.layers = \u001b[43mvg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m energy = energy_map(layers[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m], include_priors=\u001b[38;5;28;01mTrue\u001b[39;00m, include_factors=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.abs(energy_prev-energy) < \u001b[32m1e-2\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1774\u001b[39m, in \u001b[36mVGraph.vloop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layers[i]:\n\u001b[32m   1773\u001b[39m         a = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1774\u001b[39m         \u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgraph\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronous_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1775\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBottom-up \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m iteration time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1777\u001b[39m \u001b[38;5;66;03m# ---- top-down (pass mu) ----\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:220\u001b[39m, in \u001b[36mFactorGraph.synchronous_iteration\u001b[39m\u001b[34m(self, factors, level, local_relin, robustify)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nonlinear_factors \u001b[38;5;129;01mand\u001b[39;00m local_relin:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m.relinearise_factors(factors)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_all_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_relin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_relin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m time.sleep(\u001b[32m1e-9\u001b[39m)\n\u001b[32m    222\u001b[39m \u001b[38;5;28mself\u001b[39m.update_all_beliefs(\u001b[38;5;28mvars\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:101\u001b[39m, in \u001b[36mFactorGraph.compute_all_messages\u001b[39m\u001b[34m(self, factors, level, local_relin)\u001b[39m\n\u001b[32m     99\u001b[39m     factor.compute_messages(factor.eta_damping)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[43mfactor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meta_damping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_msgs += \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:935\u001b[39m, in \u001b[36mFactor.compute_messages\u001b[39m\u001b[34m(self, eta_damping)\u001b[39m\n\u001b[32m    933\u001b[39m rhs_j = np.concatenate([lnoo, eno.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)], axis=\u001b[32m1\u001b[39m)   \u001b[38;5;66;03m# (n, n+1)\u001b[39;00m\n\u001b[32m    934\u001b[39m \u001b[38;5;66;03m# cho_solve:  lnono_j * X = rhs_j\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m X = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcho_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs_j\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# True: L is lower diagonal\u001b[39;00m\n\u001b[32m    936\u001b[39m X_lam = X[:, :lnoo.shape[\u001b[32m1\u001b[39m]]\n\u001b[32m    937\u001b[39m X_eta = X[:, -\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/jax-gpu/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py:211\u001b[39m, in \u001b[36mcho_solve\u001b[39m\u001b[34m(c_and_lower, b, overwrite_b, check_finite)\u001b[39m\n\u001b[32m    208\u001b[39m overwrite_b = overwrite_b \u001b[38;5;129;01mor\u001b[39;00m _datacopied(b1, b)\n\u001b[32m    210\u001b[39m potrs, = get_lapack_funcs((\u001b[33m'\u001b[39m\u001b[33mpotrs\u001b[39m\u001b[33m'\u001b[39m,), (c, b1))\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m x, info = \u001b[43mpotrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info != \u001b[32m0\u001b[39m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33mth argument of internal potrs\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    214\u001b[39m                      % -info)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "N=5000\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "import time\n",
    "\n",
    "\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "\n",
    "\n",
    "\n",
    "# Create GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "gbp_graph.num_undamped_iters = 0\n",
    "gbp_graph.min_linear_iters = 2000\n",
    "opts=[{\"label\":\"base\",\"value\":\"base\"}]\n",
    "\n",
    "\n",
    "kk = 18\n",
    "k_next = 1\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure base graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "\n",
    "abs_layer_idx = 2\n",
    "k = 1\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(\n",
    "    layers, r_reduced=2)\n",
    "\n",
    "\n",
    "k_next = 2\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "\n",
    "abs_layer_idx = 4\n",
    "k = 2\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(\n",
    "    layers, r_reduced=2)\n",
    "\n",
    "\n",
    "\n",
    "k_next = 3\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "abs_layer_idx = 6\n",
    "k = 3\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(layers)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "k_next = 4\n",
    "super_layer_idx = k_next*2 - 1\n",
    "last = layers[-1]\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(last[\"nodes\"], last[\"edges\"], int(kk or 8), super_layer_idx, tail_heavy=True)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"super{k_next}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "if super_layer_idx > 1:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "else:\n",
    "    layers[super_layer_idx][\"graph\"] = build_super_graph(layers)\n",
    "\n",
    "\n",
    "abs_layer_idx = 8\n",
    "k = 4\n",
    "last = layers[-1]\n",
    "abs_nodes, abs_edges = copy_to_abs(last[\"nodes\"], last[\"edges\"], abs_layer_idx)\n",
    "# Ensure super graph has run at least once\n",
    "layers[-1][\"graph\"].synchronous_iteration() \n",
    "layers.append({\"name\":f\"abs{k}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = build_abs_graph(layers)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(2000):\n",
    "    layers[1][\"graph\"].synchronous_iteration()\n",
    "    layers[0][\"graph\"].synchronous_iteration()\n",
    "    layers[2][\"graph\"].synchronous_iteration()\n",
    "    #top_down_modify_super_graph(layers[:])\n",
    "    #top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {i+1:03d} | Energy = {energy:.6f}\")\n",
    "\"\"\"\n",
    "\n",
    "vg = VGraph(layers)\n",
    "energy_prev = 0\n",
    "#energy_prev = 2324.863742569365\n",
    "counter = 0\n",
    "for _ in range(1000):\n",
    "    vg.layers = layers\n",
    "    vg.r_reduced=2\n",
    "    vg.eta_damping = 0.4\n",
    "    vg.layers = vg.vloop()\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    if np.abs(energy_prev-energy) < 1e-2:\n",
    "        counter += 1\n",
    "        if counter >= 2:\n",
    "            break\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")\n",
    "    energy_prev = energy\n",
    "refresh_gbp_results(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf06b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iteration time:  0.4568\n",
      "super1:  0.35009999999999997\n",
      "ratio:  0.7664185639229422\n",
      "\n",
      "total building and backing time:  1.1084999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"total iteration time: \", 0.1708+0.0386+0.0044+0.0015+0.0002+0.0001+0.0001+0.0018+0.0011+0.0145+0.0444+0.1793)\n",
    "print(\"super1: \", 0.1708+0.1793)\n",
    "print(\"ratio: \", 0.35009999999999997/0.4568)\n",
    "\n",
    "print(\"\")\n",
    "print(\"total building and backing time: \", 0.0774+0.1253+0.0925+0.4952+0.2424 + 0.0000+0.0003+0.0004+0.0081+0.0121+0.0548)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140348b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "aa = deepcopy(layers[1][\"graph\"])\n",
    "for i in range(1000):\n",
    "    aa.synchronous_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "for i in range(1000):\n",
    "    layers[-1][\"graph\"].synchronous_iteration()\n",
    "\n",
    "bb = deepcopy(layers[-1][\"graph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21979a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[2][\"graph\"] = deepcopy(bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd2bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.3736346  104.33323553]\n",
      "[ 44.3736346  104.33323553]\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(\n",
    "    layers[:3], eta_damping=0, r_reduced=2)\n",
    "\n",
    "#layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "print(layers[abs_layer_idx][\"graph\"].var_nodes[0].mu)\n",
    "print(bb.var_nodes[0].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.38048663 104.34497706]\n",
      "[ 44.3736346  104.33323553]\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"].compute_all_messages()\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "print(layers[abs_layer_idx][\"graph\"].var_nodes[0].mu)\n",
    "bb.synchronous_iteration\n",
    "print(bb.var_nodes[0].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2342.435012\n"
     ]
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_super_graph(layers[:3])\n",
    "top_down_modify_base_and_abs_graph(layers[:2])\n",
    "\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cffe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.55637974e+00, -2.08956516e-16],\n",
       "       [-2.08957089e-16,  3.55637974e+00]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[abs_layer_idx][\"graph\"].var_nodes[0].Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c9bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.55637974e+00, -2.08956489e-16],\n",
       "       [-2.08957608e-16,  3.55637974e+00]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.var_nodes[0].Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2328.725297\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "abs_graph, Bs, ks, k2s = bottom_up_modify_abs_graph(layers[:], eta_damping=0)\n",
    "layers[2][\"graph\"] = abs_graph\n",
    "layers[2][\"Bs\"], layers[2][\"ks\"], layers[2][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "layers[2][\"graph\"].synchronous_iteration()\n",
    "layers[2][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_super_graph(layers[:3])\n",
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "\n",
    "top_down_modify_base_and_abs_graph(layers[:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74759123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 001 | Energy = 2328.725279\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for i in range(1, len(layers)):\n",
    "        name = layers[i][\"name\"]\n",
    "\n",
    "        if name.startswith(\"super1\"):\n",
    "            # Update super using the previous base graph's new linearization points\n",
    "            pass\n",
    "\n",
    "        elif name.startswith(\"super\"):\n",
    "            # Update super using the previous layer's graph\n",
    "            layers[i][\"graph\"] = build_super_graph(layers[:i+1], eta_damping=0)\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Rebuild abs using the previous super\n",
    "            abs_graph, Bs, ks, k2s = bottom_up_modify_abs_graph(layers[:i+1], eta_damping=0)\n",
    "            layers[i][\"graph\"] = abs_graph\n",
    "            layers[i][\"Bs\"], layers[i][\"ks\"], layers[i][\"k2s\"] = Bs, ks, k2s\n",
    "\n",
    "        # After build, one iteration per layer\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "    # ---- top-down (pass mu) ----\n",
    "    for i in range(len(layers) - 1, 0, -1):\n",
    "        # After one iterations per layer, reproject\n",
    "        if \"graph\" in layers[i]:\n",
    "            layers[i][\"graph\"].synchronous_iteration()\n",
    "\n",
    "        # this is very important, but dont know why yet\n",
    "        # so abs layer need more iterations\n",
    "        #if name.startswith(\"abs\"):\n",
    "        #    layers[i][\"graph\"].synchronous_iteration()  \n",
    "\n",
    "        name = layers[i][\"name\"]\n",
    "        if name.startswith(\"super\"):\n",
    "            # Split super.mu back to base/abs\n",
    "            top_down_modify_base_and_abs_graph(layers[:i+1])\n",
    "\n",
    "        elif name.startswith(\"abs\"):\n",
    "            # Project abs.mu back to super\n",
    "            top_down_modify_super_graph(layers[:i+1])\n",
    "\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23715db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Energy = 2333.057456\n",
      "Iter 1000 | Energy = 2342.434528\n",
      "Iter 1000 | Energy = 2346.848939\n",
      "Iter 1000 | Energy = 2342.829773\n",
      "Iter 1000 | Energy = 2335.406501\n",
      "Iter 1000 | Energy = 2329.460781\n",
      "Iter 1000 | Energy = 2326.647628\n",
      "Iter 1000 | Energy = 2326.626961\n",
      "Iter 1000 | Energy = 2328.345039\n",
      "Iter 1000 | Energy = 2330.722005\n",
      "Iter 1000 | Energy = 2332.962662\n",
      "Iter 1000 | Energy = 2334.638546\n",
      "Iter 1000 | Energy = 2335.631414\n",
      "Iter 1000 | Energy = 2336.017356\n",
      "Iter 1000 | Energy = 2335.954211\n",
      "Iter 1000 | Energy = 2335.604993\n",
      "Iter 1000 | Energy = 2335.101330\n",
      "Iter 1000 | Energy = 2334.535153\n",
      "Iter 1000 | Energy = 2333.964155\n",
      "Iter 1000 | Energy = 2333.420888\n",
      "Iter 1000 | Energy = 2332.920827\n",
      "Iter 1000 | Energy = 2332.468334\n",
      "Iter 1000 | Energy = 2332.060933\n",
      "Iter 1000 | Energy = 2331.692470\n",
      "Iter 1000 | Energy = 2331.355442\n",
      "Iter 1000 | Energy = 2331.042599\n",
      "Iter 1000 | Energy = 2330.747874\n",
      "Iter 1000 | Energy = 2330.466759\n",
      "Iter 1000 | Energy = 2330.196290\n",
      "Iter 1000 | Energy = 2329.934812\n",
      "Iter 1000 | Energy = 2329.681658\n",
      "Iter 1000 | Energy = 2329.436830\n",
      "Iter 1000 | Energy = 2329.200709\n",
      "Iter 1000 | Energy = 2328.973831\n",
      "Iter 1000 | Energy = 2328.756714\n",
      "Iter 1000 | Energy = 2328.549747\n",
      "Iter 1000 | Energy = 2328.353128\n",
      "Iter 1000 | Energy = 2328.166851\n",
      "Iter 1000 | Energy = 2327.990716\n",
      "Iter 1000 | Energy = 2327.824369\n",
      "Iter 1000 | Energy = 2327.667349\n",
      "Iter 1000 | Energy = 2327.519130\n",
      "Iter 1000 | Energy = 2327.379160\n",
      "Iter 1000 | Energy = 2327.246897\n",
      "Iter 1000 | Energy = 2327.121824\n",
      "Iter 1000 | Energy = 2327.003463\n",
      "Iter 1000 | Energy = 2326.891382\n",
      "Iter 1000 | Energy = 2326.785194\n",
      "Iter 1000 | Energy = 2326.684551\n",
      "Iter 1000 | Energy = 2326.589143\n",
      "Iter 1000 | Energy = 2326.498690\n",
      "Iter 1000 | Energy = 2326.412933\n",
      "Iter 1000 | Energy = 2326.331635\n",
      "Iter 1000 | Energy = 2326.254574\n",
      "Iter 1000 | Energy = 2326.181536\n",
      "Iter 1000 | Energy = 2326.112322\n",
      "Iter 1000 | Energy = 2326.046737\n",
      "Iter 1000 | Energy = 2325.984597\n",
      "Iter 1000 | Energy = 2325.925723\n",
      "Iter 1000 | Energy = 2325.869946\n",
      "Iter 1000 | Energy = 2325.817103\n",
      "Iter 1000 | Energy = 2325.767039\n",
      "Iter 1000 | Energy = 2325.719608\n",
      "Iter 1000 | Energy = 2325.674670\n",
      "Iter 1000 | Energy = 2325.632093\n",
      "Iter 1000 | Energy = 2325.591752\n",
      "Iter 1000 | Energy = 2325.553529\n",
      "Iter 1000 | Energy = 2325.517313\n",
      "Iter 1000 | Energy = 2325.482997\n",
      "Iter 1000 | Energy = 2325.450483\n",
      "Iter 1000 | Energy = 2325.419675\n",
      "Iter 1000 | Energy = 2325.390484\n",
      "Iter 1000 | Energy = 2325.362825\n",
      "Iter 1000 | Energy = 2325.336619\n",
      "Iter 1000 | Energy = 2325.311788\n",
      "Iter 1000 | Energy = 2325.288261\n",
      "Iter 1000 | Energy = 2325.265970\n",
      "Iter 1000 | Energy = 2325.244849\n",
      "Iter 1000 | Energy = 2325.224838\n",
      "Iter 1000 | Energy = 2325.205877\n",
      "Iter 1000 | Energy = 2325.187912\n",
      "Iter 1000 | Energy = 2325.170891\n",
      "Iter 1000 | Energy = 2325.154763\n",
      "Iter 1000 | Energy = 2325.139482\n",
      "Iter 1000 | Energy = 2325.125004\n",
      "Iter 1000 | Energy = 2325.111286\n",
      "Iter 1000 | Energy = 2325.098288\n",
      "Iter 1000 | Energy = 2325.085973\n",
      "Iter 1000 | Energy = 2325.074304\n",
      "Iter 1000 | Energy = 2325.063248\n",
      "Iter 1000 | Energy = 2325.052773\n",
      "Iter 1000 | Energy = 2325.042848\n",
      "Iter 1000 | Energy = 2325.033444\n",
      "Iter 1000 | Energy = 2325.024533\n",
      "Iter 1000 | Energy = 2325.016091\n",
      "Iter 1000 | Energy = 2325.008092\n",
      "Iter 1000 | Energy = 2325.000513\n",
      "Iter 1000 | Energy = 2324.993331\n",
      "Iter 1000 | Energy = 2324.986527\n",
      "Iter 1000 | Energy = 2324.980080\n",
      "Iter 1000 | Energy = 2324.973972\n",
      "Iter 1000 | Energy = 2324.968184\n",
      "Iter 1000 | Energy = 2324.962701\n",
      "Iter 1000 | Energy = 2324.957505\n",
      "Iter 1000 | Energy = 2324.952582\n",
      "Iter 1000 | Energy = 2324.947918\n",
      "Iter 1000 | Energy = 2324.943498\n",
      "Iter 1000 | Energy = 2324.939311\n",
      "Iter 1000 | Energy = 2324.935343\n",
      "Iter 1000 | Energy = 2324.931584\n",
      "Iter 1000 | Energy = 2324.928022\n",
      "Iter 1000 | Energy = 2324.924647\n",
      "Iter 1000 | Energy = 2324.921449\n",
      "Iter 1000 | Energy = 2324.918419\n",
      "Iter 1000 | Energy = 2324.915549\n",
      "Iter 1000 | Energy = 2324.912829\n",
      "Iter 1000 | Energy = 2324.910251\n",
      "Iter 1000 | Energy = 2324.907810\n",
      "Iter 1000 | Energy = 2324.905496\n",
      "Iter 1000 | Energy = 2324.903304\n",
      "Iter 1000 | Energy = 2324.901227\n",
      "Iter 1000 | Energy = 2324.899259\n",
      "Iter 1000 | Energy = 2324.897394\n",
      "Iter 1000 | Energy = 2324.895627\n",
      "Iter 1000 | Energy = 2324.893953\n",
      "Iter 1000 | Energy = 2324.892367\n",
      "Iter 1000 | Energy = 2324.890864\n",
      "Iter 1000 | Energy = 2324.889440\n",
      "Iter 1000 | Energy = 2324.888091\n",
      "Iter 1000 | Energy = 2324.886813\n",
      "Iter 1000 | Energy = 2324.885602\n",
      "Iter 1000 | Energy = 2324.884454\n",
      "Iter 1000 | Energy = 2324.883367\n",
      "Iter 1000 | Energy = 2324.882336\n",
      "Iter 1000 | Energy = 2324.881360\n",
      "Iter 1000 | Energy = 2324.880435\n",
      "Iter 1000 | Energy = 2324.879559\n",
      "Iter 1000 | Energy = 2324.878729\n",
      "Iter 1000 | Energy = 2324.877942\n",
      "Iter 1000 | Energy = 2324.877196\n",
      "Iter 1000 | Energy = 2324.876490\n",
      "Iter 1000 | Energy = 2324.875821\n",
      "Iter 1000 | Energy = 2324.875187\n",
      "Iter 1000 | Energy = 2324.874586\n",
      "Iter 1000 | Energy = 2324.874017\n",
      "Iter 1000 | Energy = 2324.873477\n",
      "Iter 1000 | Energy = 2324.872966\n",
      "Iter 1000 | Energy = 2324.872482\n",
      "Iter 1000 | Energy = 2324.872023\n",
      "Iter 1000 | Energy = 2324.871589\n",
      "Iter 1000 | Energy = 2324.871177\n",
      "Iter 1000 | Energy = 2324.870787\n",
      "Iter 1000 | Energy = 2324.870417\n",
      "Iter 1000 | Energy = 2324.870066\n",
      "Iter 1000 | Energy = 2324.869735\n",
      "Iter 1000 | Energy = 2324.869420\n",
      "Iter 1000 | Energy = 2324.869122\n",
      "Iter 1000 | Energy = 2324.868840\n",
      "Iter 1000 | Energy = 2324.868572\n",
      "Iter 1000 | Energy = 2324.868319\n",
      "Iter 1000 | Energy = 2324.868078\n",
      "Iter 1000 | Energy = 2324.867851\n",
      "Iter 1000 | Energy = 2324.867635\n",
      "Iter 1000 | Energy = 2324.867431\n",
      "Iter 1000 | Energy = 2324.867237\n",
      "Iter 1000 | Energy = 2324.867054\n",
      "Iter 1000 | Energy = 2324.866880\n",
      "Iter 1000 | Energy = 2324.866716\n",
      "Iter 1000 | Energy = 2324.866560\n",
      "Iter 1000 | Energy = 2324.866412\n",
      "Iter 1000 | Energy = 2324.866272\n",
      "Iter 1000 | Energy = 2324.866139\n",
      "Iter 1000 | Energy = 2324.866013\n",
      "Iter 1000 | Energy = 2324.865894\n",
      "Iter 1000 | Energy = 2324.865781\n",
      "Iter 1000 | Energy = 2324.865674\n",
      "Iter 1000 | Energy = 2324.865573\n",
      "Iter 1000 | Energy = 2324.865477\n",
      "Iter 1000 | Energy = 2324.865386\n",
      "Iter 1000 | Energy = 2324.865300\n",
      "Iter 1000 | Energy = 2324.865218\n",
      "Iter 1000 | Energy = 2324.865141\n",
      "Iter 1000 | Energy = 2324.865067\n",
      "Iter 1000 | Energy = 2324.864998\n",
      "Iter 1000 | Energy = 2324.864932\n",
      "Iter 1000 | Energy = 2324.864870\n",
      "Iter 1000 | Energy = 2324.864811\n",
      "Iter 1000 | Energy = 2324.864755\n",
      "Iter 1000 | Energy = 2324.864701\n",
      "Iter 1000 | Energy = 2324.864651\n",
      "Iter 1000 | Energy = 2324.864604\n",
      "Iter 1000 | Energy = 2324.864558\n",
      "Iter 1000 | Energy = 2324.864516\n",
      "Iter 1000 | Energy = 2324.864475\n",
      "Iter 1000 | Energy = 2324.864437\n",
      "Iter 1000 | Energy = 2324.864400\n",
      "Iter 1000 | Energy = 2324.864366\n",
      "Iter 1000 | Energy = 2324.864333\n",
      "Iter 1000 | Energy = 2324.864302\n",
      "Iter 1000 | Energy = 2324.864273\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"] = deepcopy(aa)\n",
    "layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "for i in range(1):\n",
    "    layers[-1][\"graph\"].synchronous_iteration()\n",
    "    top_down_modify_super_graph(layers[:])\n",
    "    top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000 | Energy = 2333.057544\n",
      "Iter 1000 | Energy = 2339.952725\n",
      "Iter 1000 | Energy = 2347.586783\n",
      "Iter 1000 | Energy = 2352.982718\n",
      "Iter 1000 | Energy = 2357.693991\n",
      "Iter 1000 | Energy = 2361.411014\n",
      "Iter 1000 | Energy = 2365.057877\n",
      "Iter 1000 | Energy = 2368.261650\n",
      "Iter 1000 | Energy = 2371.582692\n",
      "Iter 1000 | Energy = 2374.661040\n",
      "Iter 1000 | Energy = 2377.845726\n",
      "Iter 1000 | Energy = 2380.855475\n",
      "Iter 1000 | Energy = 2383.912300\n",
      "Iter 1000 | Energy = 2386.818810\n",
      "Iter 1000 | Energy = 2389.717175\n",
      "Iter 1000 | Energy = 2392.477801\n",
      "Iter 1000 | Energy = 2395.191398\n",
      "Iter 1000 | Energy = 2397.777201\n",
      "Iter 1000 | Energy = 2400.292543\n",
      "Iter 1000 | Energy = 2402.689672\n",
      "Iter 1000 | Energy = 2405.004386\n",
      "Iter 1000 | Energy = 2407.210328\n",
      "Iter 1000 | Energy = 2409.329563\n",
      "Iter 1000 | Energy = 2411.349136\n",
      "Iter 1000 | Energy = 2413.282492\n",
      "Iter 1000 | Energy = 2415.124784\n",
      "Iter 1000 | Energy = 2416.884155\n",
      "Iter 1000 | Energy = 2418.560459\n",
      "Iter 1000 | Energy = 2420.158657\n",
      "Iter 1000 | Energy = 2421.681164\n",
      "Iter 1000 | Energy = 2423.131086\n",
      "Iter 1000 | Energy = 2424.512092\n",
      "Iter 1000 | Energy = 2425.826246\n",
      "Iter 1000 | Energy = 2427.077689\n",
      "Iter 1000 | Energy = 2428.267934\n",
      "Iter 1000 | Energy = 2429.401148\n",
      "Iter 1000 | Energy = 2430.478569\n",
      "Iter 1000 | Energy = 2431.504155\n",
      "Iter 1000 | Energy = 2432.479022\n",
      "Iter 1000 | Energy = 2433.406803\n",
      "Iter 1000 | Energy = 2434.288568\n",
      "Iter 1000 | Energy = 2435.127586\n",
      "Iter 1000 | Energy = 2435.924912\n",
      "Iter 1000 | Energy = 2436.683451\n",
      "Iter 1000 | Energy = 2437.404254\n",
      "Iter 1000 | Energy = 2438.089883\n",
      "Iter 1000 | Energy = 2438.741377\n",
      "Iter 1000 | Energy = 2439.360990\n",
      "Iter 1000 | Energy = 2439.949741\n",
      "Iter 1000 | Energy = 2440.509609\n",
      "Iter 1000 | Energy = 2441.041583\n",
      "Iter 1000 | Energy = 2441.547402\n",
      "Iter 1000 | Energy = 2442.028017\n",
      "Iter 1000 | Energy = 2442.484955\n",
      "Iter 1000 | Energy = 2442.919122\n",
      "Iter 1000 | Energy = 2443.331864\n",
      "Iter 1000 | Energy = 2443.724038\n",
      "Iter 1000 | Energy = 2444.096829\n",
      "Iter 1000 | Energy = 2444.451042\n",
      "Iter 1000 | Energy = 2444.787726\n",
      "Iter 1000 | Energy = 2445.107631\n",
      "Iter 1000 | Energy = 2445.411687\n",
      "Iter 1000 | Energy = 2445.700589\n",
      "Iter 1000 | Energy = 2445.975163\n",
      "Iter 1000 | Energy = 2446.236054\n",
      "Iter 1000 | Energy = 2446.483995\n",
      "Iter 1000 | Energy = 2446.719578\n",
      "Iter 1000 | Energy = 2446.943460\n",
      "Iter 1000 | Energy = 2447.156182\n",
      "Iter 1000 | Energy = 2447.358332\n",
      "Iter 1000 | Energy = 2447.550405\n",
      "Iter 1000 | Energy = 2447.732926\n",
      "Iter 1000 | Energy = 2447.906349\n",
      "Iter 1000 | Energy = 2448.071144\n",
      "Iter 1000 | Energy = 2448.227722\n",
      "Iter 1000 | Energy = 2448.376508\n",
      "Iter 1000 | Energy = 2448.517875\n",
      "Iter 1000 | Energy = 2448.652204\n",
      "Iter 1000 | Energy = 2448.779835\n",
      "Iter 1000 | Energy = 2448.901109\n",
      "Iter 1000 | Energy = 2449.016336\n",
      "Iter 1000 | Energy = 2449.125822\n",
      "Iter 1000 | Energy = 2449.229849\n",
      "Iter 1000 | Energy = 2449.328691\n",
      "Iter 1000 | Energy = 2449.422605\n",
      "Iter 1000 | Energy = 2449.511837\n",
      "Iter 1000 | Energy = 2449.596620\n",
      "Iter 1000 | Energy = 2449.677176\n",
      "Iter 1000 | Energy = 2449.753714\n",
      "Iter 1000 | Energy = 2449.826436\n",
      "Iter 1000 | Energy = 2449.895530\n",
      "Iter 1000 | Energy = 2449.961180\n",
      "Iter 1000 | Energy = 2450.023554\n",
      "Iter 1000 | Energy = 2450.082818\n",
      "Iter 1000 | Energy = 2450.139126\n",
      "Iter 1000 | Energy = 2450.192625\n",
      "Iter 1000 | Energy = 2450.243455\n",
      "Iter 1000 | Energy = 2450.291750\n",
      "Iter 1000 | Energy = 2450.337635\n",
      "Iter 1000 | Energy = 2450.381231\n",
      "Iter 1000 | Energy = 2450.422653\n",
      "Iter 1000 | Energy = 2450.462008\n",
      "Iter 1000 | Energy = 2450.499399\n",
      "Iter 1000 | Energy = 2450.534925\n",
      "Iter 1000 | Energy = 2450.568678\n",
      "Iter 1000 | Energy = 2450.600747\n",
      "Iter 1000 | Energy = 2450.631216\n",
      "Iter 1000 | Energy = 2450.660165\n",
      "Iter 1000 | Energy = 2450.687669\n",
      "Iter 1000 | Energy = 2450.713801\n",
      "Iter 1000 | Energy = 2450.738629\n",
      "Iter 1000 | Energy = 2450.762218\n",
      "Iter 1000 | Energy = 2450.784630\n",
      "Iter 1000 | Energy = 2450.805923\n",
      "Iter 1000 | Energy = 2450.826154\n",
      "Iter 1000 | Energy = 2450.845375\n",
      "Iter 1000 | Energy = 2450.863637\n",
      "Iter 1000 | Energy = 2450.880988\n",
      "Iter 1000 | Energy = 2450.897473\n",
      "Iter 1000 | Energy = 2450.913135\n",
      "Iter 1000 | Energy = 2450.928015\n",
      "Iter 1000 | Energy = 2450.942153\n",
      "Iter 1000 | Energy = 2450.955585\n",
      "Iter 1000 | Energy = 2450.968347\n",
      "Iter 1000 | Energy = 2450.980472\n",
      "Iter 1000 | Energy = 2450.991992\n",
      "Iter 1000 | Energy = 2451.002937\n",
      "Iter 1000 | Energy = 2451.013336\n",
      "Iter 1000 | Energy = 2451.023215\n",
      "Iter 1000 | Energy = 2451.032602\n",
      "Iter 1000 | Energy = 2451.041520\n",
      "Iter 1000 | Energy = 2451.049993\n",
      "Iter 1000 | Energy = 2451.058043\n",
      "Iter 1000 | Energy = 2451.065691\n",
      "Iter 1000 | Energy = 2451.072958\n",
      "Iter 1000 | Energy = 2451.079862\n",
      "Iter 1000 | Energy = 2451.086421\n",
      "Iter 1000 | Energy = 2451.092653\n",
      "Iter 1000 | Energy = 2451.098574\n",
      "Iter 1000 | Energy = 2451.104199\n",
      "Iter 1000 | Energy = 2451.109544\n",
      "Iter 1000 | Energy = 2451.114622\n",
      "Iter 1000 | Energy = 2451.119446\n",
      "Iter 1000 | Energy = 2451.124030\n",
      "Iter 1000 | Energy = 2451.128384\n",
      "Iter 1000 | Energy = 2451.132522\n",
      "Iter 1000 | Energy = 2451.136453\n",
      "Iter 1000 | Energy = 2451.140188\n",
      "Iter 1000 | Energy = 2451.143736\n",
      "Iter 1000 | Energy = 2451.147107\n",
      "Iter 1000 | Energy = 2451.150310\n",
      "Iter 1000 | Energy = 2451.153353\n",
      "Iter 1000 | Energy = 2451.156244\n",
      "Iter 1000 | Energy = 2451.158991\n",
      "Iter 1000 | Energy = 2451.161601\n",
      "Iter 1000 | Energy = 2451.164080\n",
      "Iter 1000 | Energy = 2451.166436\n",
      "Iter 1000 | Energy = 2451.168674\n",
      "Iter 1000 | Energy = 2451.170801\n",
      "Iter 1000 | Energy = 2451.172821\n",
      "Iter 1000 | Energy = 2451.174740\n",
      "Iter 1000 | Energy = 2451.176564\n",
      "Iter 1000 | Energy = 2451.178297\n",
      "Iter 1000 | Energy = 2451.179943\n",
      "Iter 1000 | Energy = 2451.181507\n",
      "Iter 1000 | Energy = 2451.182993\n",
      "Iter 1000 | Energy = 2451.184405\n",
      "Iter 1000 | Energy = 2451.185746\n",
      "Iter 1000 | Energy = 2451.187020\n",
      "Iter 1000 | Energy = 2451.188231\n",
      "Iter 1000 | Energy = 2451.189381\n",
      "Iter 1000 | Energy = 2451.190474\n",
      "Iter 1000 | Energy = 2451.191512\n",
      "Iter 1000 | Energy = 2451.192499\n",
      "Iter 1000 | Energy = 2451.193436\n",
      "Iter 1000 | Energy = 2451.194326\n",
      "Iter 1000 | Energy = 2451.195173\n",
      "Iter 1000 | Energy = 2451.195976\n",
      "Iter 1000 | Energy = 2451.196740\n",
      "Iter 1000 | Energy = 2451.197466\n",
      "Iter 1000 | Energy = 2451.198155\n",
      "Iter 1000 | Energy = 2451.198810\n",
      "Iter 1000 | Energy = 2451.199432\n",
      "Iter 1000 | Energy = 2451.200023\n",
      "Iter 1000 | Energy = 2451.200585\n",
      "Iter 1000 | Energy = 2451.201118\n",
      "Iter 1000 | Energy = 2451.201625\n",
      "Iter 1000 | Energy = 2451.202107\n",
      "Iter 1000 | Energy = 2451.202565\n",
      "Iter 1000 | Energy = 2451.203000\n",
      "Iter 1000 | Energy = 2451.203413\n",
      "Iter 1000 | Energy = 2451.203805\n",
      "Iter 1000 | Energy = 2451.204178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mBs\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mks\u001b[39m\u001b[33m\"\u001b[39m], layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mk2s\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mbottom_up_modify_abs_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     layers[abs_layer_idx][\u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m].synchronous_iteration()\n\u001b[32m      4\u001b[39m     top_down_modify_super_graph(layers[:])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1290\u001b[39m, in \u001b[36mbottom_up_modify_abs_graph\u001b[39m\u001b[34m(layers, r_reduced, eta_damping)\u001b[39m\n\u001b[32m   1288\u001b[39m i, j = [v.variableID \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f.adj_var_nodes]\n\u001b[32m   1289\u001b[39m vi, vj = abs_var_nodes[i], abs_var_nodes[j]\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m abs_f = \u001b[43mFactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeas_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1291\u001b[39m abs_f.type = \u001b[33m\"\u001b[39m\u001b[33mabs_between\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1292\u001b[39m abs_f.adj_beliefs = [vi.belief, vj.belief]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/gbp/gbp.py:720\u001b[39m, in \u001b[36mFactor.__init__\u001b[39m\u001b[34m(self, factor_id, adj_var_nodes, measurement, measurement_lambda, meas_fn, jac_fn, loss, mahalanobis_threshold, wildfire, *args)\u001b[39m\n\u001b[32m    718\u001b[39m     \u001b[38;5;28mself\u001b[39m.adj_beliefs.append(NdimGaussian(adj_var_node.dofs))\n\u001b[32m    719\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages.append(NdimGaussian(adj_var_node.dofs))\u001b[38;5;66;03m#, eta=adj_var_node.prior.eta, lam=adj_var_node.prior.lam))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages_prior.append(\u001b[43mNdimGaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_var_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdofs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m.messages_dist.append(np.zeros(adj_var_node.dofs))\n\u001b[32m    723\u001b[39m \u001b[38;5;28mself\u001b[39m.factor = NdimGaussian(\u001b[38;5;28mself\u001b[39m.dofs_conditional_vars)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/abstraction-recovery/hierarchy/utils/gaussian.py:16\u001b[39m, in \u001b[36mNdimGaussian.__init__\u001b[39m\u001b[34m(self, dimensionality, eta, lam)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.lam = lam\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28mself\u001b[39m.lam = np.zeros([\u001b[38;5;28mself\u001b[39m.dim, \u001b[38;5;28mself\u001b[39m.dim])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    layers[abs_layer_idx][\"graph\"], layers[abs_layer_idx][\"Bs\"], layers[abs_layer_idx][\"ks\"], layers[abs_layer_idx][\"k2s\"] = bottom_up_modify_abs_graph(layers[:3])\n",
    "    layers[abs_layer_idx][\"graph\"].synchronous_iteration()\n",
    "    top_down_modify_super_graph(layers[:])\n",
    "    top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "    energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b8fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 531 | Energy = 2335.263449\n"
     ]
    }
   ],
   "source": [
    "top_down_modify_super_graph(layers[:])\n",
    "top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 531 | Energy = 2334.490358\n"
     ]
    }
   ],
   "source": [
    "layers[1][\"graph\"].synchronous_iteration()\n",
    "top_down_modify_base_and_abs_graph(layers[0:2])\n",
    "energy = energy_map(layers[0][\"graph\"], include_priors=True, include_factors=True)\n",
    "print(f\"Iter {_+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825805e-09,  7.00557252e-09])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(layers[0][\"graph\"].var_nodes[0].adj_factors[1].adj_beliefs[0].lam, layers[0][\"graph\"].var_nodes[0].adj_factors[1].adj_beliefs[0].eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd50e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825829e-09,  7.00557253e-09])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e157ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825799e-09,  7.00557250e-09,  3.94963401e+00, -2.51772335e+01,\n",
       "        2.59936671e+01, -3.96819499e+01,  3.85359407e+01, -6.20493563e+01,\n",
       "        1.33215562e+01, -7.12420831e+01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[1][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7b2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08825829e-09,  7.00557253e-09])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0][\"graph\"].var_nodes[0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abc516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5cfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Energy: 2348.0945'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_energy(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03313253012048193"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2401-2324)/2324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2481.58433706"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2402*(1.03313253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.988972036403319\n",
      "Iter 1000 | Energy = 7.815849\n",
      "Iter 1000 | Energy = 6.885167\n",
      "Iter 1000 | Energy = 6.902868\n",
      "Iter 1000 | Energy = 6.909297\n",
      "Iter 1000 | Energy = 6.910688\n",
      "Iter 1000 | Energy = 6.911066\n",
      "Iter 1000 | Energy = 6.911152\n",
      "Iter 1000 | Energy = 6.911174\n",
      "Iter 1000 | Energy = 6.911179\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n",
      "Iter 1000 | Energy = 6.911181\n"
     ]
    }
   ],
   "source": [
    "N=6\n",
    "step=25\n",
    "prob=0.05\n",
    "radius=50 \n",
    "prior_prop=0.02\n",
    "prior_sigma=1\n",
    "odom_sigma=1\n",
    "layers = []\n",
    "layers = init_layers(N=N, step_size=step, loop_prob=prob, loop_radius=radius, prior_prop=prior_prop, seed=2001)\n",
    "pair_idx = 0\n",
    "# Create GBP graph\n",
    "gbp_graph = build_noisy_pose_graph(layers[0][\"nodes\"], layers[0][\"edges\"],\n",
    "                                    prior_sigma=prior_sigma,\n",
    "                                    odom_sigma=odom_sigma,\n",
    "                                    seed=2001)\n",
    "layers[0][\"graph\"] = gbp_graph\n",
    "\n",
    "super_nodes, super_edges, node_map = fuse_to_super_order(layers[0][\"nodes\"], layers[0][\"edges\"], k=2, layer_idx=1, tail_heavy=True)\n",
    "layers.append({\"name\":f\"super{1}\", \"nodes\":super_nodes, \"edges\":super_edges, \"node_map\":node_map})\n",
    "layers[0][\"graph\"].synchronous_iteration()\n",
    "layers[1][\"graph\"] = build_super_graph(layers,eta_damping=0)\n",
    "supergraph = layers[-1][\"graph\"]\n",
    "\n",
    "\n",
    "total = 0\n",
    "a = layers[0][\"graph\"].joint_distribution_cov()[0].reshape(layers[0][\"graph\"].n_var_nodes,2)[:,:]\n",
    "for i,v in enumerate(layers[0][\"graph\"].var_nodes[:layers[0][\"graph\"].n_var_nodes]):\n",
    "    gt = np.asarray(v.GT[0:2], dtype=float)\n",
    "    r = np.asarray(a[i][0:2], dtype=float) - gt\n",
    "    total += 0.5 * float(r.T @ r)\n",
    "print(total)\n",
    "\n",
    "abs_nodes, abs_edges = copy_to_abs(layers[1][\"nodes\"], layers[1][\"edges\"], 2)\n",
    "\n",
    "# Ensure super graph has run at least once\n",
    "#layers[1][\"graph\"].synchronous_iteration() \n",
    "r = 2\n",
    "layers.append({\"name\":f\"abs{1}\", \"nodes\":abs_nodes, \"edges\":abs_edges})\n",
    "layers[2][\"graph\"], layers[2][\"Bs\"], layers[2][\"ks\"], layers[2][\"k2s\"] = build_abs_graph(layers, r_reduced=r)\n",
    "\n",
    "vg = VGraph(layers, eta_damping=0)\n",
    "for i in range(50):\n",
    "    vg.layers = layers\n",
    "    vg.layers = vg.vloop()\n",
    "    layers = vg.layers\n",
    "    refresh_gbp_results(layers)\n",
    "    energy = supergraph.energy_map(include_priors=True, include_factors=True)\n",
    "    print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8375df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matmul time: 0.0009918212890625 seconds\n",
      "jax devices: [CudaDevice(id=0)]\n",
      "Result device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "\n",
    "@jit\n",
    "def matmul(x, y):\n",
    "    return x @ y\n",
    "\n",
    "x = jnp.ones((2000, 8000))\n",
    "y = jnp.ones((8000, 2000))\n",
    "\n",
    "# 预热（第一次会 JIT 编译）\n",
    "_ = matmul(x, y).block_until_ready()\n",
    "\n",
    "t0 = time.time()\n",
    "out = matmul(x, y).block_until_ready()\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Matmul time:\", t1 - t0, \"seconds\")\n",
    "print(\"jax devices:\", jax.devices())\n",
    "print(\"Result device:\", out.device)   # ✅ 这里不要加 ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7172e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    out = matmul(x, y).block_until_ready()\n",
    "t1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efcc401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.ones((2000, 8000))\n",
    "y = np.ones((8000, 2000))\n",
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    out = x@y\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7055d3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnvidia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcusparse\u001b[39;00m  \u001b[38;5;66;03m# 先把 wheel 里的 cusparse 模块 import 进来\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 找到 pip 安装的 cuSPARSE 动态库所在目录\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m cusparse_lib_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnvidia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcusparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcusparse_lib_dir =\u001b[39m\u001b[38;5;124m\"\u001b[39m, cusparse_lib_dir)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 把 LD_LIBRARY_PATH 显式设置成这个目录（再附带上原来的其它目录）\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import nvidia.cusparse  # 先把 wheel 里的 cusparse 模块 import 进来\n",
    "\n",
    "# 找到 pip 安装的 cuSPARSE 动态库所在目录\n",
    "cusparse_lib_dir = str(pathlib.Path(nvidia.cusparse.__file__).parent)\n",
    "print(\"cusparse_lib_dir =\", cusparse_lib_dir)\n",
    "\n",
    "# 把 LD_LIBRARY_PATH 显式设置成这个目录（再附带上原来的其它目录）\n",
    "old = os.environ.get(\"LD_LIBRARY_PATH\") or \"\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = cusparse_lib_dir + (\":\" + old if old else \"\")\n",
    "print(\"LD_LIBRARY_PATH =\", os.environ[\"LD_LIBRARY_PATH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a395886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008997083362999205\n"
     ]
    }
   ],
   "source": [
    "print((6.988972036403319-6.911181)/6.988972036403319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 010 | Energy = 6.911181\n"
     ]
    }
   ],
   "source": [
    "energy = layers[1][\"graph\"].energy_map(include_priors=True, include_factors=True)\n",
    "print(f\"Iter {it+1:03d} | Energy = {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bcb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.24417217, -24.77807379])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[2][\"graph\"].var_nodes[0].mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
